{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAS BDAI Individual Innovation Project: Tennis Match Predictor\n",
    "\n",
    "## Table of Contents \n",
    "1. [Introduction](#introduction)\n",
    "2. [Preliminary steps](#preliminary-steps)\n",
    "3. [ ](# )\n",
    "4. [ ](# )\n",
    "5. [ ](# )\n",
    "6. [ ](# )\n",
    "7. [ ](# )\n",
    "8. [ ](# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "### Tennis Match Predictor: GAImeSetMatch\n",
    "\n",
    "### Goal of this project\n",
    "\n",
    "### Steps to implement\n",
    "1. Load and explore the data\n",
    "2. Data processing and cleaning\n",
    "3. Feature Engineering\n",
    "    - Surface win %\n",
    "    - Tournament level win %\n",
    "    - Head-to-head\n",
    "    - Recent form\n",
    "4. Data Analysis\n",
    "5. Prediction\n",
    "\n",
    "\n",
    "![.png](img/project/image.png)\n",
    "\n",
    "Image source: [something](https://example.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary steps <a name=\"preliminary-steps\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the path to the interpreter (OPTIONAL - skip if using Google Colab; modify if using local dev environment )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/jean/Documents/dev/cas-project/venv_proj/bin/python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dependencies\n",
    "We need to import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set static parameters\n",
    "Here we set some parameters which won't be changed. This allows for more easy handling and viewing of the data being explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, set some static parameters and options (used later too for loading other files)\n",
    "\n",
    "# directory containing the .csv files\n",
    "DIRNAME = 'data'\n",
    "\n",
    "# set options for pandas viewing\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper functions and datasets\n",
    "These will help us later with common tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data 5 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Small sample dataframe (5 matches) for misc usage\n",
    "sample_matches_df = pd.DataFrame(data = {\n",
    "    'tourney_id': ['2000-301', '2000-301', '2000-301', '2000-301', '2000-301'],\n",
    "    'tourney_name': ['Auckland', 'Auckland', 'Auckland', 'Auckland', 'Auckland'],\n",
    "    'surface': ['Hard', 'Hard', 'Hard', 'Hard', 'Hard'],\n",
    "    'draw_size': [32, 32, 32, 32, 32],\n",
    "    'tourney_level': ['A', 'A', 'A', 'A', 'A'],\n",
    "    'tourney_date': [20000110, 20000110, 20000110, 20000110, 20000110],\n",
    "    'match_num': [1, 2, 3, 4, 5],\n",
    "    'winner_id': [103163, 102607, 103252, 103507, 102103],\n",
    "    'winner_seed': [1.0, None, None, 7.0, None],\n",
    "    'winner_entry': [None, 'Q', None, None, 'Q'],\n",
    "    'winner_name': ['Tommy Haas', 'Juan Balcells', 'Alberto Martin', 'Juan Carlos Ferrero', 'Michael Sell'],\n",
    "    'winner_hand': ['R', 'R', 'R', 'R', 'R'],\n",
    "    'winner_ht': [188.0, 190.0, 175.0, 183.0, 180.0],\n",
    "    'winner_ioc': ['GER', 'ESP', 'ESP', 'ESP', 'USA'],\n",
    "    'winner_age': [21.7, 24.5, 21.3, 19.9, 27.3],\n",
    "    'loser_id': [101543, 102644, 102238, 103819, 102765],\n",
    "    'loser_seed': [None, None, None, None, 4.0],\n",
    "    'loser_entry': [None, None, None, None, None],\n",
    "    'loser_name': ['Jeff Tarango', 'Franco Squillari', 'Alberto Berasategui', 'Roger Federer', 'Nicolas Escude'],\n",
    "    'loser_hand': ['L', 'L', 'L', 'L', 'L'],\n",
    "    'loser_ht': [180.0, 183.0, 173.0, 185.0, 185.0],\n",
    "    'loser_ioc': ['USA', 'ARG', 'ESP', 'SUI', 'FRA'],\n",
    "    'loser_age': [31.1, 24.3, 26.5, 18.4, 23.7],\n",
    "    'score': ['7-5 4-6 7-5', '7-5 7-5', '6-3 6-1', '6-4 6-4', '0-6 7-6(7) 6-1'],\n",
    "    'best_of': [3, 3, 3, 3, 3],\n",
    "    'round': ['R32', 'R32', 'R32', 'R32', 'R32'],\n",
    "    'minutes': [108.0, 85.0, 56.0, 68.0, 115.0],\n",
    "    'w_ace': [18.0, 5.0, 0.0, 5.0, 1.0],\n",
    "    'w_df': [4.0, 3.0, 0.0, 1.0, 2.0],\n",
    "    'w_svpt': [96.0, 76.0, 55.0, 53.0, 98.0],\n",
    "    'w_1stIn': [49.0, 52.0, 35.0, 28.0, 66.0],\n",
    "    'w_1stWon': [39.0, 39.0, 25.0, 26.0, 39.0],\n",
    "    'w_2ndWon': [28.0, 13.0, 12.0, 15.0, 14.0],\n",
    "    'w_SvGms': [17.0, 12.0, 8.0, 10.0, 13.0],\n",
    "    'w_bpSaved': [3.0, 5.0, 1.0, 0.0, 6.0],\n",
    "    'w_bpFaced': [5.0, 6.0, 1.0, 0.0, 8.0],\n",
    "    'l_ace': [7.0, 10.0, 6.0, 11.0, 8.0],\n",
    "    'l_df': [8.0, 7.0, 6.0, 2.0, 8.0],\n",
    "    'l_svpt': [106.0, 74.0, 56.0, 70.0, 92.0],\n",
    "    'l_1stIn': [55.0, 32.0, 33.0, 43.0, 46.0],\n",
    "    'l_1stWon': [39.0, 25.0, 20.0, 29.0, 34.0],\n",
    "    'l_2ndWon': [29.0, 18.0, 7.0, 14.0, 18.0],\n",
    "    'l_SvGms': [17.0, 12.0, 8.0, 10.0, 12.0],\n",
    "    'l_bpSaved': [4.0, 3.0, 7.0, 6.0, 5.0],\n",
    "    'l_bpFaced': [7.0, 6.0, 11.0, 8.0, 9.0],\n",
    "    'winner_rank': [11.0, 211.0, 48.0, 45.0, 167.0],\n",
    "    'winner_rank_points': [1612.0, 157.0, 726.0, 768.0, 219.0],\n",
    "    'loser_rank': [63.0, 49.0, 59.0, 61.0, 34.0],\n",
    "    'loser_rank_points': [595.0, 723.0, 649.0, 616.0, 873.0]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore the data\n",
    "This section loads the data available in .csv files from the aforementioned source, explores the data and then cleans it for ease of use and data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Load matches\n",
    "Data is available in the form of results of ATP matches. For simplicity reasons, focus only on matches since the year 2000*. Each year is stored in one file using naming convention atp_matches_yyyy.csv.\n",
    "\n",
    "*The reasoning behind this: since the year 2000, there have been factors that have influenced the outcomes of the modern form of the sport. For me, these are:\n",
    "1. Racquet technology: Since the 1980s, rackets are made mainly out of graphite. Reference: [Link](https://www.pledgesports.org/2019/08/evolution-of-tennis-rackets/)\n",
    "2. String technology: In the late 1990s, polyester strings were introduced, which revolutionised the sport. Reference: [Link](https://scientificinquirer.com/2021/08/30/string-theory-the-synthetic-revolution-that-changed-tennis-forever/)\n",
    "3. Surfaces: in 2009, the ATP discontinued use of carpet court use in all its tournaments. Reference: [Link](https://racketsportsworld.com/tennis-not-played-carpet-courts/#When_was_Carpet_Discontinued_from_Use_in_Tennis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of matches (since the year 2000 ) files to load\n",
    "atp_match_files = [f'{DIRNAME}/atp_matches_{year}.csv' for year in range(2000, 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to store all matches\n",
    "matches_df = pd.DataFrame()\n",
    "\n",
    "# loop through the list of match files, read them and append the data to the combined DataFrame\n",
    "for filen in atp_match_files:\n",
    "    matches_df = pd.concat([matches_df, pd.read_csv(filen, index_col=None)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_entry</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>winner_hand</th>\n",
       "      <th>winner_ht</th>\n",
       "      <th>winner_ioc</th>\n",
       "      <th>winner_age</th>\n",
       "      <th>loser_id</th>\n",
       "      <th>loser_seed</th>\n",
       "      <th>loser_entry</th>\n",
       "      <th>loser_name</th>\n",
       "      <th>loser_hand</th>\n",
       "      <th>loser_ht</th>\n",
       "      <th>loser_ioc</th>\n",
       "      <th>loser_age</th>\n",
       "      <th>score</th>\n",
       "      <th>best_of</th>\n",
       "      <th>round</th>\n",
       "      <th>minutes</th>\n",
       "      <th>w_ace</th>\n",
       "      <th>w_df</th>\n",
       "      <th>w_svpt</th>\n",
       "      <th>w_1stIn</th>\n",
       "      <th>w_1stWon</th>\n",
       "      <th>w_2ndWon</th>\n",
       "      <th>w_SvGms</th>\n",
       "      <th>w_bpSaved</th>\n",
       "      <th>w_bpFaced</th>\n",
       "      <th>l_ace</th>\n",
       "      <th>l_df</th>\n",
       "      <th>l_svpt</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>1</td>\n",
       "      <td>103163</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tommy Haas</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>21.700</td>\n",
       "      <td>101543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeff Tarango</td>\n",
       "      <td>L</td>\n",
       "      <td>180.000</td>\n",
       "      <td>USA</td>\n",
       "      <td>31.100</td>\n",
       "      <td>7-5 4-6 7-5</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>108.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>106.000</td>\n",
       "      <td>55.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>1612.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>595.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>2</td>\n",
       "      <td>102607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Juan Balcells</td>\n",
       "      <td>R</td>\n",
       "      <td>190.000</td>\n",
       "      <td>ESP</td>\n",
       "      <td>24.500</td>\n",
       "      <td>102644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franco Squillari</td>\n",
       "      <td>L</td>\n",
       "      <td>183.000</td>\n",
       "      <td>ARG</td>\n",
       "      <td>24.300</td>\n",
       "      <td>7-5 7-5</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>85.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>76.000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>157.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>723.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>3</td>\n",
       "      <td>103252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alberto Martin</td>\n",
       "      <td>R</td>\n",
       "      <td>175.000</td>\n",
       "      <td>ESP</td>\n",
       "      <td>21.300</td>\n",
       "      <td>102238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alberto Berasategui</td>\n",
       "      <td>R</td>\n",
       "      <td>173.000</td>\n",
       "      <td>ESP</td>\n",
       "      <td>26.500</td>\n",
       "      <td>6-3 6-1</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>56.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>55.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>726.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>649.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>4</td>\n",
       "      <td>103507</td>\n",
       "      <td>7.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juan Carlos Ferrero</td>\n",
       "      <td>R</td>\n",
       "      <td>183.000</td>\n",
       "      <td>ESP</td>\n",
       "      <td>19.900</td>\n",
       "      <td>103819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>R</td>\n",
       "      <td>185.000</td>\n",
       "      <td>SUI</td>\n",
       "      <td>18.400</td>\n",
       "      <td>6-4 6-4</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>68.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>616.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>5</td>\n",
       "      <td>102103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Michael Sell</td>\n",
       "      <td>R</td>\n",
       "      <td>180.000</td>\n",
       "      <td>USA</td>\n",
       "      <td>27.300</td>\n",
       "      <td>102765</td>\n",
       "      <td>4.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicolas Escude</td>\n",
       "      <td>R</td>\n",
       "      <td>185.000</td>\n",
       "      <td>FRA</td>\n",
       "      <td>23.700</td>\n",
       "      <td>0-6 7-6(7) 6-1</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>115.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>167.000</td>\n",
       "      <td>219.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>873.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n",
       "0   2000-301     Auckland    Hard         32             A      20000110   \n",
       "1   2000-301     Auckland    Hard         32             A      20000110   \n",
       "2   2000-301     Auckland    Hard         32             A      20000110   \n",
       "3   2000-301     Auckland    Hard         32             A      20000110   \n",
       "4   2000-301     Auckland    Hard         32             A      20000110   \n",
       "\n",
       "   match_num  winner_id  winner_seed winner_entry          winner_name  \\\n",
       "0          1     103163        1.000          NaN           Tommy Haas   \n",
       "1          2     102607          NaN            Q        Juan Balcells   \n",
       "2          3     103252          NaN          NaN       Alberto Martin   \n",
       "3          4     103507        7.000          NaN  Juan Carlos Ferrero   \n",
       "4          5     102103          NaN            Q         Michael Sell   \n",
       "\n",
       "  winner_hand  winner_ht winner_ioc  winner_age  loser_id  loser_seed  \\\n",
       "0           R    188.000        GER      21.700    101543         NaN   \n",
       "1           R    190.000        ESP      24.500    102644         NaN   \n",
       "2           R    175.000        ESP      21.300    102238         NaN   \n",
       "3           R    183.000        ESP      19.900    103819         NaN   \n",
       "4           R    180.000        USA      27.300    102765       4.000   \n",
       "\n",
       "  loser_entry           loser_name loser_hand  loser_ht loser_ioc  loser_age  \\\n",
       "0         NaN         Jeff Tarango          L   180.000       USA     31.100   \n",
       "1         NaN     Franco Squillari          L   183.000       ARG     24.300   \n",
       "2         NaN  Alberto Berasategui          R   173.000       ESP     26.500   \n",
       "3         NaN        Roger Federer          R   185.000       SUI     18.400   \n",
       "4         NaN       Nicolas Escude          R   185.000       FRA     23.700   \n",
       "\n",
       "            score  best_of round  minutes  w_ace  w_df  w_svpt  w_1stIn  \\\n",
       "0     7-5 4-6 7-5        3   R32  108.000 18.000 4.000  96.000   49.000   \n",
       "1         7-5 7-5        3   R32   85.000  5.000 3.000  76.000   52.000   \n",
       "2         6-3 6-1        3   R32   56.000  0.000 0.000  55.000   35.000   \n",
       "3         6-4 6-4        3   R32   68.000  5.000 1.000  53.000   28.000   \n",
       "4  0-6 7-6(7) 6-1        3   R32  115.000  1.000 2.000  98.000   66.000   \n",
       "\n",
       "   w_1stWon  w_2ndWon  w_SvGms  w_bpSaved  w_bpFaced  l_ace   l_df  l_svpt  \\\n",
       "0    39.000    28.000   17.000      3.000      5.000  7.000  8.000 106.000   \n",
       "1    39.000    13.000   12.000      5.000      6.000  5.000 10.000  74.000   \n",
       "2    25.000    12.000    8.000      1.000      1.000  0.000  6.000  56.000   \n",
       "3    26.000    15.000   10.000      0.000      0.000 11.000  2.000  70.000   \n",
       "4    39.000    14.000   13.000      6.000     11.000  8.000  8.000  92.000   \n",
       "\n",
       "   l_1stIn  l_1stWon  l_2ndWon  l_SvGms  l_bpSaved  l_bpFaced  winner_rank  \\\n",
       "0   55.000    39.000    29.000   17.000      4.000      7.000       11.000   \n",
       "1   32.000    25.000    18.000   12.000      3.000      6.000      211.000   \n",
       "2   33.000    20.000     7.000    8.000      7.000     11.000       48.000   \n",
       "3   43.000    29.000    14.000   10.000      6.000      8.000       45.000   \n",
       "4   46.000    34.000    18.000   12.000      5.000      9.000      167.000   \n",
       "\n",
       "   winner_rank_points  loser_rank  loser_rank_points  \n",
       "0            1612.000      63.000            595.000  \n",
       "1             157.000      49.000            723.000  \n",
       "2             726.000      59.000            649.000  \n",
       "3             768.000      61.000            616.000  \n",
       "4             219.000      34.000            873.000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the matches data\n",
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 71213 entries, 0 to 2368\n",
      "Data columns (total 49 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tourney_id          71213 non-null  object \n",
      " 1   tourney_name        71213 non-null  object \n",
      " 2   surface             71213 non-null  object \n",
      " 3   draw_size           71213 non-null  int64  \n",
      " 4   tourney_level       71213 non-null  object \n",
      " 5   tourney_date        71213 non-null  int64  \n",
      " 6   match_num           71213 non-null  int64  \n",
      " 7   winner_id           71213 non-null  int64  \n",
      " 8   winner_seed         29586 non-null  float64\n",
      " 9   winner_entry        8944 non-null   object \n",
      " 10  winner_name         71213 non-null  object \n",
      " 11  winner_hand         71204 non-null  object \n",
      " 12  winner_ht           69582 non-null  float64\n",
      " 13  winner_ioc          71213 non-null  object \n",
      " 14  winner_age          71208 non-null  float64\n",
      " 15  loser_id            71213 non-null  int64  \n",
      " 16  loser_seed          16330 non-null  float64\n",
      " 17  loser_entry         14584 non-null  object \n",
      " 18  loser_name          71213 non-null  object \n",
      " 19  loser_hand          71171 non-null  object \n",
      " 20  loser_ht            67939 non-null  float64\n",
      " 21  loser_ioc           71213 non-null  object \n",
      " 22  loser_age           71207 non-null  float64\n",
      " 23  score               71213 non-null  object \n",
      " 24  best_of             71213 non-null  int64  \n",
      " 25  round               71213 non-null  object \n",
      " 26  minutes             63277 non-null  float64\n",
      " 27  w_ace               64811 non-null  float64\n",
      " 28  w_df                64811 non-null  float64\n",
      " 29  w_svpt              64811 non-null  float64\n",
      " 30  w_1stIn             64811 non-null  float64\n",
      " 31  w_1stWon            64811 non-null  float64\n",
      " 32  w_2ndWon            64811 non-null  float64\n",
      " 33  w_SvGms             64812 non-null  float64\n",
      " 34  w_bpSaved           64811 non-null  float64\n",
      " 35  w_bpFaced           64811 non-null  float64\n",
      " 36  l_ace               64811 non-null  float64\n",
      " 37  l_df                64811 non-null  float64\n",
      " 38  l_svpt              64811 non-null  float64\n",
      " 39  l_1stIn             64811 non-null  float64\n",
      " 40  l_1stWon            64811 non-null  float64\n",
      " 41  l_2ndWon            64811 non-null  float64\n",
      " 42  l_SvGms             64812 non-null  float64\n",
      " 43  l_bpSaved           64811 non-null  float64\n",
      " 44  l_bpFaced           64811 non-null  float64\n",
      " 45  winner_rank         70666 non-null  float64\n",
      " 46  winner_rank_points  70666 non-null  float64\n",
      " 47  loser_rank          69793 non-null  float64\n",
      " 48  loser_rank_points   69793 non-null  float64\n",
      "dtypes: float64(29), int64(6), object(14)\n",
      "memory usage: 27.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# get an overview of number of features, instances, empty values and data types \n",
    "matches_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alll features starting with \"w_\" or \"l_\" indicate in-game metrics, which is out of scope for this project. So we will remove them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_ht</th>\n",
       "      <th>winner_age</th>\n",
       "      <th>loser_id</th>\n",
       "      <th>loser_seed</th>\n",
       "      <th>loser_ht</th>\n",
       "      <th>loser_age</th>\n",
       "      <th>best_of</th>\n",
       "      <th>minutes</th>\n",
       "      <th>w_ace</th>\n",
       "      <th>w_df</th>\n",
       "      <th>w_svpt</th>\n",
       "      <th>w_1stIn</th>\n",
       "      <th>w_1stWon</th>\n",
       "      <th>w_2ndWon</th>\n",
       "      <th>w_SvGms</th>\n",
       "      <th>w_bpSaved</th>\n",
       "      <th>w_bpFaced</th>\n",
       "      <th>l_ace</th>\n",
       "      <th>l_df</th>\n",
       "      <th>l_svpt</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71213.000</td>\n",
       "      <td>71213.000</td>\n",
       "      <td>71213.000</td>\n",
       "      <td>71213.000</td>\n",
       "      <td>29586.000</td>\n",
       "      <td>69582.000</td>\n",
       "      <td>71208.000</td>\n",
       "      <td>71213.000</td>\n",
       "      <td>16330.000</td>\n",
       "      <td>67939.000</td>\n",
       "      <td>71207.000</td>\n",
       "      <td>71213.000</td>\n",
       "      <td>63277.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64812.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64812.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>64811.000</td>\n",
       "      <td>70666.000</td>\n",
       "      <td>70666.000</td>\n",
       "      <td>69793.000</td>\n",
       "      <td>69793.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.128</td>\n",
       "      <td>20109104.958</td>\n",
       "      <td>94.713</td>\n",
       "      <td>108736.809</td>\n",
       "      <td>7.376</td>\n",
       "      <td>186.138</td>\n",
       "      <td>26.284</td>\n",
       "      <td>108802.466</td>\n",
       "      <td>8.892</td>\n",
       "      <td>185.599</td>\n",
       "      <td>26.390</td>\n",
       "      <td>3.458</td>\n",
       "      <td>106.692</td>\n",
       "      <td>6.912</td>\n",
       "      <td>2.651</td>\n",
       "      <td>77.995</td>\n",
       "      <td>47.971</td>\n",
       "      <td>36.300</td>\n",
       "      <td>16.645</td>\n",
       "      <td>12.519</td>\n",
       "      <td>3.464</td>\n",
       "      <td>5.038</td>\n",
       "      <td>5.115</td>\n",
       "      <td>3.376</td>\n",
       "      <td>81.034</td>\n",
       "      <td>48.558</td>\n",
       "      <td>32.397</td>\n",
       "      <td>14.965</td>\n",
       "      <td>12.312</td>\n",
       "      <td>4.780</td>\n",
       "      <td>8.628</td>\n",
       "      <td>79.609</td>\n",
       "      <td>1592.650</td>\n",
       "      <td>117.938</td>\n",
       "      <td>965.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.045</td>\n",
       "      <td>68421.821</td>\n",
       "      <td>130.189</td>\n",
       "      <td>18210.110</td>\n",
       "      <td>6.790</td>\n",
       "      <td>6.811</td>\n",
       "      <td>3.959</td>\n",
       "      <td>18259.896</td>\n",
       "      <td>7.328</td>\n",
       "      <td>6.769</td>\n",
       "      <td>4.072</td>\n",
       "      <td>0.840</td>\n",
       "      <td>41.178</td>\n",
       "      <td>5.534</td>\n",
       "      <td>2.290</td>\n",
       "      <td>29.239</td>\n",
       "      <td>18.972</td>\n",
       "      <td>13.591</td>\n",
       "      <td>6.980</td>\n",
       "      <td>4.233</td>\n",
       "      <td>3.078</td>\n",
       "      <td>4.035</td>\n",
       "      <td>4.889</td>\n",
       "      <td>2.535</td>\n",
       "      <td>29.214</td>\n",
       "      <td>19.241</td>\n",
       "      <td>14.385</td>\n",
       "      <td>7.207</td>\n",
       "      <td>4.234</td>\n",
       "      <td>3.273</td>\n",
       "      <td>4.148</td>\n",
       "      <td>138.950</td>\n",
       "      <td>1997.658</td>\n",
       "      <td>186.050</td>\n",
       "      <td>1112.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000</td>\n",
       "      <td>20000103.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>100644.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>163.000</td>\n",
       "      <td>14.900</td>\n",
       "      <td>100644.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>163.000</td>\n",
       "      <td>14.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000</td>\n",
       "      <td>20050509.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>103498.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>183.000</td>\n",
       "      <td>23.400</td>\n",
       "      <td>103444.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>181.000</td>\n",
       "      <td>23.400</td>\n",
       "      <td>3.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>573.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>426.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.000</td>\n",
       "      <td>20110117.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>104339.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>185.000</td>\n",
       "      <td>26.100</td>\n",
       "      <td>104338.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>185.000</td>\n",
       "      <td>26.200</td>\n",
       "      <td>3.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>76.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>933.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>703.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.000</td>\n",
       "      <td>20170203.000</td>\n",
       "      <td>169.000</td>\n",
       "      <td>105227.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>190.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>105385.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>190.000</td>\n",
       "      <td>29.200</td>\n",
       "      <td>3.000</td>\n",
       "      <td>129.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>97.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>1715.000</td>\n",
       "      <td>114.000</td>\n",
       "      <td>1095.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>128.000</td>\n",
       "      <td>20230828.000</td>\n",
       "      <td>1701.000</td>\n",
       "      <td>211468.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>42.300</td>\n",
       "      <td>212041.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1146.000</td>\n",
       "      <td>113.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>491.000</td>\n",
       "      <td>361.000</td>\n",
       "      <td>292.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>103.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>489.000</td>\n",
       "      <td>328.000</td>\n",
       "      <td>284.000</td>\n",
       "      <td>101.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>2101.000</td>\n",
       "      <td>16950.000</td>\n",
       "      <td>2159.000</td>\n",
       "      <td>16950.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       draw_size  tourney_date  match_num  winner_id  winner_seed  winner_ht  \\\n",
       "count  71213.000     71213.000  71213.000  71213.000    29586.000  69582.000   \n",
       "mean      55.128  20109104.958     94.713 108736.809        7.376    186.138   \n",
       "std       40.045     68421.821    130.189  18210.110        6.790      6.811   \n",
       "min        2.000  20000103.000      1.000 100644.000        1.000    163.000   \n",
       "25%       32.000  20050509.000     11.000 103498.000        3.000    183.000   \n",
       "50%       32.000  20110117.000     28.000 104339.000        5.000    185.000   \n",
       "75%       64.000  20170203.000    169.000 105227.000        9.000    190.000   \n",
       "max      128.000  20230828.000   1701.000 211468.000       35.000    211.000   \n",
       "\n",
       "       winner_age   loser_id  loser_seed  loser_ht  loser_age   best_of  \\\n",
       "count   71208.000  71213.000   16330.000 67939.000  71207.000 71213.000   \n",
       "mean       26.284 108802.466       8.892   185.599     26.390     3.458   \n",
       "std         3.959  18259.896       7.328     6.769      4.072     0.840   \n",
       "min        14.900 100644.000       1.000   163.000     14.500     3.000   \n",
       "25%        23.400 103444.000       4.000   181.000     23.400     3.000   \n",
       "50%        26.100 104338.000       7.000   185.000     26.200     3.000   \n",
       "75%        29.000 105385.000      12.000   190.000     29.200     3.000   \n",
       "max        42.300 212041.000      35.000   211.000     46.000     5.000   \n",
       "\n",
       "        minutes     w_ace      w_df    w_svpt   w_1stIn  w_1stWon  w_2ndWon  \\\n",
       "count 63277.000 64811.000 64811.000 64811.000 64811.000 64811.000 64811.000   \n",
       "mean    106.692     6.912     2.651    77.995    47.971    36.300    16.645   \n",
       "std      41.178     5.534     2.290    29.239    18.972    13.591     6.980   \n",
       "min       0.000     0.000     0.000     0.000     0.000     0.000     0.000   \n",
       "25%      77.000     3.000     1.000    56.000    34.000    27.000    12.000   \n",
       "50%      99.000     6.000     2.000    73.000    45.000    34.000    16.000   \n",
       "75%     129.000     9.000     4.000    94.000    58.000    43.000    20.000   \n",
       "max    1146.000   113.000    26.000   491.000   361.000   292.000    82.000   \n",
       "\n",
       "        w_SvGms  w_bpSaved  w_bpFaced     l_ace      l_df    l_svpt   l_1stIn  \\\n",
       "count 64812.000  64811.000  64811.000 64811.000 64811.000 64811.000 64811.000   \n",
       "mean     12.519      3.464      5.038     5.115     3.376    81.034    48.558   \n",
       "std       4.233      3.078      4.035     4.889     2.535    29.214    19.241   \n",
       "min       0.000      0.000      0.000     0.000     0.000     0.000     0.000   \n",
       "25%       9.000      1.000      2.000     2.000     2.000    60.000    35.000   \n",
       "50%      11.000      3.000      4.000     4.000     3.000    76.000    45.000   \n",
       "75%      15.000      5.000      7.000     7.000     5.000    97.000    59.000   \n",
       "max      90.000     24.000     30.000   103.000    26.000   489.000   328.000   \n",
       "\n",
       "       l_1stWon  l_2ndWon   l_SvGms  l_bpSaved  l_bpFaced  winner_rank  \\\n",
       "count 64811.000 64811.000 64812.000  64811.000  64811.000    70666.000   \n",
       "mean     32.397    14.965    12.312      4.780      8.628       79.609   \n",
       "std      14.385     7.207     4.234      3.273      4.148      138.950   \n",
       "min       0.000     0.000     0.000      0.000      0.000        1.000   \n",
       "25%      22.000    10.000     9.000      2.000      6.000       18.000   \n",
       "50%      30.000    14.000    11.000      4.000      8.000       45.000   \n",
       "75%      40.000    19.000    15.000      7.000     11.000       85.000   \n",
       "max     284.000   101.000    91.000     27.000     38.000     2101.000   \n",
       "\n",
       "       winner_rank_points  loser_rank  loser_rank_points  \n",
       "count           70666.000   69793.000          69793.000  \n",
       "mean             1592.650     117.938            965.143  \n",
       "std              1997.658     186.050           1112.623  \n",
       "min                 1.000       1.000              1.000  \n",
       "25%               573.000      36.000            426.000  \n",
       "50%               933.000      68.000            703.000  \n",
       "75%              1715.000     114.000           1095.000  \n",
       "max             16950.000    2159.000          16950.000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of instances and features: (71213, 49)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of instances and features: \" + str(matches_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeros\n",
    "Here we check for zeros in the matches mframe, in order to decide what to do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_id                0\n",
       "tourney_name              0\n",
       "surface                   0\n",
       "draw_size                 0\n",
       "tourney_level             0\n",
       "tourney_date              0\n",
       "match_num                 0\n",
       "winner_id                 0\n",
       "winner_seed               0\n",
       "winner_entry              0\n",
       "winner_name               0\n",
       "winner_hand               0\n",
       "winner_ht                 0\n",
       "winner_ioc                0\n",
       "winner_age                0\n",
       "loser_id                  0\n",
       "loser_seed                0\n",
       "loser_entry               0\n",
       "loser_name                0\n",
       "loser_hand                0\n",
       "loser_ht                  0\n",
       "loser_ioc                 0\n",
       "loser_age                 0\n",
       "score                     0\n",
       "best_of                   0\n",
       "round                     0\n",
       "minutes                  47\n",
       "w_ace                  2482\n",
       "w_df                   9355\n",
       "w_svpt                    5\n",
       "w_1stIn                   5\n",
       "w_1stWon                  7\n",
       "w_2ndWon                 29\n",
       "w_SvGms                   9\n",
       "w_bpSaved             10751\n",
       "w_bpFaced              6280\n",
       "l_ace                  5856\n",
       "l_df                   5183\n",
       "l_svpt                    4\n",
       "l_1stIn                   6\n",
       "l_1stWon                 24\n",
       "l_2ndWon                 75\n",
       "l_SvGms                  11\n",
       "l_bpSaved              3322\n",
       "l_bpFaced               184\n",
       "winner_rank               0\n",
       "winner_rank_points        0\n",
       "loser_rank                0\n",
       "loser_rank_points         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all features for zero's\n",
    "zero_count_per_feature= matches_df.apply(lambda col: (col == 0).sum())\n",
    "zero_count_per_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_entry</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>winner_hand</th>\n",
       "      <th>winner_ht</th>\n",
       "      <th>winner_ioc</th>\n",
       "      <th>winner_age</th>\n",
       "      <th>loser_id</th>\n",
       "      <th>loser_seed</th>\n",
       "      <th>loser_entry</th>\n",
       "      <th>loser_name</th>\n",
       "      <th>loser_hand</th>\n",
       "      <th>loser_ht</th>\n",
       "      <th>loser_ioc</th>\n",
       "      <th>loser_age</th>\n",
       "      <th>score</th>\n",
       "      <th>best_of</th>\n",
       "      <th>round</th>\n",
       "      <th>minutes</th>\n",
       "      <th>w_ace</th>\n",
       "      <th>w_df</th>\n",
       "      <th>w_svpt</th>\n",
       "      <th>w_1stIn</th>\n",
       "      <th>w_1stWon</th>\n",
       "      <th>w_2ndWon</th>\n",
       "      <th>w_SvGms</th>\n",
       "      <th>w_bpSaved</th>\n",
       "      <th>w_bpFaced</th>\n",
       "      <th>l_ace</th>\n",
       "      <th>l_df</th>\n",
       "      <th>l_svpt</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2020-580</td>\n",
       "      <td>Australian Open</td>\n",
       "      <td>Hard</td>\n",
       "      <td>128</td>\n",
       "      <td>G</td>\n",
       "      <td>20200120</td>\n",
       "      <td>188</td>\n",
       "      <td>126774</td>\n",
       "      <td>6.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stefanos Tsitsipas</td>\n",
       "      <td>R</td>\n",
       "      <td>193.000</td>\n",
       "      <td>GRE</td>\n",
       "      <td>21.400</td>\n",
       "      <td>104259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philipp Kohlschreiber</td>\n",
       "      <td>R</td>\n",
       "      <td>178.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>36.200</td>\n",
       "      <td>W/O</td>\n",
       "      <td>5</td>\n",
       "      <td>R64</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5375.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>700.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2020-0891</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20200203</td>\n",
       "      <td>287</td>\n",
       "      <td>105216</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yuichi Sugita</td>\n",
       "      <td>R</td>\n",
       "      <td>173.000</td>\n",
       "      <td>JPN</td>\n",
       "      <td>31.300</td>\n",
       "      <td>104678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Viktor Troicki</td>\n",
       "      <td>R</td>\n",
       "      <td>193.000</td>\n",
       "      <td>SRB</td>\n",
       "      <td>33.900</td>\n",
       "      <td>W/O</td>\n",
       "      <td>3</td>\n",
       "      <td>R16</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.000</td>\n",
       "      <td>645.000</td>\n",
       "      <td>191.000</td>\n",
       "      <td>263.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2020-0506</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20200210</td>\n",
       "      <td>299</td>\n",
       "      <td>105155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LL</td>\n",
       "      <td>Pedro Sousa</td>\n",
       "      <td>R</td>\n",
       "      <td>180.000</td>\n",
       "      <td>POR</td>\n",
       "      <td>31.700</td>\n",
       "      <td>106043</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diego Schwartzman</td>\n",
       "      <td>R</td>\n",
       "      <td>170.000</td>\n",
       "      <td>ARG</td>\n",
       "      <td>27.400</td>\n",
       "      <td>W/O</td>\n",
       "      <td>3</td>\n",
       "      <td>SF</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>2325.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2020-0407</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20200210</td>\n",
       "      <td>275</td>\n",
       "      <td>206173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WC</td>\n",
       "      <td>Jannik Sinner</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>ITA</td>\n",
       "      <td>18.400</td>\n",
       "      <td>105430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radu Albot</td>\n",
       "      <td>R</td>\n",
       "      <td>175.000</td>\n",
       "      <td>MDA</td>\n",
       "      <td>30.200</td>\n",
       "      <td>W/O</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.000</td>\n",
       "      <td>710.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>977.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2020-0352</td>\n",
       "      <td>Paris Masters</td>\n",
       "      <td>Hard</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>20201102</td>\n",
       "      <td>271</td>\n",
       "      <td>105227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marin Cilic</td>\n",
       "      <td>R</td>\n",
       "      <td>198.000</td>\n",
       "      <td>CRO</td>\n",
       "      <td>32.000</td>\n",
       "      <td>144895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WC</td>\n",
       "      <td>Corentin Moutet</td>\n",
       "      <td>L</td>\n",
       "      <td>178.000</td>\n",
       "      <td>FRA</td>\n",
       "      <td>21.500</td>\n",
       "      <td>W/O</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000</td>\n",
       "      <td>1280.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>838.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tourney_id     tourney_name surface  draw_size tourney_level  \\\n",
       "255    2020-580  Australian Open    Hard        128             G   \n",
       "361   2020-0891             Pune    Hard         32             A   \n",
       "376   2020-0506     Buenos Aires    Clay         32             A   \n",
       "454   2020-0407        Rotterdam    Hard         32             A   \n",
       "1258  2020-0352    Paris Masters    Hard         64             M   \n",
       "\n",
       "      tourney_date  match_num  winner_id  winner_seed winner_entry  \\\n",
       "255       20200120        188     126774        6.000          NaN   \n",
       "361       20200203        287     105216        5.000          NaN   \n",
       "376       20200210        299     105155          NaN           LL   \n",
       "454       20200210        275     206173          NaN           WC   \n",
       "1258      20201102        271     105227          NaN          NaN   \n",
       "\n",
       "             winner_name winner_hand  winner_ht winner_ioc  winner_age  \\\n",
       "255   Stefanos Tsitsipas           R    193.000        GRE      21.400   \n",
       "361        Yuichi Sugita           R    173.000        JPN      31.300   \n",
       "376          Pedro Sousa           R    180.000        POR      31.700   \n",
       "454        Jannik Sinner           R    188.000        ITA      18.400   \n",
       "1258         Marin Cilic           R    198.000        CRO      32.000   \n",
       "\n",
       "      loser_id  loser_seed loser_entry             loser_name loser_hand  \\\n",
       "255     104259         NaN         NaN  Philipp Kohlschreiber          R   \n",
       "361     104678         NaN           Q         Viktor Troicki          R   \n",
       "376     106043       1.000         NaN      Diego Schwartzman          R   \n",
       "454     105430         NaN         NaN             Radu Albot          R   \n",
       "1258    144895         NaN          WC        Corentin Moutet          L   \n",
       "\n",
       "      loser_ht loser_ioc  loser_age score  best_of round  minutes  w_ace  \\\n",
       "255    178.000       GER     36.200   W/O        5   R64    0.000    NaN   \n",
       "361    193.000       SRB     33.900   W/O        3   R16    0.000    NaN   \n",
       "376    170.000       ARG     27.400   W/O        3    SF    0.000    NaN   \n",
       "454    175.000       MDA     30.200   W/O        3   R32    0.000    NaN   \n",
       "1258   178.000       FRA     21.500   W/O        3   R32    0.000    NaN   \n",
       "\n",
       "      w_df  w_svpt  w_1stIn  w_1stWon  w_2ndWon  w_SvGms  w_bpSaved  \\\n",
       "255    NaN     NaN      NaN       NaN       NaN      NaN        NaN   \n",
       "361    NaN     NaN      NaN       NaN       NaN      NaN        NaN   \n",
       "376    NaN     NaN      NaN       NaN       NaN      NaN        NaN   \n",
       "454    NaN     NaN      NaN       NaN       NaN      NaN        NaN   \n",
       "1258   NaN     NaN      NaN       NaN       NaN      NaN        NaN   \n",
       "\n",
       "      w_bpFaced  l_ace  l_df  l_svpt  l_1stIn  l_1stWon  l_2ndWon  l_SvGms  \\\n",
       "255         NaN    NaN   NaN     NaN      NaN       NaN       NaN      NaN   \n",
       "361         NaN    NaN   NaN     NaN      NaN       NaN       NaN      NaN   \n",
       "376         NaN    NaN   NaN     NaN      NaN       NaN       NaN      NaN   \n",
       "454         NaN    NaN   NaN     NaN      NaN       NaN       NaN      NaN   \n",
       "1258        NaN    NaN   NaN     NaN      NaN       NaN       NaN      NaN   \n",
       "\n",
       "      l_bpSaved  l_bpFaced  winner_rank  winner_rank_points  loser_rank  \\\n",
       "255         NaN        NaN        6.000            5375.000      79.000   \n",
       "361         NaN        NaN       86.000             645.000     191.000   \n",
       "376         NaN        NaN      145.000             373.000      14.000   \n",
       "454         NaN        NaN       79.000             710.000      50.000   \n",
       "1258        NaN        NaN       43.000            1280.000      75.000   \n",
       "\n",
       "      loser_rank_points  \n",
       "255             700.000  \n",
       "361             263.000  \n",
       "376            2325.000  \n",
       "454             977.000  \n",
       "1258            838.000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the matches with 0 or less minutes\n",
    "matches_lessthan_0mins = matches_df.loc[matches_df['minutes']<=0]\n",
    "matches_lessthan_0mins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matches lasting 0 minutes are all W/O (\"Walkovers\"), meaning that one player did not contest the match due to injury, illness, etc. These instances should not be used for predicting matches, as they don't measure a player's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score contains text\n",
    "Sometimes the score feature contains text, like \"RET\" (match retirement), in addition to the previously observation about W/O. If we want to calculate the number of games played, we should remove this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_entry</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>winner_hand</th>\n",
       "      <th>winner_ht</th>\n",
       "      <th>winner_ioc</th>\n",
       "      <th>winner_age</th>\n",
       "      <th>loser_id</th>\n",
       "      <th>loser_seed</th>\n",
       "      <th>loser_entry</th>\n",
       "      <th>loser_name</th>\n",
       "      <th>loser_hand</th>\n",
       "      <th>loser_ht</th>\n",
       "      <th>loser_ioc</th>\n",
       "      <th>loser_age</th>\n",
       "      <th>score</th>\n",
       "      <th>best_of</th>\n",
       "      <th>round</th>\n",
       "      <th>minutes</th>\n",
       "      <th>w_ace</th>\n",
       "      <th>w_df</th>\n",
       "      <th>w_svpt</th>\n",
       "      <th>w_1stIn</th>\n",
       "      <th>w_1stWon</th>\n",
       "      <th>w_2ndWon</th>\n",
       "      <th>w_SvGms</th>\n",
       "      <th>w_bpSaved</th>\n",
       "      <th>w_bpFaced</th>\n",
       "      <th>l_ace</th>\n",
       "      <th>l_df</th>\n",
       "      <th>l_svpt</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>26</td>\n",
       "      <td>102021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael Chang</td>\n",
       "      <td>R</td>\n",
       "      <td>175.000</td>\n",
       "      <td>USA</td>\n",
       "      <td>27.800</td>\n",
       "      <td>101320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Magnus Gustafsson</td>\n",
       "      <td>R</td>\n",
       "      <td>185.000</td>\n",
       "      <td>SWE</td>\n",
       "      <td>33.000</td>\n",
       "      <td>7-5 3-6 1-0 RET</td>\n",
       "      <td>3</td>\n",
       "      <td>QF</td>\n",
       "      <td>113.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>55.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>722.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>626.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2000-306</td>\n",
       "      <td>St. Poelten</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000522</td>\n",
       "      <td>1</td>\n",
       "      <td>102247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andrea Gaudenzi</td>\n",
       "      <td>R</td>\n",
       "      <td>183.000</td>\n",
       "      <td>ITA</td>\n",
       "      <td>26.800</td>\n",
       "      <td>103017</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicolas Kiefer</td>\n",
       "      <td>R</td>\n",
       "      <td>183.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>22.800</td>\n",
       "      <td>6-7(4) 3-0 RET</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>76.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>575.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1874.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2000-306</td>\n",
       "      <td>St. Poelten</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000522</td>\n",
       "      <td>3</td>\n",
       "      <td>102869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Galo Blanco</td>\n",
       "      <td>R</td>\n",
       "      <td>173.000</td>\n",
       "      <td>ESP</td>\n",
       "      <td>23.600</td>\n",
       "      <td>102987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andre Sa</td>\n",
       "      <td>R</td>\n",
       "      <td>185.000</td>\n",
       "      <td>BRA</td>\n",
       "      <td>23.000</td>\n",
       "      <td>6-1 1-0 RET</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>36.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>593.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>481.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2000-308</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000501</td>\n",
       "      <td>3</td>\n",
       "      <td>102562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jiri Novak</td>\n",
       "      <td>R</td>\n",
       "      <td>190.000</td>\n",
       "      <td>CZE</td>\n",
       "      <td>25.100</td>\n",
       "      <td>102783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rainer Schuettler</td>\n",
       "      <td>R</td>\n",
       "      <td>180.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>24.000</td>\n",
       "      <td>6-1 3-2 RET</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>48.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>822.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>583.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2000-308</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000501</td>\n",
       "      <td>5</td>\n",
       "      <td>103163</td>\n",
       "      <td>3.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tommy Haas</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>22.000</td>\n",
       "      <td>102184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>David Prinosil</td>\n",
       "      <td>R</td>\n",
       "      <td>185.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>27.100</td>\n",
       "      <td>6-1 4-2 RET</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>48.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>41.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>41.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>1230.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>418.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n",
       "25   2000-301     Auckland    Hard         32             A      20000110   \n",
       "31   2000-306  St. Poelten    Clay         32             A      20000522   \n",
       "33   2000-306  St. Poelten    Clay         32             A      20000522   \n",
       "64   2000-308       Munich    Clay         32             A      20000501   \n",
       "66   2000-308       Munich    Clay         32             A      20000501   \n",
       "\n",
       "    match_num  winner_id  winner_seed winner_entry      winner_name  \\\n",
       "25         26     102021          NaN          NaN    Michael Chang   \n",
       "31          1     102247          NaN          NaN  Andrea Gaudenzi   \n",
       "33          3     102869          NaN          NaN      Galo Blanco   \n",
       "64          3     102562          NaN          NaN       Jiri Novak   \n",
       "66          5     103163        3.000          NaN       Tommy Haas   \n",
       "\n",
       "   winner_hand  winner_ht winner_ioc  winner_age  loser_id  loser_seed  \\\n",
       "25           R    175.000        USA      27.800    101320         NaN   \n",
       "31           R    183.000        ITA      26.800    103017       1.000   \n",
       "33           R    173.000        ESP      23.600    102987         NaN   \n",
       "64           R    190.000        CZE      25.100    102783         NaN   \n",
       "66           R    188.000        GER      22.000    102184         NaN   \n",
       "\n",
       "   loser_entry         loser_name loser_hand  loser_ht loser_ioc  loser_age  \\\n",
       "25         NaN  Magnus Gustafsson          R   185.000       SWE     33.000   \n",
       "31         NaN     Nicolas Kiefer          R   183.000       GER     22.800   \n",
       "33         NaN           Andre Sa          R   185.000       BRA     23.000   \n",
       "64         NaN  Rainer Schuettler          R   180.000       GER     24.000   \n",
       "66         NaN     David Prinosil          R   185.000       GER     27.100   \n",
       "\n",
       "              score  best_of round  minutes  w_ace  w_df  w_svpt  w_1stIn  \\\n",
       "25  7-5 3-6 1-0 RET        3    QF  113.000  0.000 1.000  68.000   35.000   \n",
       "31   6-7(4) 3-0 RET        3   R32   76.000  1.000 3.000  50.000   35.000   \n",
       "33      6-1 1-0 RET        3   R32   36.000  1.000 0.000  21.000   12.000   \n",
       "64      6-1 3-2 RET        3   R32   48.000  1.000 1.000  36.000   25.000   \n",
       "66      6-1 4-2 RET        3   R32   48.000  5.000 2.000  41.000   23.000   \n",
       "\n",
       "    w_1stWon  w_2ndWon  w_SvGms  w_bpSaved  w_bpFaced  l_ace  l_df  l_svpt  \\\n",
       "25    24.000    16.000   12.000      6.000      9.000  6.000 6.000  85.000   \n",
       "31    19.000     8.000    8.000      4.000      8.000  0.000 4.000  53.000   \n",
       "33     7.000     7.000    5.000      0.000      1.000  0.000 3.000  25.000   \n",
       "64    21.000     7.000    6.000      1.000      1.000  2.000 3.000  47.000   \n",
       "66    18.000    10.000    7.000      3.000      4.000  2.000 2.000  41.000   \n",
       "\n",
       "    l_1stIn  l_1stWon  l_2ndWon  l_SvGms  l_bpSaved  l_bpFaced  winner_rank  \\\n",
       "25   55.000    37.000    14.000   11.000      9.000     12.000       50.000   \n",
       "31   24.000    11.000    12.000    8.000      5.000     10.000       74.000   \n",
       "33   11.000     4.000     4.000    4.000      0.000      4.000       70.000   \n",
       "64   27.000    18.000     6.000    7.000      5.000      8.000       42.000   \n",
       "66   22.000    12.000     7.000    7.000      1.000      5.000       19.000   \n",
       "\n",
       "    winner_rank_points  loser_rank  loser_rank_points  \n",
       "25             722.000      60.000            626.000  \n",
       "31             575.000       8.000           1874.000  \n",
       "33             593.000      86.000            481.000  \n",
       "64             822.000      68.000            583.000  \n",
       "66            1230.000      94.000            418.000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_score_text = matches_df[matches_df['score'].str.contains('[a-zA-Z]')]\n",
    "matches_score_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN or empty values\n",
    "Here we check for NaN or empty values in the matches mframe, in order to decide what to do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_id                0\n",
       "tourney_name              0\n",
       "surface                   0\n",
       "draw_size                 0\n",
       "tourney_level             0\n",
       "tourney_date              0\n",
       "match_num                 0\n",
       "winner_id                 0\n",
       "winner_seed           41627\n",
       "winner_entry          62269\n",
       "winner_name               0\n",
       "winner_hand               9\n",
       "winner_ht              1631\n",
       "winner_ioc                0\n",
       "winner_age                5\n",
       "loser_id                  0\n",
       "loser_seed            54883\n",
       "loser_entry           56629\n",
       "loser_name                0\n",
       "loser_hand               42\n",
       "loser_ht               3274\n",
       "loser_ioc                 0\n",
       "loser_age                 6\n",
       "score                     0\n",
       "best_of                   0\n",
       "round                     0\n",
       "minutes                7936\n",
       "w_ace                  6402\n",
       "w_df                   6402\n",
       "w_svpt                 6402\n",
       "w_1stIn                6402\n",
       "w_1stWon               6402\n",
       "w_2ndWon               6402\n",
       "w_SvGms                6401\n",
       "w_bpSaved              6402\n",
       "w_bpFaced              6402\n",
       "l_ace                  6402\n",
       "l_df                   6402\n",
       "l_svpt                 6402\n",
       "l_1stIn                6402\n",
       "l_1stWon               6402\n",
       "l_2ndWon               6402\n",
       "l_SvGms                6401\n",
       "l_bpSaved              6402\n",
       "l_bpFaced              6402\n",
       "winner_rank             547\n",
       "winner_rank_points      547\n",
       "loser_rank             1420\n",
       "loser_rank_points      1420\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all features for empty values\n",
    "empty_count_per_feature= matches_df.isnull().sum()\n",
    "empty_count_per_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the features starting with \"w_\" or \"l_\", there are 8 features in the matches dataset which have empty values, and indication whether this will be used for prediction or not:\n",
    "1. minutes - not used\n",
    "2. seed - not used\n",
    "3. entry - not used\n",
    "4. hand - not used\n",
    "5. ht (height) - not used\n",
    "6. age - not used\n",
    "7. rank - used\n",
    "8. rank_points - not used\n",
    "\n",
    "Of these 8 features, only 1 will be used: rank. Let's explore a few of these matches with an empty rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_entry</th>\n",
       "      <th>winner_name</th>\n",
       "      <th>winner_hand</th>\n",
       "      <th>winner_ht</th>\n",
       "      <th>winner_ioc</th>\n",
       "      <th>winner_age</th>\n",
       "      <th>loser_id</th>\n",
       "      <th>loser_seed</th>\n",
       "      <th>loser_entry</th>\n",
       "      <th>loser_name</th>\n",
       "      <th>loser_hand</th>\n",
       "      <th>loser_ht</th>\n",
       "      <th>loser_ioc</th>\n",
       "      <th>loser_age</th>\n",
       "      <th>score</th>\n",
       "      <th>best_of</th>\n",
       "      <th>round</th>\n",
       "      <th>minutes</th>\n",
       "      <th>w_ace</th>\n",
       "      <th>w_df</th>\n",
       "      <th>w_svpt</th>\n",
       "      <th>w_1stIn</th>\n",
       "      <th>w_1stWon</th>\n",
       "      <th>w_2ndWon</th>\n",
       "      <th>w_SvGms</th>\n",
       "      <th>w_bpSaved</th>\n",
       "      <th>w_bpFaced</th>\n",
       "      <th>l_ace</th>\n",
       "      <th>l_df</th>\n",
       "      <th>l_svpt</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2000-308</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000501</td>\n",
       "      <td>14</td>\n",
       "      <td>210013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martin Damm Sr</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>CZE</td>\n",
       "      <td>27.700</td>\n",
       "      <td>102563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thomas Johansson</td>\n",
       "      <td>R</td>\n",
       "      <td>180.000</td>\n",
       "      <td>SWE</td>\n",
       "      <td>25.100</td>\n",
       "      <td>6-7(6) 7-6(5) 6-3</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>153.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>119.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.000</td>\n",
       "      <td>663.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2000-308</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000501</td>\n",
       "      <td>23</td>\n",
       "      <td>102644</td>\n",
       "      <td>7.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franco Squillari</td>\n",
       "      <td>L</td>\n",
       "      <td>183.000</td>\n",
       "      <td>ARG</td>\n",
       "      <td>24.600</td>\n",
       "      <td>210013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martin Damm Sr</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>CZE</td>\n",
       "      <td>27.700</td>\n",
       "      <td>6-2 6-2</td>\n",
       "      <td>3</td>\n",
       "      <td>R16</td>\n",
       "      <td>64.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>51.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>733.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2000-316</td>\n",
       "      <td>Bastad</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000710</td>\n",
       "      <td>15</td>\n",
       "      <td>103182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Markus Hipfl</td>\n",
       "      <td>R</td>\n",
       "      <td>178.000</td>\n",
       "      <td>AUT</td>\n",
       "      <td>22.200</td>\n",
       "      <td>104026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WC</td>\n",
       "      <td>Joachim Johansson</td>\n",
       "      <td>R</td>\n",
       "      <td>198.000</td>\n",
       "      <td>SWE</td>\n",
       "      <td>18.000</td>\n",
       "      <td>6-3 RET</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>34.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>103.000</td>\n",
       "      <td>388.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2000-338</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>9</td>\n",
       "      <td>102344</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Karol Kucera</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>SVK</td>\n",
       "      <td>25.800</td>\n",
       "      <td>210013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martin Damm Sr</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>CZE</td>\n",
       "      <td>27.400</td>\n",
       "      <td>7-6(3) 6-1</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>69.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1346.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2000-359</td>\n",
       "      <td>Bogota</td>\n",
       "      <td>Clay</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000306</td>\n",
       "      <td>3</td>\n",
       "      <td>103082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Markus Hantschk</td>\n",
       "      <td>R</td>\n",
       "      <td>188.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>22.200</td>\n",
       "      <td>101991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mauricio Hadad</td>\n",
       "      <td>R</td>\n",
       "      <td>170.000</td>\n",
       "      <td>COL</td>\n",
       "      <td>28.200</td>\n",
       "      <td>4-6 6-0 6-4</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>110.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>76.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>391.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n",
       "75    2000-308       Munich    Clay         32             A      20000501   \n",
       "84    2000-308       Munich    Clay         32             A      20000501   \n",
       "224   2000-316       Bastad    Clay         32             A      20000710   \n",
       "568   2000-338       Sydney    Hard         32             A      20000110   \n",
       "718   2000-359       Bogota    Clay         32             A      20000306   \n",
       "\n",
       "     match_num  winner_id  winner_seed winner_entry       winner_name  \\\n",
       "75          14     210013          NaN          NaN    Martin Damm Sr   \n",
       "84          23     102644        7.000          NaN  Franco Squillari   \n",
       "224         15     103182          NaN            Q      Markus Hipfl   \n",
       "568          9     102344        5.000          NaN      Karol Kucera   \n",
       "718          3     103082          NaN          NaN   Markus Hantschk   \n",
       "\n",
       "    winner_hand  winner_ht winner_ioc  winner_age  loser_id  loser_seed  \\\n",
       "75            R    188.000        CZE      27.700    102563         NaN   \n",
       "84            L    183.000        ARG      24.600    210013         NaN   \n",
       "224           R    178.000        AUT      22.200    104026         NaN   \n",
       "568           R    188.000        SVK      25.800    210013         NaN   \n",
       "718           R    188.000        GER      22.200    101991         NaN   \n",
       "\n",
       "    loser_entry         loser_name loser_hand  loser_ht loser_ioc  loser_age  \\\n",
       "75          NaN   Thomas Johansson          R   180.000       SWE     25.100   \n",
       "84          NaN     Martin Damm Sr          R   188.000       CZE     27.700   \n",
       "224          WC  Joachim Johansson          R   198.000       SWE     18.000   \n",
       "568         NaN     Martin Damm Sr          R   188.000       CZE     27.400   \n",
       "718           Q     Mauricio Hadad          R   170.000       COL     28.200   \n",
       "\n",
       "                 score  best_of round  minutes  w_ace  w_df  w_svpt  w_1stIn  \\\n",
       "75   6-7(6) 7-6(5) 6-3        3   R32  153.000 16.000 0.000 105.000   69.000   \n",
       "84             6-2 6-2        3   R16   64.000  2.000 2.000  51.000   26.000   \n",
       "224            6-3 RET        3   R32   34.000  3.000 0.000  21.000   14.000   \n",
       "568         7-6(3) 6-1        3   R32   69.000  4.000 2.000  48.000   28.000   \n",
       "718        4-6 6-0 6-4        3   R32  110.000  2.000 4.000  79.000   32.000   \n",
       "\n",
       "     w_1stWon  w_2ndWon  w_SvGms  w_bpSaved  w_bpFaced  l_ace  l_df  l_svpt  \\\n",
       "75     57.000    22.000   17.000      1.000      1.000 11.000 2.000 119.000   \n",
       "84     19.000    16.000    8.000      3.000      3.000  2.000 2.000  49.000   \n",
       "224    12.000     4.000    5.000      0.000      0.000  2.000 0.000  26.000   \n",
       "568    25.000    16.000    9.000      0.000      0.000  1.000 3.000  67.000   \n",
       "718    21.000    22.000   13.000      2.000      6.000  2.000 1.000  76.000   \n",
       "\n",
       "     l_1stIn  l_1stWon  l_2ndWon  l_SvGms  l_bpSaved  l_bpFaced  winner_rank  \\\n",
       "75    59.000    46.000    34.000   16.000      9.000     10.000          NaN   \n",
       "84    28.000    16.000     8.000    8.000      2.000      6.000       52.000   \n",
       "224    8.000     6.000     7.000    5.000      0.000      2.000      103.000   \n",
       "568   35.000    25.000    15.000   10.000      7.000     10.000       17.000   \n",
       "718   40.000    17.000    18.000   13.000      7.000     14.000      105.000   \n",
       "\n",
       "     winner_rank_points  loser_rank  loser_rank_points  \n",
       "75                  NaN      58.000            663.000  \n",
       "84              733.000         NaN                NaN  \n",
       "224             388.000         NaN                NaN  \n",
       "568            1346.000         NaN                NaN  \n",
       "718             391.000         NaN                NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the matches with empty rank\n",
    "matches_empty_rank = matches_df.loc[matches_df['winner_rank'].isnull() | matches_df['loser_rank'].isnull()]\n",
    "matches_empty_rank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matches with players having no (empty) rank could be because they are new, or have been inactive due to injury and hence lost their ranking before returning. We can try and look up their last valid ranking in the rankings file later. \n",
    "\n",
    "Next, do the values for rank make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matches_with_rank = matches_df.loc[~matches_df['winner_rank'].isnull() & ~matches_df['loser_rank'].isnull()]\n",
    "\n",
    "# Plot 2 histograms for distribution of values for \"rank\"\n",
    "# Create subplots for the histograms\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Plot the first histogram for winner_rank\n",
    "ax1.hist(matches_with_rank['winner_rank'], bins=20, color='blue', alpha=0.7)\n",
    "ax1.set_title('Distribution of winner rank')\n",
    "ax1.set_xlabel('Rank')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Plot the second histogram for loser_rank\n",
    "ax2.hist(matches_with_rank['loser_rank'], bins=20, color='green', alpha=0.7)\n",
    "ax2.set_title('Distribution of loser rank')\n",
    "ax2.set_xlabel('Rank')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "# Display the histograms\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that most matches are won by players ranked in the top 100 (~60'000), which makes sense. Also, there are no outlier values like rank=5'000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could matches with empty minutes be due to the tourney_level?\n",
    "# print(matches_empty_minutes['tourney_level'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tournament start dates\n",
    "It would be interesting to see on which weekdays tournaments start. Becuase later, we want to link the rankings data with the matches data, so a common day of the week  would be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_date_dt_day_name\n",
       "Monday      0.809\n",
       "Friday      0.088\n",
       "Sunday      0.074\n",
       "Thursday    0.013\n",
       "Wednesday   0.011\n",
       "Saturday    0.004\n",
       "Tuesday     0.001\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert date from tourney_date \n",
    "matches_tournament_starts = matches_df.copy()\n",
    "matches_tournament_starts['tourney_date_dt'] = pd.to_datetime(matches_df['tourney_date'], format='%Y%m%d')\n",
    "\n",
    "# create a column representing the day of the week\n",
    "matches_tournament_starts['tourney_date_dt_day_name'] = matches_tournament_starts['tourney_date_dt'].dt.day_name()\n",
    "\n",
    "# day of week frequency for matches and rankingsday of week frequency for matches and rankings\n",
    "matches_tournament_starts['tourney_date_dt_day_name'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, ca. **81%** of the matches started on a Monday. This is a strong case to say that for simplicity, we set all matches to start at the beginning of the week which would be Monday. But before doing this, let's see which matches don't start on a Monday and group by tournament type, then display the results using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group the matches_tournament_starts by 'tourney_level' and 'tourney_date_dt_day_name' and count the occurrences\n",
    "matches_tournament_starts = matches_tournament_starts.groupby(['tourney_level', 'tourney_date_dt_day_name']).size().unstack().fillna(0)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "matches_tournament_starts.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Tournament Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Tournament Start Weekday by Tournament Type')\n",
    "\n",
    "# Display the legend\n",
    "plt.legend(title='Tournament Start Weekday', loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [matches_data_dictionary.txt](data/matches_data_dictionary.txt):\n",
    "- 'G' = Grand Slams\n",
    "- 'M' = Masters 1000s\n",
    "- 'A' = other tour-level events\n",
    "- 'C' = Challengers\n",
    "- 'S' = Satellites/ITFs\n",
    "- 'F' = Tour finals and other season-ending events\n",
    "- 'D' = Davis Cup \n",
    "\n",
    "Most tournaments start on a Monday, with a notable exception: Davis Cup, which are run over weekends and start on a Friday. \n",
    "**Decision**: For better linking with rankings, we've decided that we will set all tournaments' start dates to the Monday which precedes it. For example, if its Friday yyyy-mm-dd, then a supplemental date feature will be provided for its preceding Monday yyyy-mm-dd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction benchmark for matches\n",
    "In order to evaluate the prediction accuracy of our model, we need a benchmark to compare when predicting the results of matches. One simple benchmark would be to assume that the higher (i.e. closer to 1) ranked player will always win. This \"higher-ranked player win ratio\" can easily be calculated using the features available in the original dataset.\n",
    "We know that some rankings are empty, so we will just substitute a number higher than the max. ranking (which is 2101)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winning_player_ranked\n",
       "higher   65.638\n",
       "lower    34.362\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting a prediction benchmark, empty ranking means no ranking, so replace with a arbitrary high value\n",
    "matches_wins_by_ranking_df = matches_df.copy()\n",
    "matches_wins_by_ranking_df[['winner_rank','loser_rank']] = matches_wins_by_ranking_df[['winner_rank','loser_rank']].fillna(value=10000)\n",
    "\n",
    "# add a new feature which is the result of checking whether the winner was ranked higher (i.e. closer to 1) than the loser\n",
    "matches_wins_by_ranking_df['winning_player_ranked'] = matches_wins_by_ranking_df.apply(lambda x: \"higher\" if x['winner_rank'] < x['loser_rank'] else \"lower\", axis=1)\n",
    "matches_wins_by_ranking_df['winning_player_ranked'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that for our dataset, the higher ranked player won **65.6%** of all the matches. This will be our benchmark for evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load rankings\n",
    "Data is also available in the form of ranking of ATP players. It may be required to supplement the missing data for current rankings in the matches dataset, for example, a player doesn't have a ranking at the time of playing a match. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the rankings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of rankings (since the year 2000 ) files to load\n",
    "atp_rankings_files = [f'{DIRNAME}/atp_rankings_{year}.csv' for year in ['00s','10s', '20s', 'current']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to store all rankings\n",
    "rankings_df = pd.DataFrame()\n",
    "\n",
    "# loop through the list of rankings files, read them and append the data to the combined DataFrame\n",
    "for filen in atp_rankings_files:\n",
    "    rankings_df = pd.concat([rankings_df, pd.read_csv(filen, index_col=None)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking_date</th>\n",
       "      <th>rank</th>\n",
       "      <th>player</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000110</td>\n",
       "      <td>1</td>\n",
       "      <td>101736</td>\n",
       "      <td>4135.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000110</td>\n",
       "      <td>2</td>\n",
       "      <td>102338</td>\n",
       "      <td>2915.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000110</td>\n",
       "      <td>3</td>\n",
       "      <td>101948</td>\n",
       "      <td>2419.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000110</td>\n",
       "      <td>4</td>\n",
       "      <td>103017</td>\n",
       "      <td>2184.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000110</td>\n",
       "      <td>5</td>\n",
       "      <td>102856</td>\n",
       "      <td>2169.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking_date  rank  player   points\n",
       "0      20000110     1  101736 4135.000\n",
       "1      20000110     2  102338 2915.000\n",
       "2      20000110     3  101948 2419.000\n",
       "3      20000110     4  103017 2184.000\n",
       "4      20000110     5  102856 2169.000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the rankings data\n",
    "rankings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2140631 entries, 0 to 58510\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ranking_date  int64  \n",
      " 1   rank          int64  \n",
      " 2   player        int64  \n",
      " 3   points        float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 81.7 MB\n"
     ]
    }
   ],
   "source": [
    "# get an overview of number of features, instances, empty values and data types \n",
    "rankings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking_date</th>\n",
       "      <th>rank</th>\n",
       "      <th>player</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2140631.000</td>\n",
       "      <td>2140631.000</td>\n",
       "      <td>2140631.000</td>\n",
       "      <td>2139882.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20112972.331</td>\n",
       "      <td>941.096</td>\n",
       "      <td>119768.989</td>\n",
       "      <td>117.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>66763.213</td>\n",
       "      <td>547.581</td>\n",
       "      <td>31216.724</td>\n",
       "      <td>455.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20000110.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>100149.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20060213.000</td>\n",
       "      <td>470.000</td>\n",
       "      <td>104128.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20110919.000</td>\n",
       "      <td>946.000</td>\n",
       "      <td>105498.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20170306.000</td>\n",
       "      <td>1381.000</td>\n",
       "      <td>120568.000</td>\n",
       "      <td>65.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20230911.000</td>\n",
       "      <td>2271.000</td>\n",
       "      <td>212464.000</td>\n",
       "      <td>16950.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ranking_date        rank      player      points\n",
       "count   2140631.000 2140631.000 2140631.000 2139882.000\n",
       "mean   20112972.331     941.096  119768.989     117.056\n",
       "std       66763.213     547.581   31216.724     455.880\n",
       "min    20000110.000       1.000  100149.000       1.000\n",
       "25%    20060213.000     470.000  104128.000       2.000\n",
       "50%    20110919.000     946.000  105498.000      10.000\n",
       "75%    20170306.000    1381.000  120568.000      65.000\n",
       "max    20230911.000    2271.000  212464.000   16950.000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks on the data (min values, max values, etc.)\n",
    "rankings_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, the min and max values for the rankings make sense. Also, the ranking_date makes sense. Finally, there are no missing values, so no data cleaning is required on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of instances and features: (2140631, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of instances and features: \" + str(rankings_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking dates\n",
    "Similar to which weekdays tournaments start, let's look at the days on which the rankings get updated. Becuase later, we want to link the rankings data with the matches data, so a common day of the week  would be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranking_date_dt_day_name\n",
       "Monday   1.000\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert date from ranking_date \n",
    "ranking_update = rankings_df.copy()\n",
    "ranking_update['ranking_date_dt'] = pd.to_datetime(rankings_df['ranking_date'], format='%Y%m%d')\n",
    "\n",
    "# create a column representing the day of the week\n",
    "ranking_update['ranking_date_dt_day_name'] = ranking_update['ranking_date_dt'].dt.day_name()\n",
    "\n",
    "# day of week frequency for ranking\n",
    "ranking_update['ranking_date_dt_day_name'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All (100%)** of the rankings are updated on a Monday. Therefore, we are aligned with the idea to set all tournament start dates to a Monday.\n",
    "\n",
    "Below is a final view of the loaded data for rankings, with the new column for the datetime formatted `ranking_date_dt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2140631 entries, 0 to 58510\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ranking_date  int64  \n",
      " 1   rank          int64  \n",
      " 2   player        int64  \n",
      " 3   points        float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 81.7 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking_date</th>\n",
       "      <th>rank</th>\n",
       "      <th>player</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000110</td>\n",
       "      <td>1</td>\n",
       "      <td>101736</td>\n",
       "      <td>4135.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000110</td>\n",
       "      <td>2</td>\n",
       "      <td>102338</td>\n",
       "      <td>2915.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000110</td>\n",
       "      <td>3</td>\n",
       "      <td>101948</td>\n",
       "      <td>2419.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000110</td>\n",
       "      <td>4</td>\n",
       "      <td>103017</td>\n",
       "      <td>2184.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000110</td>\n",
       "      <td>5</td>\n",
       "      <td>102856</td>\n",
       "      <td>2169.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking_date  rank  player   points\n",
       "0      20000110     1  101736 4135.000\n",
       "1      20000110     2  102338 2915.000\n",
       "2      20000110     3  101948 2419.000\n",
       "3      20000110     4  103017 2184.000\n",
       "4      20000110     5  102856 2169.000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "print(rankings_df.info())\n",
    "\n",
    "# preview data\n",
    "rankings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing and cleaning\n",
    "\n",
    "### Scope of processing and cleaning\n",
    "1. Replace the matches' winner and loser columns\n",
    "2. Clean the date features and make them consistent\n",
    "3. Ensure the matches are sorted as needed\n",
    "4. Remove matches with result as W/O\n",
    "5. Players without rankings: \n",
    "- seasoned players  (they had a long layoff due to injury, etc.). keep match and lookup ranking from earlier. Apply penalty of 10 ranking places for each week they were absent.\n",
    "- if they played less than 10 matches (cumulative) - remove match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the processing and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with a copy of the original loaded dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 71213 entries, 0 to 2368\n",
      "Data columns (total 49 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tourney_id          71213 non-null  object \n",
      " 1   tourney_name        71213 non-null  object \n",
      " 2   surface             71213 non-null  object \n",
      " 3   draw_size           71213 non-null  int64  \n",
      " 4   tourney_level       71213 non-null  object \n",
      " 5   tourney_date        71213 non-null  int64  \n",
      " 6   match_num           71213 non-null  int64  \n",
      " 7   winner_id           71213 non-null  int64  \n",
      " 8   winner_seed         29586 non-null  float64\n",
      " 9   winner_entry        8944 non-null   object \n",
      " 10  winner_name         71213 non-null  object \n",
      " 11  winner_hand         71204 non-null  object \n",
      " 12  winner_ht           69582 non-null  float64\n",
      " 13  winner_ioc          71213 non-null  object \n",
      " 14  winner_age          71208 non-null  float64\n",
      " 15  loser_id            71213 non-null  int64  \n",
      " 16  loser_seed          16330 non-null  float64\n",
      " 17  loser_entry         14584 non-null  object \n",
      " 18  loser_name          71213 non-null  object \n",
      " 19  loser_hand          71171 non-null  object \n",
      " 20  loser_ht            67939 non-null  float64\n",
      " 21  loser_ioc           71213 non-null  object \n",
      " 22  loser_age           71207 non-null  float64\n",
      " 23  score               71213 non-null  object \n",
      " 24  best_of             71213 non-null  int64  \n",
      " 25  round               71213 non-null  object \n",
      " 26  minutes             63277 non-null  float64\n",
      " 27  w_ace               64811 non-null  float64\n",
      " 28  w_df                64811 non-null  float64\n",
      " 29  w_svpt              64811 non-null  float64\n",
      " 30  w_1stIn             64811 non-null  float64\n",
      " 31  w_1stWon            64811 non-null  float64\n",
      " 32  w_2ndWon            64811 non-null  float64\n",
      " 33  w_SvGms             64812 non-null  float64\n",
      " 34  w_bpSaved           64811 non-null  float64\n",
      " 35  w_bpFaced           64811 non-null  float64\n",
      " 36  l_ace               64811 non-null  float64\n",
      " 37  l_df                64811 non-null  float64\n",
      " 38  l_svpt              64811 non-null  float64\n",
      " 39  l_1stIn             64811 non-null  float64\n",
      " 40  l_1stWon            64811 non-null  float64\n",
      " 41  l_2ndWon            64811 non-null  float64\n",
      " 42  l_SvGms             64812 non-null  float64\n",
      " 43  l_bpSaved           64811 non-null  float64\n",
      " 44  l_bpFaced           64811 non-null  float64\n",
      " 45  winner_rank         70666 non-null  float64\n",
      " 46  winner_rank_points  70666 non-null  float64\n",
      " 47  loser_rank          69793 non-null  float64\n",
      " 48  loser_rank_points   69793 non-null  float64\n",
      "dtypes: float64(29), int64(6), object(14)\n",
      "memory usage: 27.2+ MB\n"
     ]
    }
   ],
   "source": [
    "matches_processed_df = matches_df.copy()\n",
    "matches_processed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2140631 entries, 0 to 58510\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ranking_date  int64  \n",
      " 1   rank          int64  \n",
      " 2   player        int64  \n",
      " 3   points        float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 81.7 MB\n"
     ]
    }
   ],
   "source": [
    "rankings_processed_df = rankings_df.copy()\n",
    "rankings_processed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hide winner and loser from columns names\n",
    "Replace columns starting with 'winner_' and 'loser_' with 'player_1_' and 'player_2_' for the required features. As we want to be able to predict who will be the winner and the loser in each match, we remove the 'winner_' and 'loser_' columns for each match, and instead replace it with player_1_ and player_2 according to which the ranking of the players. \n",
    "\n",
    "The features starting with 'w_' and 'l_' are measures recorded during the match and will not be used in the model for predicting the outcome, so we remove these features.\n",
    "We will add a column at the end of the dataframe, which will serve as our y variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_winner_loser(input_df):\n",
    "    # List of required features to be replaced with prefixes player_1 and player_2\n",
    "    features = ['id', 'seed', 'entry', 'name', 'hand', 'ht', 'ioc', 'age', 'rank', 'rank_points']\n",
    "    \n",
    "    # Copy the input DataFrame to a new one\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Add player_1_name and player_2_name columns based on higher rank\n",
    "    df['player_1_name'] = np.where((df['winner_rank'].fillna(float('inf')) <= df['loser_rank'].fillna(float('inf'))),\n",
    "                                   df['winner_name'],\n",
    "                                   df['loser_name']\n",
    "                                   )\n",
    "    df['player_2_name'] = np.where((df['winner_rank'].fillna(float('inf')) > df['loser_rank'].fillna(float('inf'))),\n",
    "                                   df['winner_name'],\n",
    "                                   df['loser_name']\n",
    "                                   )\n",
    "\n",
    "    # Transfer the values from 'winner_' and 'loser_' features to 'player_1_' and 'player_2_' features, according to who was the winner & loser\n",
    "    for feat in features:\n",
    "        player_1_feature = np.where(df['player_1_name'] == df['winner_name'],\n",
    "                                    df['winner_' + feat],\n",
    "                                    df['loser_' + feat]\n",
    "                                    )\n",
    "        player_2_feature = np.where(df['player_2_name'] == df['winner_name'],\n",
    "                                    df['winner_' + feat],\n",
    "                                    df['loser_' + feat]\n",
    "                                    )\n",
    "        df['player_1_' + feat] = player_1_feature\n",
    "        df['player_2_' + feat] = player_2_feature   \n",
    "\n",
    "          \n",
    "    # Add a winner column\n",
    "    df['winner'] = df.apply(lambda row: 'player_1' if row['winner_name'] == row['player_1_name'] else 'player_2', axis=1)\n",
    "\n",
    "    # Remove columns starting with 'winner_' and 'loser_' (they have been replaced by player_1_ and player_2_)\n",
    "    df = df.loc[:, ~df.columns.str.startswith('winner_') & ~df.columns.str.startswith('loser_')]\n",
    "\n",
    "    # Remove columns starting with 'w_' and 'l_' (not needed for predicting_)\n",
    "    df = df.loc[:, ~df.columns.str.startswith('w_') & ~df.columns.str.startswith('l_')]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the function hide_winner_loser with a sample dataset of 5 instances. Observe the renamed features, from \"winnner_\" and \"loser_\" to \"player_1\" and \" player_2\", and the new feature called \"winner\" (our y variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 32 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   tourney_id            5 non-null      object \n",
      " 1   tourney_name          5 non-null      object \n",
      " 2   surface               5 non-null      object \n",
      " 3   draw_size             5 non-null      int64  \n",
      " 4   tourney_level         5 non-null      object \n",
      " 5   tourney_date          5 non-null      int64  \n",
      " 6   match_num             5 non-null      int64  \n",
      " 7   score                 5 non-null      object \n",
      " 8   best_of               5 non-null      int64  \n",
      " 9   round                 5 non-null      object \n",
      " 10  minutes               5 non-null      float64\n",
      " 11  player_1_name         5 non-null      object \n",
      " 12  player_2_name         5 non-null      object \n",
      " 13  player_1_id           5 non-null      int64  \n",
      " 14  player_2_id           5 non-null      int64  \n",
      " 15  player_1_seed         3 non-null      float64\n",
      " 16  player_2_seed         0 non-null      float64\n",
      " 17  player_1_entry        0 non-null      object \n",
      " 18  player_2_entry        2 non-null      object \n",
      " 19  player_1_hand         5 non-null      object \n",
      " 20  player_2_hand         5 non-null      object \n",
      " 21  player_1_ht           5 non-null      float64\n",
      " 22  player_2_ht           5 non-null      float64\n",
      " 23  player_1_ioc          5 non-null      object \n",
      " 24  player_2_ioc          5 non-null      object \n",
      " 25  player_1_age          5 non-null      float64\n",
      " 26  player_2_age          5 non-null      float64\n",
      " 27  player_1_rank         5 non-null      float64\n",
      " 28  player_2_rank         5 non-null      float64\n",
      " 29  player_1_rank_points  5 non-null      float64\n",
      " 30  player_2_rank_points  5 non-null      float64\n",
      " 31  winner                5 non-null      object \n",
      "dtypes: float64(11), int64(6), object(15)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "output_df = hide_winner_loser(sample_matches_df)\n",
    "output_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_2_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Tommy Haas</td>\n",
       "      <td>11.000</td>\n",
       "      <td>Jeff Tarango</td>\n",
       "      <td>63.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Franco Squillari</td>\n",
       "      <td>49.000</td>\n",
       "      <td>Juan Balcells</td>\n",
       "      <td>211.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Alberto Martin</td>\n",
       "      <td>48.000</td>\n",
       "      <td>Alberto Berasategui</td>\n",
       "      <td>59.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Juan Carlos Ferrero</td>\n",
       "      <td>45.000</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>61.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Nicolas Escude</td>\n",
       "      <td>34.000</td>\n",
       "      <td>Michael Sell</td>\n",
       "      <td>167.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_id        player_1_name  player_1_rank        player_2_name  \\\n",
       "0   2000-301           Tommy Haas         11.000         Jeff Tarango   \n",
       "1   2000-301     Franco Squillari         49.000        Juan Balcells   \n",
       "2   2000-301       Alberto Martin         48.000  Alberto Berasategui   \n",
       "3   2000-301  Juan Carlos Ferrero         45.000        Roger Federer   \n",
       "4   2000-301       Nicolas Escude         34.000         Michael Sell   \n",
       "\n",
       "   player_2_rank  \n",
       "0         63.000  \n",
       "1        211.000  \n",
       "2         59.000  \n",
       "3         61.000  \n",
       "4        167.000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df[['tourney_id'\n",
    "           , 'player_1_name', 'player_1_rank'\n",
    "           , 'player_2_name', 'player_2_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>score</th>\n",
       "      <th>best_of</th>\n",
       "      <th>round</th>\n",
       "      <th>minutes</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_1_id</th>\n",
       "      <th>player_2_id</th>\n",
       "      <th>player_1_seed</th>\n",
       "      <th>player_2_seed</th>\n",
       "      <th>player_1_entry</th>\n",
       "      <th>player_2_entry</th>\n",
       "      <th>player_1_hand</th>\n",
       "      <th>player_2_hand</th>\n",
       "      <th>player_1_ht</th>\n",
       "      <th>player_2_ht</th>\n",
       "      <th>player_1_ioc</th>\n",
       "      <th>player_2_ioc</th>\n",
       "      <th>player_1_age</th>\n",
       "      <th>player_2_age</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_rank</th>\n",
       "      <th>player_1_rank_points</th>\n",
       "      <th>player_2_rank_points</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>1</td>\n",
       "      <td>7-5 4-6 7-5</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>108.000</td>\n",
       "      <td>Tommy Haas</td>\n",
       "      <td>Jeff Tarango</td>\n",
       "      <td>103163</td>\n",
       "      <td>101543</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>188.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>GER</td>\n",
       "      <td>USA</td>\n",
       "      <td>21.700</td>\n",
       "      <td>31.100</td>\n",
       "      <td>11.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>1612.000</td>\n",
       "      <td>595.000</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>2</td>\n",
       "      <td>7-5 7-5</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>85.000</td>\n",
       "      <td>Franco Squillari</td>\n",
       "      <td>Juan Balcells</td>\n",
       "      <td>102644</td>\n",
       "      <td>102607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>L</td>\n",
       "      <td>R</td>\n",
       "      <td>183.000</td>\n",
       "      <td>190.000</td>\n",
       "      <td>ARG</td>\n",
       "      <td>ESP</td>\n",
       "      <td>24.300</td>\n",
       "      <td>24.500</td>\n",
       "      <td>49.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>723.000</td>\n",
       "      <td>157.000</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>3</td>\n",
       "      <td>6-3 6-1</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>56.000</td>\n",
       "      <td>Alberto Martin</td>\n",
       "      <td>Alberto Berasategui</td>\n",
       "      <td>103252</td>\n",
       "      <td>102238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>175.000</td>\n",
       "      <td>173.000</td>\n",
       "      <td>ESP</td>\n",
       "      <td>ESP</td>\n",
       "      <td>21.300</td>\n",
       "      <td>26.500</td>\n",
       "      <td>48.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>726.000</td>\n",
       "      <td>649.000</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>4</td>\n",
       "      <td>6-4 6-4</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>68.000</td>\n",
       "      <td>Juan Carlos Ferrero</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>103507</td>\n",
       "      <td>103819</td>\n",
       "      <td>7.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>183.000</td>\n",
       "      <td>185.000</td>\n",
       "      <td>ESP</td>\n",
       "      <td>SUI</td>\n",
       "      <td>19.900</td>\n",
       "      <td>18.400</td>\n",
       "      <td>45.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>616.000</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-301</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000110</td>\n",
       "      <td>5</td>\n",
       "      <td>0-6 7-6(7) 6-1</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>115.000</td>\n",
       "      <td>Nicolas Escude</td>\n",
       "      <td>Michael Sell</td>\n",
       "      <td>102765</td>\n",
       "      <td>102103</td>\n",
       "      <td>4.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>185.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>FRA</td>\n",
       "      <td>USA</td>\n",
       "      <td>23.700</td>\n",
       "      <td>27.300</td>\n",
       "      <td>34.000</td>\n",
       "      <td>167.000</td>\n",
       "      <td>873.000</td>\n",
       "      <td>219.000</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n",
       "0   2000-301     Auckland    Hard         32             A      20000110   \n",
       "1   2000-301     Auckland    Hard         32             A      20000110   \n",
       "2   2000-301     Auckland    Hard         32             A      20000110   \n",
       "3   2000-301     Auckland    Hard         32             A      20000110   \n",
       "4   2000-301     Auckland    Hard         32             A      20000110   \n",
       "\n",
       "   match_num           score  best_of round  minutes        player_1_name  \\\n",
       "0          1     7-5 4-6 7-5        3   R32  108.000           Tommy Haas   \n",
       "1          2         7-5 7-5        3   R32   85.000     Franco Squillari   \n",
       "2          3         6-3 6-1        3   R32   56.000       Alberto Martin   \n",
       "3          4         6-4 6-4        3   R32   68.000  Juan Carlos Ferrero   \n",
       "4          5  0-6 7-6(7) 6-1        3   R32  115.000       Nicolas Escude   \n",
       "\n",
       "         player_2_name  player_1_id  player_2_id  player_1_seed  \\\n",
       "0         Jeff Tarango       103163       101543          1.000   \n",
       "1        Juan Balcells       102644       102607            NaN   \n",
       "2  Alberto Berasategui       103252       102238            NaN   \n",
       "3        Roger Federer       103507       103819          7.000   \n",
       "4         Michael Sell       102765       102103          4.000   \n",
       "\n",
       "   player_2_seed player_1_entry player_2_entry player_1_hand player_2_hand  \\\n",
       "0            NaN            NaN            NaN             R             L   \n",
       "1            NaN            NaN              Q             L             R   \n",
       "2            NaN            NaN            NaN             R             R   \n",
       "3            NaN            NaN            NaN             R             R   \n",
       "4            NaN            NaN              Q             R             R   \n",
       "\n",
       "   player_1_ht  player_2_ht player_1_ioc player_2_ioc  player_1_age  \\\n",
       "0      188.000      180.000          GER          USA        21.700   \n",
       "1      183.000      190.000          ARG          ESP        24.300   \n",
       "2      175.000      173.000          ESP          ESP        21.300   \n",
       "3      183.000      185.000          ESP          SUI        19.900   \n",
       "4      185.000      180.000          FRA          USA        23.700   \n",
       "\n",
       "   player_2_age  player_1_rank  player_2_rank  player_1_rank_points  \\\n",
       "0        31.100         11.000         63.000              1612.000   \n",
       "1        24.500         49.000        211.000               723.000   \n",
       "2        26.500         48.000         59.000               726.000   \n",
       "3        18.400         45.000         61.000               768.000   \n",
       "4        27.300         34.000        167.000               873.000   \n",
       "\n",
       "   player_2_rank_points    winner  \n",
       "0               595.000  player_1  \n",
       "1               157.000  player_2  \n",
       "2               649.000  player_1  \n",
       "3               616.000  player_1  \n",
       "4               219.000  player_2  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the winner and loser columns with player_1 and player_2 for the matches dataset\n",
    "matches_processed_df= hide_winner_loser(matches_processed_df)\n",
    "matches_processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and consistent date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column for datetime datatype version of the date columns\n",
    "matches_processed_df['tourney_date_dt'] = pd.to_datetime(matches_processed_df['tourney_date'], format='%Y%m%d')\n",
    "rankings_processed_df['ranking_date_dt'] = pd.to_datetime(rankings_processed_df['ranking_date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure the matches are sorted as needed\n",
    "This is crucial as we are calculating cumulative measures (e.g. count of prior matches) to base a prediction on. It's not required for the rankings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>score</th>\n",
       "      <th>best_of</th>\n",
       "      <th>round</th>\n",
       "      <th>minutes</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_1_id</th>\n",
       "      <th>player_2_id</th>\n",
       "      <th>player_1_seed</th>\n",
       "      <th>player_2_seed</th>\n",
       "      <th>player_1_entry</th>\n",
       "      <th>player_2_entry</th>\n",
       "      <th>player_1_hand</th>\n",
       "      <th>player_2_hand</th>\n",
       "      <th>player_1_ht</th>\n",
       "      <th>player_2_ht</th>\n",
       "      <th>player_1_ioc</th>\n",
       "      <th>player_2_ioc</th>\n",
       "      <th>player_1_age</th>\n",
       "      <th>player_2_age</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_rank</th>\n",
       "      <th>player_1_rank_points</th>\n",
       "      <th>player_2_rank_points</th>\n",
       "      <th>winner</th>\n",
       "      <th>tourney_date_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-339</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000103</td>\n",
       "      <td>1</td>\n",
       "      <td>6-3 6-4</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>76.000</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Arnaud Clement</td>\n",
       "      <td>102358</td>\n",
       "      <td>103096</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>190.000</td>\n",
       "      <td>173.000</td>\n",
       "      <td>SWE</td>\n",
       "      <td>FRA</td>\n",
       "      <td>25.700</td>\n",
       "      <td>22.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>2606.000</td>\n",
       "      <td>805.000</td>\n",
       "      <td>player_1</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-339</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000103</td>\n",
       "      <td>2</td>\n",
       "      <td>6-1 6-4</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>45.000</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Jens Knippschild</td>\n",
       "      <td>103819</td>\n",
       "      <td>102533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>185.000</td>\n",
       "      <td>190.000</td>\n",
       "      <td>SUI</td>\n",
       "      <td>GER</td>\n",
       "      <td>18.300</td>\n",
       "      <td>24.800</td>\n",
       "      <td>64.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>749.000</td>\n",
       "      <td>525.000</td>\n",
       "      <td>player_1</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-339</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000103</td>\n",
       "      <td>3</td>\n",
       "      <td>3-6 7-6(5) 6-4</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>115.000</td>\n",
       "      <td>Jan Michael Gambill</td>\n",
       "      <td>Wayne Arthurs</td>\n",
       "      <td>102998</td>\n",
       "      <td>101885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>190.000</td>\n",
       "      <td>190.000</td>\n",
       "      <td>USA</td>\n",
       "      <td>AUS</td>\n",
       "      <td>22.500</td>\n",
       "      <td>28.700</td>\n",
       "      <td>58.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>803.000</td>\n",
       "      <td>449.000</td>\n",
       "      <td>player_1</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-339</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000103</td>\n",
       "      <td>4</td>\n",
       "      <td>6-2 6-1</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>65.000</td>\n",
       "      <td>Sebastien Grosjean</td>\n",
       "      <td>Andrew Ilie</td>\n",
       "      <td>103206</td>\n",
       "      <td>102776</td>\n",
       "      <td>7.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>175.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>FRA</td>\n",
       "      <td>AUS</td>\n",
       "      <td>21.500</td>\n",
       "      <td>23.600</td>\n",
       "      <td>27.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>1298.000</td>\n",
       "      <td>845.000</td>\n",
       "      <td>player_1</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-339</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>20000103</td>\n",
       "      <td>5</td>\n",
       "      <td>6-4 6-4</td>\n",
       "      <td>3</td>\n",
       "      <td>R32</td>\n",
       "      <td>68.000</td>\n",
       "      <td>Magnus Norman</td>\n",
       "      <td>Scott Draper</td>\n",
       "      <td>102796</td>\n",
       "      <td>102401</td>\n",
       "      <td>3.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WC</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>188.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>SWE</td>\n",
       "      <td>AUS</td>\n",
       "      <td>23.500</td>\n",
       "      <td>25.500</td>\n",
       "      <td>15.000</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1748.000</td>\n",
       "      <td>297.000</td>\n",
       "      <td>player_1</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n",
       "0   2000-339     Adelaide    Hard         32             A      20000103   \n",
       "1   2000-339     Adelaide    Hard         32             A      20000103   \n",
       "2   2000-339     Adelaide    Hard         32             A      20000103   \n",
       "3   2000-339     Adelaide    Hard         32             A      20000103   \n",
       "4   2000-339     Adelaide    Hard         32             A      20000103   \n",
       "\n",
       "   match_num           score  best_of round  minutes        player_1_name  \\\n",
       "0          1         6-3 6-4        3   R32   76.000       Thomas Enqvist   \n",
       "1          2         6-1 6-4        3   R32   45.000        Roger Federer   \n",
       "2          3  3-6 7-6(5) 6-4        3   R32  115.000  Jan Michael Gambill   \n",
       "3          4         6-2 6-1        3   R32   65.000   Sebastien Grosjean   \n",
       "4          5         6-4 6-4        3   R32   68.000        Magnus Norman   \n",
       "\n",
       "      player_2_name  player_1_id  player_2_id  player_1_seed  player_2_seed  \\\n",
       "0    Arnaud Clement       102358       103096          1.000            NaN   \n",
       "1  Jens Knippschild       103819       102533            NaN            NaN   \n",
       "2     Wayne Arthurs       102998       101885            NaN            NaN   \n",
       "3       Andrew Ilie       103206       102776          7.000            NaN   \n",
       "4      Scott Draper       102796       102401          3.000            NaN   \n",
       "\n",
       "  player_1_entry player_2_entry player_1_hand player_2_hand  player_1_ht  \\\n",
       "0            NaN            NaN             R             R      190.000   \n",
       "1            NaN            NaN             R             R      185.000   \n",
       "2            NaN            NaN             R             L      190.000   \n",
       "3            NaN            NaN             R             R      175.000   \n",
       "4            NaN             WC             R             L      188.000   \n",
       "\n",
       "   player_2_ht player_1_ioc player_2_ioc  player_1_age  player_2_age  \\\n",
       "0      173.000          SWE          FRA        25.700        22.000   \n",
       "1      190.000          SUI          GER        18.300        24.800   \n",
       "2      190.000          USA          AUS        22.500        28.700   \n",
       "3      180.000          FRA          AUS        21.500        23.600   \n",
       "4      178.000          SWE          AUS        23.500        25.500   \n",
       "\n",
       "   player_1_rank  player_2_rank  player_1_rank_points  player_2_rank_points  \\\n",
       "0          4.000         56.000              2606.000               805.000   \n",
       "1         64.000         91.000               749.000               525.000   \n",
       "2         58.000        105.000               803.000               449.000   \n",
       "3         27.000         54.000              1298.000               845.000   \n",
       "4         15.000        154.000              1748.000               297.000   \n",
       "\n",
       "     winner tourney_date_dt  \n",
       "0  player_1      2000-01-03  \n",
       "1  player_1      2000-01-03  \n",
       "2  player_1      2000-01-03  \n",
       "3  player_1      2000-01-03  \n",
       "4  player_1      2000-01-03  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort matches by tourney_date, tourney_id and match_num, and reset the index as the old one is not required anymore.\n",
    "matches_processed_df = matches_processed_df.sort_values(['tourney_date', 'tourney_id', 'match_num'], ascending=True)\n",
    "matches_processed_df = matches_processed_df.reset_index(drop=True) \n",
    "matches_processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove matches with result as W/O\n",
    "W/O stands for \"Walkover\". Matches resulting in W/O should not be considered, so remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70910"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove matches resulting in a W/O\n",
    "matches_processed_df = matches_processed_df[matches_processed_df['score'] != 'W/O']\n",
    "len(matches_processed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down from 71'213 to 70'910 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove matches with 0 or less minutes\n",
    "Not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove matches with 0 or less minutes\n",
    "# matches_df = matches_df.loc[matches_df['minutes']<0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature for matches dataset that all tournaments start dates are shown as a Monday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_date_dt_preceding_monday\n",
       "Monday    70910\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add feature for tournaments not starting on a Monday, with its value being the preceding Monday\n",
    "matches_processed_df['tourney_date_dt'] = pd.to_datetime(matches_processed_df['tourney_date'], format='%Y%m%d')\n",
    "matches_processed_df['tourney_date_dt_preceding_monday'] = matches_processed_df['tourney_date_dt'].apply(lambda x: x - pd.DateOffset(days=x.weekday()) if x.weekday() != 0 else x)\n",
    "\n",
    "# verify that this feature's date values are all on a Monday\n",
    "matches_processed_df['tourney_date_dt_preceding_monday'].dt.day_name().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>tourney_date_dt_preceding_monday</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-04</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-17</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_date_dt tourney_date_dt_preceding_monday  count\n",
       "0      2000-01-28                       2000-01-24      6\n",
       "1      2000-02-04                       2000-01-31     88\n",
       "2      2000-03-17                       2000-03-13      4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check examples of these new column values compared to its original\n",
    "matches_processed_df[matches_processed_df['tourney_date_dt'].dt.day_name() != 'Monday'][['tourney_date_dt', 'tourney_date_dt_preceding_monday']].groupby(['tourney_date_dt', 'tourney_date_dt_preceding_monday']).size().reset_index(name='count').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 28 Jan. 2000 was a Friday, and 24 Jan. 2000 was the preceding Monday\n",
    "- 4 Feb. 2000 was a Friday, and 31 Jan. 2000 was the preceding Monday\n",
    "- 17 Mar. 2000 was a Friday, and 13 Mar. 2000 was the preceding Monday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches_processed_df.to_csv(\"matches_processed_df.csv\", sep=\",\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process matches with new players having no ranking \n",
    "Remove matches where 1 opponent has so far played less than 10 completed matches. \n",
    "Notes: \n",
    "- Don't remove matches in the year 2000, as our players could have played 10 matches prior to the year 2000, and our cumulative count features need a year to get working.\n",
    "- W/O matches don't count, but retirements do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### example of players where 1 opponent has so far played < 10 completed matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process matches with seasoned players having no ranking\n",
    "As explained before, there are matches with seasoned (experienced on the ATP Tour) players having no (empty) rank possibly because they have been inactive due to injury and hence lost their ranking before returning. If they are not new players, we can try and look up their last valid ranking in the rankings file. A recent example is Kevin Anderson, who was inactive for a period due to retiring in May 2022 and then announcing his comeback in July 2023* \n",
    "\n",
    "*Source: [Wikipedia \"Kevin_Anderson (tennis)\", accessed Oct. 2023](https://en.wikipedia.org/wiki/Kevin_Anderson_(tennis))\n",
    "\n",
    "We will: \n",
    "1. for a particular match, find the latest available historical ranking in the rankings dataset for the player in the matches dataset\n",
    "2. add 10 to the ranking for each week where the player was inactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>player_1_id</th>\n",
       "      <th>player_2_id</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66779</th>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>104731</td>\n",
       "      <td>207678</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>Juan Manuel Cerundolo</td>\n",
       "      <td>91.000</td>\n",
       "      <td>122.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70693</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>209113</td>\n",
       "      <td>104731</td>\n",
       "      <td>Gabriel Diallo</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>141.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70704</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>133835</td>\n",
       "      <td>104731</td>\n",
       "      <td>Gijs Brouwer</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>145.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70710</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>200005</td>\n",
       "      <td>104731</td>\n",
       "      <td>Ugo Humbert</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>40.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70867</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>111442</td>\n",
       "      <td>104731</td>\n",
       "      <td>Jordan Thompson</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>71.000</td>\n",
       "      <td>652.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tourney_date_dt  player_1_id  player_2_id    player_1_name  \\\n",
       "66779      2022-03-21       104731       207678   Kevin Anderson   \n",
       "70693      2023-07-17       209113       104731   Gabriel Diallo   \n",
       "70704      2023-07-17       133835       104731     Gijs Brouwer   \n",
       "70710      2023-07-17       200005       104731      Ugo Humbert   \n",
       "70867      2023-07-31       111442       104731  Jordan Thompson   \n",
       "\n",
       "               player_2_name  player_1_rank  player_2_rank  \n",
       "66779  Juan Manuel Cerundolo         91.000        122.000  \n",
       "70693         Kevin Anderson        141.000            NaN  \n",
       "70704         Kevin Anderson        145.000            NaN  \n",
       "70710         Kevin Anderson         40.000            NaN  \n",
       "70867         Kevin Anderson         71.000        652.000  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of player previously having a ranking but later no ranking\n",
    "matches_processed_ka_df = matches_processed_df[(matches_processed_df['player_1_name'] == 'Kevin Anderson') \n",
    "                                                | (matches_processed_df['player_2_name'] == 'Kevin Anderson')].tail()\n",
    "matches_processed_ka_df[['tourney_date_dt', 'player_1_id', 'player_2_id', 'player_1_name', 'player_2_name', 'player_1_rank', 'player_2_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define static parameter\n",
    "rank_penalty_per_week_inactivity = 10\n",
    "\n",
    "# define a function to look up historic rankings for players having no ranking in a particular match\n",
    "def impute_missing_rankings(m, r):\n",
    "    last_rankings = {}  # Dictionary to store the last available player_rank for each player_id\n",
    "\n",
    "    for i, row in m.iterrows():\n",
    "        if pd.isna(row['player_1_rank']):\n",
    "            week = row['tourney_date_dt'] - dt.timedelta(days=row['tourney_date_dt'].weekday())\n",
    "            p1_id = row['player_1_id']\n",
    "\n",
    "            # Find the last available ranking date prior to the tourney_date_dt\n",
    "            last_ranking_date = r[(r['player'] == p1_id) & (r['ranking_date_dt'] < week)]['ranking_date_dt'].max()\n",
    "\n",
    "            if last_ranking_date:\n",
    "                last_ranking_row = r[(r['player'] == p1_id) & (r['ranking_date_dt'] == last_ranking_date)]\n",
    "                if not last_ranking_row.empty:\n",
    "                    last_rank = last_ranking_row['rank'].values[0]\n",
    "                    weeks_difference = (week - last_ranking_date).days // 7\n",
    "                    imputed_rank = last_rank + weeks_difference * rank_penalty_per_week_inactivity\n",
    "                    if imputed_rank > 3333: # Don't over-penalize\n",
    "                        m.at[i, 'player_1_rank'] = 3333   # Set a default value   \n",
    "                    else: \n",
    "                        m.at[i, 'player_1_rank'] = imputed_rank\n",
    "                        last_rankings[p1_id] = imputed_rank\n",
    "                else:\n",
    "                    m.at[i, 'player_1_rank'] = 3333  # Set a default value\n",
    "            else:\n",
    "                m.at[i, 'player_1_rank'] = 3333  # Set a default value\n",
    "\n",
    "        if pd.isna(row['player_2_rank']):\n",
    "            week = row['tourney_date_dt'] - dt.timedelta(days=row['tourney_date_dt'].weekday())\n",
    "            p2_id = row['player_2_id']\n",
    "\n",
    "            # Find the last available ranking date prior to the tourney_date_dt\n",
    "            last_ranking_date = r[(r['player'] == p2_id) & (r['ranking_date_dt'] < week)]['ranking_date_dt'].max()\n",
    "\n",
    "            if last_ranking_date:\n",
    "                last_ranking_row = r[(r['player'] == p2_id) & (r['ranking_date_dt'] == last_ranking_date)]\n",
    "                if not last_ranking_row.empty:\n",
    "                    last_rank = last_ranking_row['rank'].values[0]\n",
    "                    weeks_difference = (week - last_ranking_date).days // 7\n",
    "                    imputed_rank = last_rank + weeks_difference * rank_penalty_per_week_inactivity\n",
    "                    if imputed_rank > 3333: # Don't over-penalize\n",
    "                        m.at[i, 'player_2_rank'] = 3333   # Set a default value   \n",
    "                    else:\n",
    "                        m.at[i, 'player_2_rank'] = imputed_rank\n",
    "                        last_rankings[p2_id] = imputed_rank\n",
    "                else: \n",
    "                    m.at[i, 'player_2_rank'] = 3333  # Set a default value\n",
    "            else:\n",
    "                m.at[i, 'player_2_rank'] = 3333  # Set a default value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function using the example of Kevin Anderson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_rank</th>\n",
       "      <th>round</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66779</th>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>Juan Manuel Cerundolo</td>\n",
       "      <td>91.000</td>\n",
       "      <td>122.000</td>\n",
       "      <td>R64</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70693</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>Gabriel Diallo</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>141.000</td>\n",
       "      <td>704.000</td>\n",
       "      <td>R32</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70704</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>Gijs Brouwer</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>145.000</td>\n",
       "      <td>704.000</td>\n",
       "      <td>R16</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70710</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>Ugo Humbert</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>40.000</td>\n",
       "      <td>704.000</td>\n",
       "      <td>QF</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70867</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>Jordan Thompson</td>\n",
       "      <td>Kevin Anderson</td>\n",
       "      <td>71.000</td>\n",
       "      <td>652.000</td>\n",
       "      <td>R64</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tourney_date_dt    player_1_name          player_2_name  player_1_rank  \\\n",
       "66779      2022-03-21   Kevin Anderson  Juan Manuel Cerundolo         91.000   \n",
       "70693      2023-07-17   Gabriel Diallo         Kevin Anderson        141.000   \n",
       "70704      2023-07-17     Gijs Brouwer         Kevin Anderson        145.000   \n",
       "70710      2023-07-17      Ugo Humbert         Kevin Anderson         40.000   \n",
       "70867      2023-07-31  Jordan Thompson         Kevin Anderson         71.000   \n",
       "\n",
       "       player_2_rank round    winner  \n",
       "66779        122.000   R64  player_2  \n",
       "70693        704.000   R32  player_2  \n",
       "70704        704.000   R16  player_2  \n",
       "70710        704.000    QF  player_1  \n",
       "70867        652.000   R64  player_1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function using only reduced dataset: Kevin Anderson\n",
    "impute_missing_rankings(matches_processed_ka_df, rankings_processed_df)\n",
    "matches_processed_ka_df[['tourney_date_dt', 'player_1_name', 'player_2_name', 'player_1_rank', 'player_2_rank','round', 'winner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking_date</th>\n",
       "      <th>rank</th>\n",
       "      <th>player</th>\n",
       "      <th>points</th>\n",
       "      <th>ranking_date_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182305</th>\n",
       "      <td>20220502</td>\n",
       "      <td>107</td>\n",
       "      <td>104731</td>\n",
       "      <td>602.000</td>\n",
       "      <td>2022-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184458</th>\n",
       "      <td>20220509</td>\n",
       "      <td>104</td>\n",
       "      <td>104731</td>\n",
       "      <td>602.000</td>\n",
       "      <td>2022-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186590</th>\n",
       "      <td>20220516</td>\n",
       "      <td>104</td>\n",
       "      <td>104731</td>\n",
       "      <td>597.000</td>\n",
       "      <td>2022-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188736</th>\n",
       "      <td>20220523</td>\n",
       "      <td>104</td>\n",
       "      <td>104731</td>\n",
       "      <td>597.000</td>\n",
       "      <td>2022-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45886</th>\n",
       "      <td>20230724</td>\n",
       "      <td>645</td>\n",
       "      <td>104731</td>\n",
       "      <td>45.000</td>\n",
       "      <td>2023-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47944</th>\n",
       "      <td>20230731</td>\n",
       "      <td>652</td>\n",
       "      <td>104731</td>\n",
       "      <td>45.000</td>\n",
       "      <td>2023-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ranking_date  rank  player  points ranking_date_dt\n",
       "182305      20220502   107  104731 602.000      2022-05-02\n",
       "184458      20220509   104  104731 602.000      2022-05-09\n",
       "186590      20220516   104  104731 597.000      2022-05-16\n",
       "188736      20220523   104  104731 597.000      2022-05-23\n",
       "45886       20230724   645  104731  45.000      2023-07-24\n",
       "47944       20230731   652  104731  45.000      2023-07-31"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_processed_df[(rankings_processed_df['ranking_date'].between(20220501, 20230801)) & (rankings_processed_df['player'] == 104731)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks_ka_inactive = (dt.date(2023,7,17) - dt.date(2022,5,23)).days  // 7 # no. or weeks inactivity\n",
    "weeks_ka_inactive * 10 # rank place penalty of 10 per week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penalty of roughly 600 places for a 60 week period of inactivity reflects roughly the output of the function impute_missing_rankings.\n",
    "\n",
    "Finally, we apply the function to our full dataset, and do a small check to verify that no null values exist anymore for these features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_missing_rankings(matches_processed_df, rankings_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_1_rank\n",
       "False    70910\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_processed_df['player_1_rank'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_2_rank\n",
       "False    70910\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_processed_df['player_2_rank'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70910.000</td>\n",
       "      <td>70910.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>71.792</td>\n",
       "      <td>201.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.660</td>\n",
       "      <td>467.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000</td>\n",
       "      <td>53.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000</td>\n",
       "      <td>86.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>63.000</td>\n",
       "      <td>143.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3333.000</td>\n",
       "      <td>3333.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_1_rank  player_2_rank\n",
       "count      70910.000      70910.000\n",
       "mean          71.792        201.093\n",
       "std          217.660        467.177\n",
       "min            1.000          2.000\n",
       "25%           14.000         53.000\n",
       "50%           33.000         86.000\n",
       "75%           63.000        143.000\n",
       "max         3333.000       3333.000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_processed_df[['player_1_rank', 'player_2_rank']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70910 entries, 0 to 70909\n",
      "Data columns (total 34 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   tourney_id                        70910 non-null  object        \n",
      " 1   tourney_name                      70910 non-null  object        \n",
      " 2   surface                           70910 non-null  object        \n",
      " 3   draw_size                         70910 non-null  int64         \n",
      " 4   tourney_level                     70910 non-null  object        \n",
      " 5   tourney_date                      70910 non-null  int64         \n",
      " 6   match_num                         70910 non-null  int64         \n",
      " 7   score                             70910 non-null  object        \n",
      " 8   best_of                           70910 non-null  int64         \n",
      " 9   round                             70910 non-null  object        \n",
      " 10  minutes                           63229 non-null  float64       \n",
      " 11  player_1_name                     70910 non-null  object        \n",
      " 12  player_2_name                     70910 non-null  object        \n",
      " 13  player_1_id                       70910 non-null  int64         \n",
      " 14  player_2_id                       70910 non-null  int64         \n",
      " 15  player_1_seed                     38952 non-null  float64       \n",
      " 16  player_2_seed                     6638 non-null   float64       \n",
      " 17  player_1_entry                    2772 non-null   object        \n",
      " 18  player_2_entry                    20699 non-null  object        \n",
      " 19  player_1_hand                     70902 non-null  object        \n",
      " 20  player_2_hand                     70867 non-null  object        \n",
      " 21  player_1_ht                       69489 non-null  float64       \n",
      " 22  player_2_ht                       67438 non-null  float64       \n",
      " 23  player_1_ioc                      70910 non-null  object        \n",
      " 24  player_2_ioc                      70910 non-null  object        \n",
      " 25  player_1_age                      70908 non-null  float64       \n",
      " 26  player_2_age                      70901 non-null  float64       \n",
      " 27  player_1_rank                     70910 non-null  float64       \n",
      " 28  player_2_rank                     70910 non-null  float64       \n",
      " 29  player_1_rank_points              70650 non-null  float64       \n",
      " 30  player_2_rank_points              69210 non-null  float64       \n",
      " 31  winner                            70910 non-null  object        \n",
      " 32  tourney_date_dt                   70910 non-null  datetime64[ns]\n",
      " 33  tourney_date_dt_preceding_monday  70910 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(11), int64(6), object(15)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# make a new copy of the dataframe, for starting the feature engineering\n",
    "matches_features_df = matches_processed_df.copy().reset_index(drop=True)\n",
    "matches_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add feature for cumulative number of games played so far in a tournament - OPTIONAL and WIP\n",
    "It would be interesting if the cumulative number of games played so far in a tournament could be used to predict the next result of a match, indicating either fatigue or dominance (won in straight sets). So far this feature is optional for our prediction model.\n",
    "\n",
    "*Note: this function does not yet work 100%. It doesn't yet calculate the `player_x_tourney_cum_games_count` correctly in the case where a player can appear as player_1 or player_2 in the same tournament.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef calc_game_counts(m):\\n    # Initialize columns to store game counts\\n    m['player_1_match_games_count'] = 0\\n    m['player_2_match_games_count'] = 0\\n    m['player_1_tourney_cum_games_count'] = 0\\n    m['player_2_tourney_cum_games_count'] = 0\\n    \\n    # Regular expression to match scores\\n    score_pattern = r'(\\\\d+)-(\\\\d+)(?:\\\\(\\\\d+\\\\))?'\\n    \\n    # Extract individual scores using regular expression and convert to numeric values\\n    scores = m['score'].str.extractall(score_pattern).astype(int)\\n    m[['player_1_games', 'player_2_games']] = scores.groupby(level=0).sum()\\n    \\n    # Determine the winner and adjust game counts accordingly\\n    winner_mask = m['winner'] == 'player_1'\\n    m.loc[winner_mask, 'player_1_match_games_count'] = m.loc[winner_mask, 'player_1_games']\\n    m.loc[~winner_mask, 'player_1_match_games_count'] = m.loc[~winner_mask, 'player_2_games']\\n    \\n    m['player_2_match_games_count'] = m['player_1_games'] + m['player_2_games'] - m['player_1_match_games_count']\\n    \\n    # Calculate cumulative game counts using groupby and cumsum without resetting\\n    m['player_1_tourney_cum_games_count'] = m.groupby(['tourney_id', 'player_1_id'])['player_1_match_games_count'].cumsum() - m['player_1_match_games_count']\\n    m['player_2_tourney_cum_games_count'] = m.groupby(['tourney_id', 'player_2_id'])['player_2_match_games_count'].cumsum() - m['player_2_match_games_count']\\n    \\n    # Set the initial cumulative game counts to 0 for the first matches of each player\\n    m.loc[m.groupby(['tourney_id', 'player_1_id'])['player_1_match_games_count'].cumcount() == 0, 'player_1_tourney_cum_games_count'] = 0\\n    m.loc[m.groupby(['tourney_id', 'player_2_id'])['player_2_match_games_count'].cumcount() == 0, 'player_2_tourney_cum_games_count'] = 0\\n    \\n    return m\\n\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function calc_game_counts: to calculate game counts for each match, uses vectorization instead of row iteration for performance reasons\n",
    "'''\n",
    "def calc_game_counts(m):\n",
    "    # Initialize columns to store game counts\n",
    "    m['player_1_match_games_count'] = 0\n",
    "    m['player_2_match_games_count'] = 0\n",
    "    m['player_1_tourney_cum_games_count'] = 0\n",
    "    m['player_2_tourney_cum_games_count'] = 0\n",
    "    \n",
    "    # Regular expression to match scores\n",
    "    score_pattern = r'(\\d+)-(\\d+)(?:\\(\\d+\\))?'\n",
    "    \n",
    "    # Extract individual scores using regular expression and convert to numeric values\n",
    "    scores = m['score'].str.extractall(score_pattern).astype(int)\n",
    "    m[['player_1_games', 'player_2_games']] = scores.groupby(level=0).sum()\n",
    "    \n",
    "    # Determine the winner and adjust game counts accordingly\n",
    "    winner_mask = m['winner'] == 'player_1'\n",
    "    m.loc[winner_mask, 'player_1_match_games_count'] = m.loc[winner_mask, 'player_1_games']\n",
    "    m.loc[~winner_mask, 'player_1_match_games_count'] = m.loc[~winner_mask, 'player_2_games']\n",
    "    \n",
    "    m['player_2_match_games_count'] = m['player_1_games'] + m['player_2_games'] - m['player_1_match_games_count']\n",
    "    \n",
    "    # Calculate cumulative game counts using groupby and cumsum without resetting\n",
    "    m['player_1_tourney_cum_games_count'] = m.groupby(['tourney_id', 'player_1_id'])['player_1_match_games_count'].cumsum() - m['player_1_match_games_count']\n",
    "    m['player_2_tourney_cum_games_count'] = m.groupby(['tourney_id', 'player_2_id'])['player_2_match_games_count'].cumsum() - m['player_2_match_games_count']\n",
    "    \n",
    "    # Set the initial cumulative game counts to 0 for the first matches of each player\n",
    "    m.loc[m.groupby(['tourney_id', 'player_1_id'])['player_1_match_games_count'].cumcount() == 0, 'player_1_tourney_cum_games_count'] = 0\n",
    "    m.loc[m.groupby(['tourney_id', 'player_2_id'])['player_2_match_games_count'].cumcount() == 0, 'player_2_tourney_cum_games_count'] = 0\n",
    "    \n",
    "    return m\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmatches_processed_df = calc_game_counts(matches_processed_df)\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the function calc_game_counts on the matches dataset\n",
    "'''\n",
    "matches_processed_df = calc_game_counts(matches_processed_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matches_processed_df[matches_processed_df[\\'tourney_id\\'].str.contains(\\'2000-451|2000-301\\')][[\\'tourney_id\\',\\'match_num\\', \\'player_1_id\\',\\'player_2_id\\',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   \\'player_1_name\\',\\'player_2_name\\', \\'round\\' ,\\'score\\', \\'winner\\', \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\'player_1_match_games_count\\', \\'player_2_match_games_count\\',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\'player_1_tourney_cum_games_count\\', \\'player_2_tourney_cum_games_count\\']].to_csv(\"matches_processed.csv\", sep=\\',\\', header=True, index=False)\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test by exporting to .csv\n",
    "'''matches_processed_df[matches_processed_df['tourney_id'].str.contains('2000-451|2000-301')][['tourney_id','match_num', 'player_1_id','player_2_id',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   'player_1_name','player_2_name', 'round' ,'score', 'winner', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'player_1_match_games_count', 'player_2_match_games_count',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'player_1_tourney_cum_games_count', 'player_2_tourney_cum_games_count']].to_csv(\"matches_processed.csv\", sep=',', header=True, index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmatches_processed_df[['tourney_id','match_num', 'player_1_id','player_2_id',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   'player_1_name','player_2_name', 'round' ,'score', 'winner', \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'player_1_match_games_count', 'player_2_match_games_count',\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'player_1_tourney_cum_games_count', 'player_2_tourney_cum_games_count']].head(31)\\n\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review the output of the new columns for the first 31 rows (1 tournament)\n",
    "'''\n",
    "matches_processed_df[['tourney_id','match_num', 'player_1_id','player_2_id',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   'player_1_name','player_2_name', 'round' ,'score', 'winner', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'player_1_match_games_count', 'player_2_match_games_count',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'player_1_tourney_cum_games_count', 'player_2_tourney_cum_games_count']].head(31)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add feature for ranking difference\n",
    "This feature may help our model more easily assess the how the ranking plays a factor in determining the winner of the match. It simply calculates the weight of the difference between player_2_rank and player_1_rank, by using a normalized difference. The normalized difference is expressed as a number between 0 and 1. In that case, the closer the ranking between player 1 and player 2, the higher the number will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_2_rank</th>\n",
       "      <th>ranking_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70905</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>Frances Tiafoe</td>\n",
       "      <td>10.000</td>\n",
       "      <td>Ben Shelton</td>\n",
       "      <td>47.000</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70906</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Taylor Fritz</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70907</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>Carlos Alcaraz</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Daniil Medvedev</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70908</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Ben Shelton</td>\n",
       "      <td>47.000</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70909</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Daniil Medvedev</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tourney_date_dt   player_1_name  player_1_rank    player_2_name  \\\n",
       "70905      2023-08-28  Frances Tiafoe         10.000      Ben Shelton   \n",
       "70906      2023-08-28  Novak Djokovic          2.000     Taylor Fritz   \n",
       "70907      2023-08-28  Carlos Alcaraz          1.000  Daniil Medvedev   \n",
       "70908      2023-08-28  Novak Djokovic          2.000      Ben Shelton   \n",
       "70909      2023-08-28  Novak Djokovic          2.000  Daniil Medvedev   \n",
       "\n",
       "       player_2_rank  ranking_difference  \n",
       "70905         47.000               0.989  \n",
       "70906          9.000               0.998  \n",
       "70907          3.000               0.999  \n",
       "70908         47.000               0.986  \n",
       "70909          3.000               1.000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate max. possible rank difference\n",
    "max_possible_rank_difference = max(matches_features_df['player_2_rank'] - matches_features_df['player_1_rank'])\n",
    "\n",
    "# calculate normalized rank difference\n",
    "matches_features_df['ranking_difference'] = 1 - ((matches_features_df['player_2_rank'] - matches_features_df['player_1_rank']) / max_possible_rank_difference)\n",
    "\n",
    "# preview the result for the last 5 observations of the dataset\n",
    "matches_features_df[['tourney_date_dt', 'player_1_name', 'player_1_rank','player_2_name', 'player_2_rank', 'ranking_difference']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_2_rank</th>\n",
       "      <th>ranking_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>4.000</td>\n",
       "      <td>Arnaud Clement</td>\n",
       "      <td>56.000</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>64.000</td>\n",
       "      <td>Jens Knippschild</td>\n",
       "      <td>91.000</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Jan Michael Gambill</td>\n",
       "      <td>58.000</td>\n",
       "      <td>Wayne Arthurs</td>\n",
       "      <td>105.000</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Sebastien Grosjean</td>\n",
       "      <td>27.000</td>\n",
       "      <td>Andrew Ilie</td>\n",
       "      <td>54.000</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Magnus Norman</td>\n",
       "      <td>15.000</td>\n",
       "      <td>Scott Draper</td>\n",
       "      <td>154.000</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_date_dt        player_1_name  player_1_rank     player_2_name  \\\n",
       "0      2000-01-03       Thomas Enqvist          4.000    Arnaud Clement   \n",
       "1      2000-01-03        Roger Federer         64.000  Jens Knippschild   \n",
       "2      2000-01-03  Jan Michael Gambill         58.000     Wayne Arthurs   \n",
       "3      2000-01-03   Sebastien Grosjean         27.000       Andrew Ilie   \n",
       "4      2000-01-03        Magnus Norman         15.000      Scott Draper   \n",
       "\n",
       "   player_2_rank  ranking_difference  \n",
       "0         56.000               0.984  \n",
       "1         91.000               0.992  \n",
       "2        105.000               0.986  \n",
       "3         54.000               0.992  \n",
       "4        154.000               0.958  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the result for the first 5 observations of the dataset\n",
    "matches_features_df[['tourney_date_dt', 'player_1_name', 'player_1_rank','player_2_name', 'player_2_rank', 'ranking_difference']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add feature for cumulative matches played count, and win percentages per surface and tourney level for player 1 and player 2\n",
    "This cumulative matches played count and win percentages per surface and tourney level are important features for our prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surface win %\n",
    "This feature will show a player's success so far on a particular tennis court surface. There will be a number expressed as a percentage which will reflect the number of wins divided by the total matches on a surface, prior to that match taking place.\n",
    "First, what are the different surfaces being played on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surface\n",
       "Hard     0.541\n",
       "Clay     0.327\n",
       "Grass    0.103\n",
       "Carpet   0.029\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the different surfaces played on since 2000?\n",
    "matches_features_df['surface'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tourney_name\n",
      "Australian Open         3042\n",
      "US Open                 2535\n",
      "Miami Masters           2172\n",
      "Indian Wells Masters    2041\n",
      "Cincinnati Masters      1372\n",
      "Canada Masters          1301\n",
      "Washington              1053\n",
      "Tokyo                    816\n",
      "Paris Masters            768\n",
      "Dubai                    756\n",
      "Name: count, dtype: int64\n",
      "tourney_name\n",
      "Roland Garros          3042\n",
      "Rome Masters           1409\n",
      "Monte Carlo Masters    1316\n",
      "Barcelona              1179\n",
      "Madrid Masters          803\n",
      "Kitzbuhel               788\n",
      "Buenos Aires            682\n",
      "Munich                  668\n",
      "Gstaad                  658\n",
      "Estoril                 658\n",
      "Name: count, dtype: int64\n",
      "tourney_name\n",
      "Wimbledon          2913\n",
      "Queen's Club       1065\n",
      "Halle               698\n",
      "Newport             680\n",
      "s Hertogenbosch     649\n",
      "Nottingham          370\n",
      "Eastbourne          336\n",
      "Stuttgart           214\n",
      "Antalya              81\n",
      "Mallorca             79\n",
      "Name: count, dtype: int64\n",
      "tourney_name\n",
      "Paris Masters                  327\n",
      "Lyon                           279\n",
      "Moscow                         217\n",
      "Basel                          215\n",
      "Milan                          154\n",
      "St. Petersburg                 123\n",
      "Zagreb                          62\n",
      "Ho Chi Minh City                30\n",
      "Masters Cup                     15\n",
      "Davis Cup G2 R1: POL vs LAT      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# what are the different surfaces played on in the top 10 tournaments in 2000?\n",
    "print(matches_features_df[matches_features_df['surface'] == 'Hard']['tourney_name'].value_counts().head(10))\n",
    "print(matches_features_df[matches_features_df['surface'] == 'Clay']['tourney_name'].value_counts().head(10))\n",
    "print(matches_features_df[matches_features_df['surface'] == 'Grass']['tourney_name'].value_counts().head(10))\n",
    "print(matches_features_df[matches_features_df['surface'] == 'Carpet']['tourney_name'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>match_num</th>\n",
       "      <th>surface</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>player_1_id</th>\n",
       "      <th>player_2_id</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>103163</td>\n",
       "      <td>101543</td>\n",
       "      <td>Tommy Haas</td>\n",
       "      <td>Jeff Tarango</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>2</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>102644</td>\n",
       "      <td>102607</td>\n",
       "      <td>Franco Squillari</td>\n",
       "      <td>Juan Balcells</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>3</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>103252</td>\n",
       "      <td>102238</td>\n",
       "      <td>Alberto Martin</td>\n",
       "      <td>Alberto Berasategui</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>4</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>103507</td>\n",
       "      <td>103819</td>\n",
       "      <td>Juan Carlos Ferrero</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>102765</td>\n",
       "      <td>102103</td>\n",
       "      <td>Nicolas Escude</td>\n",
       "      <td>Michael Sell</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>Basel</td>\n",
       "      <td>2000-10-23</td>\n",
       "      <td>27</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>A</td>\n",
       "      <td>102450</td>\n",
       "      <td>102271</td>\n",
       "      <td>Tim Henman</td>\n",
       "      <td>Hicham Arazi</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>Basel</td>\n",
       "      <td>2000-10-23</td>\n",
       "      <td>28</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>A</td>\n",
       "      <td>102358</td>\n",
       "      <td>103103</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Dominik Hrbaty</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>Basel</td>\n",
       "      <td>2000-10-23</td>\n",
       "      <td>29</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>A</td>\n",
       "      <td>103720</td>\n",
       "      <td>103819</td>\n",
       "      <td>Lleyton Hewitt</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>Basel</td>\n",
       "      <td>2000-10-23</td>\n",
       "      <td>30</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>A</td>\n",
       "      <td>102358</td>\n",
       "      <td>102450</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Tim Henman</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>Basel</td>\n",
       "      <td>2000-10-23</td>\n",
       "      <td>31</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>A</td>\n",
       "      <td>102358</td>\n",
       "      <td>103819</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tourney_name tourney_date_dt  match_num surface tourney_level  \\\n",
       "93       Auckland      2000-01-10          1    Hard             A   \n",
       "94       Auckland      2000-01-10          2    Hard             A   \n",
       "95       Auckland      2000-01-10          3    Hard             A   \n",
       "96       Auckland      2000-01-10          4    Hard             A   \n",
       "97       Auckland      2000-01-10          5    Hard             A   \n",
       "...           ...             ...        ...     ...           ...   \n",
       "3095        Basel      2000-10-23         27  Carpet             A   \n",
       "3096        Basel      2000-10-23         28  Carpet             A   \n",
       "3097        Basel      2000-10-23         29  Carpet             A   \n",
       "3098        Basel      2000-10-23         30  Carpet             A   \n",
       "3099        Basel      2000-10-23         31  Carpet             A   \n",
       "\n",
       "      player_1_id  player_2_id        player_1_name        player_2_name  \\\n",
       "93         103163       101543           Tommy Haas         Jeff Tarango   \n",
       "94         102644       102607     Franco Squillari        Juan Balcells   \n",
       "95         103252       102238       Alberto Martin  Alberto Berasategui   \n",
       "96         103507       103819  Juan Carlos Ferrero        Roger Federer   \n",
       "97         102765       102103       Nicolas Escude         Michael Sell   \n",
       "...           ...          ...                  ...                  ...   \n",
       "3095       102450       102271           Tim Henman         Hicham Arazi   \n",
       "3096       102358       103103       Thomas Enqvist       Dominik Hrbaty   \n",
       "3097       103720       103819       Lleyton Hewitt        Roger Federer   \n",
       "3098       102358       102450       Thomas Enqvist           Tim Henman   \n",
       "3099       102358       103819       Thomas Enqvist        Roger Federer   \n",
       "\n",
       "        winner  \n",
       "93    player_1  \n",
       "94    player_2  \n",
       "95    player_1  \n",
       "96    player_1  \n",
       "97    player_2  \n",
       "...        ...  \n",
       "3095  player_1  \n",
       "3096  player_1  \n",
       "3097  player_2  \n",
       "3098  player_1  \n",
       "3099  player_1  \n",
       "\n",
       "[148 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a test dataset for all 4 surface types, and preview the columns and sample rows relevant for calculation\n",
    "matches_4surfaces = matches_features_df[(matches_features_df['tourney_name'].isin(['Auckland', 'Barcelona', 'Halle', 'Basel']))\n",
    "\t\t\t\t\t& (matches_features_df['tourney_date'] < 20010000)][['tourney_name', 'tourney_date_dt', 'match_num', 'surface', 'tourney_level'\n",
    "                                                                                , 'player_1_id', 'player_2_id', 'player_1_name', 'player_2_name'\n",
    "                                                                                , 'winner'\n",
    "\t\t\t\t\t]]\n",
    "matches_4surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tournament level win %\n",
    "This feature will show a player's success so far on a particular type (level) of tournament. There will be a number expressed as a percentage which will reflect the number of wins divided by the total matches on that level, prior to that match taking place.\n",
    "First, what are the different tournament level being played?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_level\n",
       "A   0.547\n",
       "M   0.185\n",
       "G   0.170\n",
       "D   0.093\n",
       "F   0.005\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the different tournament levels played since 2000?\n",
    "matches_features_df['tourney_level'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate win %s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cum_match_counts_and_pct (df):\n",
    "\n",
    "    # Initialize dictionaries to keep track of cumulative match counts and wins for each player and surface\n",
    "    player_cumulative_counts = {}\n",
    "    player_surface_cumulative_counts = {}\n",
    "    player_surface_cumulative_wins = {}\n",
    "    player_tourney_level_cumulative_counts = {}\n",
    "    player_tourney_level_cumulative_wins = {}\n",
    "\n",
    "    # Lists to store the cumulative match counts for each row\n",
    "    player_1_cumulative_counts_list = []\n",
    "    player_2_cumulative_counts_list = []\n",
    "    player_1_surface_cumulative_counts_list = []\n",
    "    player_2_surface_cumulative_counts_list = []\n",
    "    player_1_surface_cumulative_wins_list = []\n",
    "    player_2_surface_cumulative_wins_list = []\n",
    "    player_1_tourney_level_cumulative_counts_list = []\n",
    "    player_2_tourney_level_cumulative_counts_list = []\n",
    "    player_1_tourney_level_cumulative_wins_list = []\n",
    "    player_2_tourney_level_cumulative_wins_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        player_1_id = row['player_1_id']\n",
    "        player_2_id = row['player_2_id']\n",
    "        surface = row['surface']\n",
    "        tourney_level = row['tourney_level']\n",
    "\n",
    "        # Get the cumulative match counts so far for each player\n",
    "        player_1_cumulative_count = player_cumulative_counts.get(player_1_id, 0)\n",
    "        player_2_cumulative_count = player_cumulative_counts.get(player_2_id, 0)\n",
    "\n",
    "        # Get the cumulative match counts and wins on the current surface for each player\n",
    "        player_1_surface_cumulative_count = player_surface_cumulative_counts.get((player_1_id, surface), 0)\n",
    "        player_2_surface_cumulative_count = player_surface_cumulative_counts.get((player_2_id, surface), 0)\n",
    "        player_1_surface_cumulative_wins = player_surface_cumulative_wins.get((player_1_id, surface), 0)\n",
    "        player_2_surface_cumulative_wins = player_surface_cumulative_wins.get((player_2_id, surface), 0)\n",
    "\n",
    "        # Get the cumulative match counts and wins on the current tourney level for each player\n",
    "        player_1_tourney_level_cumulative_count = player_tourney_level_cumulative_counts.get((player_1_id, tourney_level), 0)\n",
    "        player_2_tourney_level_cumulative_count = player_tourney_level_cumulative_counts.get((player_2_id, tourney_level), 0)\n",
    "        player_1_tourney_level_cumulative_wins = player_tourney_level_cumulative_wins.get((player_1_id, tourney_level), 0)\n",
    "        player_2_tourney_level_cumulative_wins = player_tourney_level_cumulative_wins.get((player_2_id, tourney_level), 0)\n",
    "\n",
    "        # Update the cumulative match counts and wins for each player, surface and tourney level in the current players' lists\n",
    "        player_1_cumulative_counts_list.append(player_1_cumulative_count)\n",
    "        player_2_cumulative_counts_list.append(player_2_cumulative_count)\n",
    "        player_1_surface_cumulative_counts_list.append(player_1_surface_cumulative_count)\n",
    "        player_2_surface_cumulative_counts_list.append(player_2_surface_cumulative_count)\n",
    "        player_1_tourney_level_cumulative_counts_list.append(player_1_tourney_level_cumulative_count)\n",
    "        player_2_tourney_level_cumulative_counts_list.append(player_2_tourney_level_cumulative_count)\n",
    "\n",
    "        # Calculate and update the cumulative match won percentage on the current surface for each player\n",
    "        player_1_surface_cumulative_wins_percentage = (\n",
    "            player_1_surface_cumulative_wins / player_1_surface_cumulative_count\n",
    "        ) if player_1_surface_cumulative_count > 0 else 0.0\n",
    "        player_2_surface_cumulative_wins_percentage = (\n",
    "            player_2_surface_cumulative_wins / player_2_surface_cumulative_count\n",
    "        ) if player_2_surface_cumulative_count > 0 else 0.0\n",
    "\n",
    "        player_1_surface_cumulative_wins_list.append(player_1_surface_cumulative_wins_percentage)\n",
    "        player_2_surface_cumulative_wins_list.append(player_2_surface_cumulative_wins_percentage)\n",
    "\n",
    "        # Calculate and update the cumulative match won percentage on the current tourney level for each player\n",
    "        player_1_tourney_level_cumulative_wins_percentage = (\n",
    "            player_1_tourney_level_cumulative_wins / player_1_tourney_level_cumulative_count\n",
    "        ) if player_1_tourney_level_cumulative_count > 0 else 0.0\n",
    "        player_2_tourney_level_cumulative_wins_percentage = (\n",
    "            player_2_tourney_level_cumulative_wins / player_2_tourney_level_cumulative_count\n",
    "        ) if player_2_tourney_level_cumulative_count > 0 else 0.0\n",
    "\n",
    "        player_1_tourney_level_cumulative_wins_list.append(player_1_tourney_level_cumulative_wins_percentage)\n",
    "        player_2_tourney_level_cumulative_wins_list.append(player_2_tourney_level_cumulative_wins_percentage)\n",
    "\n",
    "        # Increment the cumulative match counts and wins for each player and surface in the dictionaries\n",
    "        player_cumulative_counts[player_1_id] = player_1_cumulative_count + 1\n",
    "        player_cumulative_counts[player_2_id] = player_2_cumulative_count + 1\n",
    "        player_surface_cumulative_counts[(player_1_id, surface)] = player_1_surface_cumulative_count + 1\n",
    "        player_surface_cumulative_counts[(player_2_id, surface)] = player_2_surface_cumulative_count + 1\n",
    "        player_tourney_level_cumulative_counts[(player_1_id, tourney_level)] = player_1_tourney_level_cumulative_count + 1\n",
    "        player_tourney_level_cumulative_counts[(player_2_id, tourney_level)] = player_2_tourney_level_cumulative_count + 1\n",
    "\n",
    "        # Increment the cumulative match wins on the current surface for the winner\n",
    "        if row['winner'] == 'player_1':\n",
    "            player_surface_cumulative_wins[(player_1_id, surface)] = player_1_surface_cumulative_wins + 1\n",
    "        else:\n",
    "            player_surface_cumulative_wins[(player_2_id, surface)] = player_2_surface_cumulative_wins + 1\n",
    "\n",
    "        # Increment the cumulative match wins on the current tourney level for the winner\n",
    "        if row['winner'] == 'player_1':\n",
    "            player_tourney_level_cumulative_wins[(player_1_id, tourney_level)] = player_1_tourney_level_cumulative_wins + 1\n",
    "        else:\n",
    "            player_tourney_level_cumulative_wins[(player_2_id, tourney_level)] = player_2_tourney_level_cumulative_wins + 1\n",
    "\n",
    "    # Add the cumulative match count and surface- and tourney level-related columns to the input dataset\n",
    "    df['player_1_cum_match_count'] = player_1_cumulative_counts_list\n",
    "    df['player_2_cum_match_count'] = player_2_cumulative_counts_list\n",
    "    df['player_1_surface_cum_match_count'] = player_1_surface_cumulative_counts_list\n",
    "    df['player_2_surface_cum_match_count'] = player_2_surface_cumulative_counts_list\n",
    "    df['player_1_surface_cum_win_percentage'] = player_1_surface_cumulative_wins_list\n",
    "    df['player_2_surface_cum_win_percentage'] = player_2_surface_cumulative_wins_list\n",
    "    df['player_1_tourney_level_cum_match_count'] = player_1_tourney_level_cumulative_counts_list\n",
    "    df['player_2_tourney_level_cum_match_count'] = player_2_tourney_level_cumulative_counts_list\n",
    "    df['player_1_tourney_level_cum_win_percentage'] = player_1_tourney_level_cumulative_wins_list\n",
    "    df['player_2_tourney_level_cum_win_percentage'] = player_2_tourney_level_cumulative_wins_list\n",
    "\n",
    "    # Add win percentage difference columns for surface- and tourney level\n",
    "    df['surface_win_pct_difference'] = df['player_1_surface_cum_win_percentage'] - df['player_2_surface_cum_win_percentage']\n",
    "    df['tourney_level_win_pct_difference'] = df['player_1_tourney_level_cum_win_percentage'] - df['player_2_tourney_level_cum_win_percentage']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the data\n",
    "matches_features_df = calc_cum_match_counts_and_pct(matches_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the function on some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>match_num</th>\n",
       "      <th>surface</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>winner</th>\n",
       "      <th>player_1_surface_cum_win_percentage</th>\n",
       "      <th>player_2_surface_cum_win_percentage</th>\n",
       "      <th>player_1_tourney_level_cum_win_percentage</th>\n",
       "      <th>player_2_tourney_level_cum_win_percentage</th>\n",
       "      <th>surface_win_pct_difference</th>\n",
       "      <th>tourney_level_win_pct_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Jens Knippschild</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>17</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>4</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Juan Carlos Ferrero</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Australian Open</td>\n",
       "      <td>2000-01-17</td>\n",
       "      <td>52</td>\n",
       "      <td>Hard</td>\n",
       "      <td>G</td>\n",
       "      <td>Michael Chang</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Australian Open</td>\n",
       "      <td>2000-01-17</td>\n",
       "      <td>90</td>\n",
       "      <td>Hard</td>\n",
       "      <td>G</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Jan Kroslak</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64434</th>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>148</td>\n",
       "      <td>Grass</td>\n",
       "      <td>G</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64473</th>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>188</td>\n",
       "      <td>Grass</td>\n",
       "      <td>G</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Richard Gasquet</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64493</th>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>208</td>\n",
       "      <td>Grass</td>\n",
       "      <td>G</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Cameron Norrie</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64503</th>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>218</td>\n",
       "      <td>Grass</td>\n",
       "      <td>G</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Lorenzo Sonego</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64508</th>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>223</td>\n",
       "      <td>Grass</td>\n",
       "      <td>G</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>Hubert Hurkacz</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1493 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tourney_name tourney_date_dt  match_num surface tourney_level  \\\n",
       "1             Adelaide      2000-01-03          2    Hard             A   \n",
       "16            Adelaide      2000-01-03         17    Hard             A   \n",
       "96            Auckland      2000-01-10          4    Hard             A   \n",
       "206    Australian Open      2000-01-17         52    Hard             G   \n",
       "244    Australian Open      2000-01-17         90    Hard             G   \n",
       "...                ...             ...        ...     ...           ...   \n",
       "64434        Wimbledon      2021-06-28        148   Grass             G   \n",
       "64473        Wimbledon      2021-06-28        188   Grass             G   \n",
       "64493        Wimbledon      2021-06-28        208   Grass             G   \n",
       "64503        Wimbledon      2021-06-28        218   Grass             G   \n",
       "64508        Wimbledon      2021-06-28        223   Grass             G   \n",
       "\n",
       "             player_1_name     player_2_name    winner  \\\n",
       "1            Roger Federer  Jens Knippschild  player_1   \n",
       "16          Thomas Enqvist     Roger Federer  player_1   \n",
       "96     Juan Carlos Ferrero     Roger Federer  player_1   \n",
       "206          Michael Chang     Roger Federer  player_2   \n",
       "244          Roger Federer       Jan Kroslak  player_1   \n",
       "...                    ...               ...       ...   \n",
       "64434        Roger Federer  Adrian Mannarino  player_1   \n",
       "64473        Roger Federer   Richard Gasquet  player_1   \n",
       "64493        Roger Federer    Cameron Norrie  player_1   \n",
       "64503        Roger Federer    Lorenzo Sonego  player_1   \n",
       "64508        Roger Federer    Hubert Hurkacz  player_2   \n",
       "\n",
       "       player_1_surface_cum_win_percentage  \\\n",
       "1                                    0.000   \n",
       "16                                   1.000   \n",
       "96                                   0.000   \n",
       "206                                  0.800   \n",
       "244                                  0.500   \n",
       "...                                    ...   \n",
       "64434                                0.879   \n",
       "64473                                0.880   \n",
       "64493                                0.880   \n",
       "64503                                0.881   \n",
       "64508                                0.881   \n",
       "\n",
       "       player_2_surface_cum_win_percentage  \\\n",
       "1                                    0.000   \n",
       "16                                   1.000   \n",
       "96                                   0.500   \n",
       "206                                  0.333   \n",
       "244                                  0.500   \n",
       "...                                    ...   \n",
       "64434                                0.589   \n",
       "64473                                0.676   \n",
       "64493                                0.524   \n",
       "64503                                0.688   \n",
       "64508                                0.571   \n",
       "\n",
       "       player_1_tourney_level_cum_win_percentage  \\\n",
       "1                                          0.000   \n",
       "16                                         1.000   \n",
       "96                                         0.000   \n",
       "206                                        0.000   \n",
       "244                                        1.000   \n",
       "...                                          ...   \n",
       "64434                                      0.865   \n",
       "64473                                      0.866   \n",
       "64493                                      0.866   \n",
       "64503                                      0.866   \n",
       "64508                                      0.867   \n",
       "\n",
       "       player_2_tourney_level_cum_win_percentage  surface_win_pct_difference  \\\n",
       "1                                          0.000                       0.000   \n",
       "16                                         1.000                       0.000   \n",
       "96                                         0.500                      -0.500   \n",
       "206                                        0.000                       0.467   \n",
       "244                                        1.000                       0.000   \n",
       "...                                          ...                         ...   \n",
       "64434                                      0.429                       0.290   \n",
       "64473                                      0.637                       0.203   \n",
       "64493                                      0.462                       0.356   \n",
       "64503                                      0.476                       0.193   \n",
       "64508                                      0.455                       0.310   \n",
       "\n",
       "       tourney_level_win_pct_difference  \n",
       "1                                 0.000  \n",
       "16                                0.000  \n",
       "96                               -0.500  \n",
       "206                               0.000  \n",
       "244                               0.000  \n",
       "...                                 ...  \n",
       "64434                             0.437  \n",
       "64473                             0.228  \n",
       "64493                             0.404  \n",
       "64503                             0.390  \n",
       "64508                             0.412  \n",
       "\n",
       "[1493 rows x 14 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test surface win pct and tourney level win pct for one player\n",
    "matches_features_df[(matches_features_df['player_1_name'] == 'Roger Federer') \n",
    "                     |\n",
    "                     (matches_features_df['player_2_name'] == 'Roger Federer')][['tourney_name', 'tourney_date_dt', 'match_num', 'surface', 'tourney_level'\n",
    "                                                                                , 'player_1_name', 'player_2_name'\n",
    "                                                                                , 'winner'\n",
    "                                                                                 , 'player_1_surface_cum_win_percentage','player_2_surface_cum_win_percentage'\n",
    "                                                                                 , 'player_1_tourney_level_cum_win_percentage','player_2_tourney_level_cum_win_percentage'\n",
    "                                                                                 , 'surface_win_pct_difference', 'tourney_level_win_pct_difference'\n",
    "                                                                                 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>match_num</th>\n",
       "      <th>surface</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>winner</th>\n",
       "      <th>player_1_surface_cum_win_percentage</th>\n",
       "      <th>player_2_surface_cum_win_percentage</th>\n",
       "      <th>player_1_tourney_level_cum_win_percentage</th>\n",
       "      <th>player_2_tourney_level_cum_win_percentage</th>\n",
       "      <th>surface_win_pct_difference</th>\n",
       "      <th>tourney_level_win_pct_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Arnaud Clement</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>17</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>25</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Sebastien Grosjean</td>\n",
       "      <td>player_1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>29</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Magnus Norman</td>\n",
       "      <td>player_1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>31</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Lleyton Hewitt</td>\n",
       "      <td>player_2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17849</th>\n",
       "      <td>Roland Garros</td>\n",
       "      <td>2005-05-23</td>\n",
       "      <td>47</td>\n",
       "      <td>Clay</td>\n",
       "      <td>G</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Lukas Dlouhy</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2005-06-20</td>\n",
       "      <td>6</td>\n",
       "      <td>Grass</td>\n",
       "      <td>G</td>\n",
       "      <td>Hyung Taik Lee</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19341</th>\n",
       "      <td>Stockholm</td>\n",
       "      <td>2005-10-10</td>\n",
       "      <td>7</td>\n",
       "      <td>Hard</td>\n",
       "      <td>A</td>\n",
       "      <td>Rainer Schuettler</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19477</th>\n",
       "      <td>Lyon</td>\n",
       "      <td>2005-10-24</td>\n",
       "      <td>3</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>A</td>\n",
       "      <td>Gregory Carraz</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19492</th>\n",
       "      <td>Lyon</td>\n",
       "      <td>2005-10-24</td>\n",
       "      <td>18</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>A</td>\n",
       "      <td>Mario Ancic</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.553</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tourney_name tourney_date_dt  match_num surface tourney_level  \\\n",
       "0           Adelaide      2000-01-03          1    Hard             A   \n",
       "16          Adelaide      2000-01-03         17    Hard             A   \n",
       "24          Adelaide      2000-01-03         25    Hard             A   \n",
       "28          Adelaide      2000-01-03         29    Hard             A   \n",
       "30          Adelaide      2000-01-03         31    Hard             A   \n",
       "...              ...             ...        ...     ...           ...   \n",
       "17849  Roland Garros      2005-05-23         47    Clay             G   \n",
       "18081      Wimbledon      2005-06-20          6   Grass             G   \n",
       "19341      Stockholm      2005-10-10          7    Hard             A   \n",
       "19477           Lyon      2005-10-24          3  Carpet             A   \n",
       "19492           Lyon      2005-10-24         18  Carpet             A   \n",
       "\n",
       "           player_1_name       player_2_name    winner  \\\n",
       "0         Thomas Enqvist      Arnaud Clement  player_1   \n",
       "16        Thomas Enqvist       Roger Federer  player_1   \n",
       "24        Thomas Enqvist  Sebastien Grosjean  player_1   \n",
       "28        Thomas Enqvist       Magnus Norman  player_1   \n",
       "30        Thomas Enqvist      Lleyton Hewitt  player_2   \n",
       "...                  ...                 ...       ...   \n",
       "17849     Thomas Enqvist        Lukas Dlouhy  player_2   \n",
       "18081     Hyung Taik Lee      Thomas Enqvist  player_1   \n",
       "19341  Rainer Schuettler      Thomas Enqvist  player_1   \n",
       "19477     Gregory Carraz      Thomas Enqvist  player_2   \n",
       "19492        Mario Ancic      Thomas Enqvist  player_1   \n",
       "\n",
       "       player_1_surface_cum_win_percentage  \\\n",
       "0                                    0.000   \n",
       "16                                   1.000   \n",
       "24                                   1.000   \n",
       "28                                   1.000   \n",
       "30                                   1.000   \n",
       "...                                    ...   \n",
       "17849                                0.491   \n",
       "18081                                0.476   \n",
       "19341                                0.594   \n",
       "19477                                0.500   \n",
       "19492                                0.591   \n",
       "\n",
       "       player_2_surface_cum_win_percentage  \\\n",
       "0                                    0.000   \n",
       "16                                   1.000   \n",
       "24                                   1.000   \n",
       "28                                   1.000   \n",
       "30                                   1.000   \n",
       "...                                    ...   \n",
       "17849                                0.000   \n",
       "18081                                0.524   \n",
       "19341                                0.571   \n",
       "19477                                0.619   \n",
       "19492                                0.636   \n",
       "\n",
       "       player_1_tourney_level_cum_win_percentage  \\\n",
       "0                                          0.000   \n",
       "16                                         1.000   \n",
       "24                                         1.000   \n",
       "28                                         1.000   \n",
       "30                                         1.000   \n",
       "...                                          ...   \n",
       "17849                                      0.583   \n",
       "18081                                      0.429   \n",
       "19341                                      0.568   \n",
       "19477                                      0.431   \n",
       "19492                                      0.582   \n",
       "\n",
       "       player_2_tourney_level_cum_win_percentage  surface_win_pct_difference  \\\n",
       "0                                          0.000                       0.000   \n",
       "16                                         1.000                       0.000   \n",
       "24                                         1.000                       0.000   \n",
       "28                                         1.000                       0.000   \n",
       "30                                         1.000                       0.000   \n",
       "...                                          ...                         ...   \n",
       "17849                                      0.000                       0.491   \n",
       "18081                                      0.571                      -0.048   \n",
       "19341                                      0.554                       0.024   \n",
       "19477                                      0.550                      -0.119   \n",
       "19492                                      0.553                      -0.045   \n",
       "\n",
       "       tourney_level_win_pct_difference  \n",
       "0                                 0.000  \n",
       "16                                0.000  \n",
       "24                                0.000  \n",
       "28                                0.000  \n",
       "30                                0.000  \n",
       "...                                 ...  \n",
       "17849                             0.583  \n",
       "18081                            -0.143  \n",
       "19341                             0.015  \n",
       "19477                            -0.119  \n",
       "19492                             0.029  \n",
       "\n",
       "[267 rows x 14 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test surface win pct and tourney level win pct for another player\n",
    "matches_features_df[(matches_features_df['player_1_name'] == 'Thomas Enqvist') \n",
    "                    | (matches_features_df['player_2_name'] == 'Thomas Enqvist')][['tourney_name', 'tourney_date_dt', 'match_num', 'surface', 'tourney_level'\n",
    "                                                                                , 'player_1_name', 'player_2_name'\n",
    "                                                                                , 'winner'\n",
    "                                                                                , 'player_1_surface_cum_win_percentage','player_2_surface_cum_win_percentage'\n",
    "                                                                                , 'player_1_tourney_level_cum_win_percentage','player_2_tourney_level_cum_win_percentage'\n",
    "                                                                                , 'surface_win_pct_difference', 'tourney_level_win_pct_difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>match_num</th>\n",
       "      <th>surface</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>winner</th>\n",
       "      <th>player_1_surface_cum_win_percentage</th>\n",
       "      <th>player_2_surface_cum_win_percentage</th>\n",
       "      <th>surface_win_pct_difference</th>\n",
       "      <th>tourney_level_win_pct_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Tommy Haas</td>\n",
       "      <td>Jeff Tarango</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>2</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Franco Squillari</td>\n",
       "      <td>Juan Balcells</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>3</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Alberto Martin</td>\n",
       "      <td>Alberto Berasategui</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>4</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Juan Carlos Ferrero</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Nicolas Escude</td>\n",
       "      <td>Michael Sell</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>6</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Michael Chang</td>\n",
       "      <td>Byron Black</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>7</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Magnus Gustafsson</td>\n",
       "      <td>Mark Nielsen</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>8</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Thomas Johansson</td>\n",
       "      <td>Glenn Weiner</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>9</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Sjeng Schalken</td>\n",
       "      <td>Goran Ivanisevic</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>10</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Markus Hantschk</td>\n",
       "      <td>Tomas Behrend</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tourney_name tourney_date_dt  match_num surface        player_1_name  \\\n",
       "93      Auckland      2000-01-10          1    Hard           Tommy Haas   \n",
       "94      Auckland      2000-01-10          2    Hard     Franco Squillari   \n",
       "95      Auckland      2000-01-10          3    Hard       Alberto Martin   \n",
       "96      Auckland      2000-01-10          4    Hard  Juan Carlos Ferrero   \n",
       "97      Auckland      2000-01-10          5    Hard       Nicolas Escude   \n",
       "98      Auckland      2000-01-10          6    Hard        Michael Chang   \n",
       "99      Auckland      2000-01-10          7    Hard    Magnus Gustafsson   \n",
       "100     Auckland      2000-01-10          8    Hard     Thomas Johansson   \n",
       "101     Auckland      2000-01-10          9    Hard       Sjeng Schalken   \n",
       "102     Auckland      2000-01-10         10    Hard      Markus Hantschk   \n",
       "\n",
       "           player_2_name    winner  player_1_surface_cum_win_percentage  \\\n",
       "93          Jeff Tarango  player_1                                0.000   \n",
       "94         Juan Balcells  player_2                                0.000   \n",
       "95   Alberto Berasategui  player_1                                0.000   \n",
       "96         Roger Federer  player_1                                0.000   \n",
       "97          Michael Sell  player_2                                0.000   \n",
       "98           Byron Black  player_1                                0.000   \n",
       "99          Mark Nielsen  player_1                                0.000   \n",
       "100         Glenn Weiner  player_1                                0.000   \n",
       "101     Goran Ivanisevic  player_1                                0.000   \n",
       "102        Tomas Behrend  player_2                                0.000   \n",
       "\n",
       "     player_2_surface_cum_win_percentage  surface_win_pct_difference  \\\n",
       "93                                 0.000                       0.000   \n",
       "94                                 0.000                       0.000   \n",
       "95                                 0.000                       0.000   \n",
       "96                                 0.000                       0.000   \n",
       "97                                 0.000                       0.000   \n",
       "98                                 0.000                       0.000   \n",
       "99                                 0.000                       0.000   \n",
       "100                                0.000                       0.000   \n",
       "101                                0.000                       0.000   \n",
       "102                                0.000                       0.000   \n",
       "\n",
       "     tourney_level_win_pct_difference  \n",
       "93                              0.000  \n",
       "94                              0.000  \n",
       "95                              0.000  \n",
       "96                              0.000  \n",
       "97                              0.000  \n",
       "98                              0.000  \n",
       "99                              0.000  \n",
       "100                             0.000  \n",
       "101                             0.000  \n",
       "102                             0.000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for 4 tournaments, each on different surface\n",
    "matches_4surfaces_calc = calc_cum_match_counts_and_pct(matches_4surfaces)\n",
    "matches_4surfaces_calc[['tourney_name', 'tourney_date_dt', 'match_num', 'surface'\n",
    "                                                                                , 'player_1_name', 'player_2_name'\n",
    "                                                                                , 'winner'\n",
    "                                                                                 , 'player_1_surface_cum_win_percentage','player_2_surface_cum_win_percentage'\n",
    "                                                                                 , 'surface_win_pct_difference', 'tourney_level_win_pct_difference']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>match_num</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>player_1_id</th>\n",
       "      <th>player_2_id</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>winner</th>\n",
       "      <th>player_1_tourney_level_cum_win_percentage</th>\n",
       "      <th>player_2_tourney_level_cum_win_percentage</th>\n",
       "      <th>tourney_level_win_pct_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>103163</td>\n",
       "      <td>101543</td>\n",
       "      <td>Tommy Haas</td>\n",
       "      <td>Jeff Tarango</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>102644</td>\n",
       "      <td>102607</td>\n",
       "      <td>Franco Squillari</td>\n",
       "      <td>Juan Balcells</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>103252</td>\n",
       "      <td>102238</td>\n",
       "      <td>Alberto Martin</td>\n",
       "      <td>Alberto Berasategui</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>103507</td>\n",
       "      <td>103819</td>\n",
       "      <td>Juan Carlos Ferrero</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>102765</td>\n",
       "      <td>102103</td>\n",
       "      <td>Nicolas Escude</td>\n",
       "      <td>Michael Sell</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Indian Wells Masters</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>59</td>\n",
       "      <td>M</td>\n",
       "      <td>102882</td>\n",
       "      <td>102854</td>\n",
       "      <td>Mark Philippoussis</td>\n",
       "      <td>Sjeng Schalken</td>\n",
       "      <td>player_1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Indian Wells Masters</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>101948</td>\n",
       "      <td>102358</td>\n",
       "      <td>Pete Sampras</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>player_2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Indian Wells Masters</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>102839</td>\n",
       "      <td>102374</td>\n",
       "      <td>Nicolas Lapentti</td>\n",
       "      <td>Alex Corretja</td>\n",
       "      <td>player_2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>Indian Wells Masters</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>102358</td>\n",
       "      <td>102882</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Mark Philippoussis</td>\n",
       "      <td>player_1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>Indian Wells Masters</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>102358</td>\n",
       "      <td>102374</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Alex Corretja</td>\n",
       "      <td>player_2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tourney_name tourney_date_dt  match_num tourney_level  \\\n",
       "93               Auckland      2000-01-10          1             A   \n",
       "94               Auckland      2000-01-10          2             A   \n",
       "95               Auckland      2000-01-10          3             A   \n",
       "96               Auckland      2000-01-10          4             A   \n",
       "97               Auckland      2000-01-10          5             A   \n",
       "..                    ...             ...        ...           ...   \n",
       "820  Indian Wells Masters      2000-03-13         59             M   \n",
       "821  Indian Wells Masters      2000-03-13         60             M   \n",
       "822  Indian Wells Masters      2000-03-13         61             M   \n",
       "823  Indian Wells Masters      2000-03-13         62             M   \n",
       "824  Indian Wells Masters      2000-03-13         63             M   \n",
       "\n",
       "     player_1_id  player_2_id        player_1_name        player_2_name  \\\n",
       "93        103163       101543           Tommy Haas         Jeff Tarango   \n",
       "94        102644       102607     Franco Squillari        Juan Balcells   \n",
       "95        103252       102238       Alberto Martin  Alberto Berasategui   \n",
       "96        103507       103819  Juan Carlos Ferrero        Roger Federer   \n",
       "97        102765       102103       Nicolas Escude         Michael Sell   \n",
       "..           ...          ...                  ...                  ...   \n",
       "820       102882       102854   Mark Philippoussis       Sjeng Schalken   \n",
       "821       101948       102358         Pete Sampras       Thomas Enqvist   \n",
       "822       102839       102374     Nicolas Lapentti        Alex Corretja   \n",
       "823       102358       102882       Thomas Enqvist   Mark Philippoussis   \n",
       "824       102358       102374       Thomas Enqvist        Alex Corretja   \n",
       "\n",
       "       winner  player_1_tourney_level_cum_win_percentage  \\\n",
       "93   player_1                                      0.000   \n",
       "94   player_2                                      0.500   \n",
       "95   player_1                                      0.667   \n",
       "96   player_1                                      0.000   \n",
       "97   player_2                                      0.750   \n",
       "..        ...                                        ...   \n",
       "820  player_1                                      1.000   \n",
       "821  player_2                                      1.000   \n",
       "822  player_2                                      1.000   \n",
       "823  player_1                                      1.000   \n",
       "824  player_2                                      1.000   \n",
       "\n",
       "     player_2_tourney_level_cum_win_percentage  \\\n",
       "93                                       0.000   \n",
       "94                                       0.000   \n",
       "95                                       0.500   \n",
       "96                                       0.500   \n",
       "97                                       0.000   \n",
       "..                                         ...   \n",
       "820                                      1.000   \n",
       "821                                      1.000   \n",
       "822                                      1.000   \n",
       "823                                      1.000   \n",
       "824                                      1.000   \n",
       "\n",
       "     tourney_level_win_pct_difference  \n",
       "93                              0.000  \n",
       "94                              0.500  \n",
       "95                              0.167  \n",
       "96                             -0.500  \n",
       "97                              0.750  \n",
       "..                                ...  \n",
       "820                             0.000  \n",
       "821                             0.000  \n",
       "822                             0.000  \n",
       "823                             0.000  \n",
       "824                             0.000  \n",
       "\n",
       "[221 rows x 12 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a test dataset for all 5 tournament levels, and preview the columns and sample rows relevant for calculation\n",
    "matches_5levels = matches_features_df[(matches_features_df['tourney_name'].isin(['Auckland', 'Davis Cup QLS R1: GER vs SUI', 'Tour Finals', 'Australian Open', 'Indian Wells Masters',]))\n",
    "\t\t\t\t\t& (matches_features_df['tourney_date'] < 20010000)][['tourney_name', 'tourney_date_dt', 'match_num', 'tourney_level'\n",
    "                                                                                , 'player_1_id', 'player_2_id', 'player_1_name', 'player_2_name'\n",
    "                                                                                , 'winner'\n",
    "                                                                                , 'player_1_tourney_level_cum_win_percentage','player_2_tourney_level_cum_win_percentage'\n",
    "                                                                                , 'tourney_level_win_pct_difference'\n",
    "\t\t\t\t\t                                                    ]]\n",
    "matches_5levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head-to-head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the head-to-head record for two players, and expresses the result as a percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_h2h_win_pct(df):\n",
    "\n",
    "\n",
    "    # Create a dictionary to store cumulative wins and matches for each pair of players\n",
    "    h2h_stats = {}\n",
    "\n",
    "    # Initialize new columns\n",
    "    df['player_1_h2h_win_pct'] = 0.0\n",
    "    df['player_2_h2h_win_pct'] = 0.0\n",
    "\n",
    "    # Calculate head-to-head win percentage\n",
    "    for index, row in df.iterrows():\n",
    "        player_1_id = row['player_1_id']\n",
    "        player_2_id = row['player_2_id']\n",
    "        winner = row['winner']\n",
    "\n",
    "        # Create a unique key for the pair of players\n",
    "        player_pair_key = tuple(sorted([player_1_id, player_2_id]))\n",
    "\n",
    "        # Update head-to-head stats for the player pair\n",
    "        h2h_stats[player_pair_key] = h2h_stats.get(player_pair_key, {'ppk_1_wins': 0, 'ppk_2_wins': 0, 'matches': 0}) # ppk stands for \"player pair key\"\n",
    "\n",
    "        # Calculate and update head-to-head win percentages\n",
    "        if h2h_stats[player_pair_key]['matches'] == 0:\n",
    "            # At the first match, both win percentages are set to 0\n",
    "            df.at[index, 'player_1_h2h_win_pct'] = 0.0\n",
    "            df.at[index, 'player_2_h2h_win_pct'] = 0.0\n",
    "        else:\n",
    "            # For subsequent matches, calculate based on the previous match\n",
    "            if player_1_id == player_pair_key[0]: \n",
    "                player_1_win_pct = h2h_stats[player_pair_key]['ppk_1_wins'] / h2h_stats[player_pair_key]['matches']\n",
    "            else: \n",
    "                player_1_win_pct = h2h_stats[player_pair_key]['ppk_2_wins'] / h2h_stats[player_pair_key]['matches']\n",
    "            df.at[index, 'player_1_h2h_win_pct'] = player_1_win_pct\n",
    "            df.at[index, 'player_2_h2h_win_pct'] = 1.0 - player_1_win_pct\n",
    "\n",
    "        # Update head-to-head stats for the player pair after the match\n",
    "        h2h_stats[player_pair_key]['matches'] += 1\n",
    "        if ((winner == 'player_1') & (player_1_id == player_pair_key[0]) | (winner == 'player_2') & (player_2_id == player_pair_key[0])):\n",
    "            h2h_stats[player_pair_key]['ppk_1_wins'] += 1\n",
    "        else:\n",
    "            h2h_stats[player_pair_key]['ppk_2_wins'] += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the data\n",
    "matches_features_df = calc_h2h_win_pct(matches_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a h2h difference\n",
    "matches_features_df['h2h_win_pct_difference'] = matches_features_df['player_1_h2h_win_pct'] - matches_features_df['player_2_h2h_win_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date_dt</th>\n",
       "      <th>match_num</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>round</th>\n",
       "      <th>player_1_id</th>\n",
       "      <th>player_2_id</th>\n",
       "      <th>player_1_name</th>\n",
       "      <th>player_2_name</th>\n",
       "      <th>player_1_rank</th>\n",
       "      <th>player_2_rank</th>\n",
       "      <th>winner</th>\n",
       "      <th>player_1_h2h_win_pct</th>\n",
       "      <th>player_2_h2h_win_pct</th>\n",
       "      <th>h2h_win_pct_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62808</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>287</td>\n",
       "      <td>A</td>\n",
       "      <td>R16</td>\n",
       "      <td>126094</td>\n",
       "      <td>206173</td>\n",
       "      <td>Andrey Rublev</td>\n",
       "      <td>Jannik Sinner</td>\n",
       "      <td>8.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63817</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>2021-04-19</td>\n",
       "      <td>295</td>\n",
       "      <td>A</td>\n",
       "      <td>QF</td>\n",
       "      <td>126094</td>\n",
       "      <td>206173</td>\n",
       "      <td>Andrey Rublev</td>\n",
       "      <td>Jannik Sinner</td>\n",
       "      <td>7.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>player_2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66658</th>\n",
       "      <td>Monte Carlo Masters</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>287</td>\n",
       "      <td>M</td>\n",
       "      <td>R16</td>\n",
       "      <td>126094</td>\n",
       "      <td>206173</td>\n",
       "      <td>Andrey Rublev</td>\n",
       "      <td>Jannik Sinner</td>\n",
       "      <td>8.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67080</th>\n",
       "      <td>Roland Garros</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>218</td>\n",
       "      <td>G</td>\n",
       "      <td>R16</td>\n",
       "      <td>126094</td>\n",
       "      <td>206173</td>\n",
       "      <td>Andrey Rublev</td>\n",
       "      <td>Jannik Sinner</td>\n",
       "      <td>7.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>player_1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>-0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69453</th>\n",
       "      <td>Miami Masters</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>290</td>\n",
       "      <td>M</td>\n",
       "      <td>R16</td>\n",
       "      <td>126094</td>\n",
       "      <td>206173</td>\n",
       "      <td>Andrey Rublev</td>\n",
       "      <td>Jannik Sinner</td>\n",
       "      <td>7.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>player_2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tourney_name tourney_date_dt  match_num tourney_level round  \\\n",
       "62808               Vienna      2020-10-26        287             A   R16   \n",
       "63817            Barcelona      2021-04-19        295             A    QF   \n",
       "66658  Monte Carlo Masters      2022-04-11        287             M   R16   \n",
       "67080        Roland Garros      2022-05-23        218             G   R16   \n",
       "69453        Miami Masters      2023-03-20        290             M   R16   \n",
       "\n",
       "       player_1_id  player_2_id  player_1_name  player_2_name  player_1_rank  \\\n",
       "62808       126094       206173  Andrey Rublev  Jannik Sinner          8.000   \n",
       "63817       126094       206173  Andrey Rublev  Jannik Sinner          7.000   \n",
       "66658       126094       206173  Andrey Rublev  Jannik Sinner          8.000   \n",
       "67080       126094       206173  Andrey Rublev  Jannik Sinner          7.000   \n",
       "69453       126094       206173  Andrey Rublev  Jannik Sinner          7.000   \n",
       "\n",
       "       player_2_rank    winner  player_1_h2h_win_pct  player_2_h2h_win_pct  \\\n",
       "62808         43.000  player_1                 0.000                 0.000   \n",
       "63817         19.000  player_2                 1.000                 0.000   \n",
       "66658         12.000  player_2                 0.500                 0.500   \n",
       "67080         12.000  player_1                 0.333                 0.667   \n",
       "69453         11.000  player_2                 0.500                 0.500   \n",
       "\n",
       "       h2h_win_pct_difference  \n",
       "62808                   0.000  \n",
       "63817                   1.000  \n",
       "66658                   0.000  \n",
       "67080                  -0.333  \n",
       "69453                   0.000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a test dataset for 2 players' head-to-head matches, and preview the columns and sample rows relevant for calculation\n",
    "\n",
    "matches_2players = matches_features_df[((matches_features_df['player_1_name'] == 'Andrey Rublev') & (matches_features_df['player_2_name'] == 'Jannik Sinner')) | \n",
    "                 ((matches_features_df['player_1_name'] == 'Jannik Sinner') & (matches_features_df['player_2_name'] == 'Andrey Rublev'))][['tourney_name', 'tourney_date_dt', 'match_num', 'tourney_level', 'round'\n",
    "                                                                                                                                        , 'player_1_id', 'player_2_id'\n",
    "                                                                                                                                        , 'player_1_name', 'player_2_name'\n",
    "                                                                                                                                        , 'player_1_rank', 'player_2_rank'\n",
    "                                                                                                                                        , 'winner'\n",
    "                                                                                                                                        , 'player_1_h2h_win_pct','player_2_h2h_win_pct'\n",
    "                                                                                                                                        , 'h2h_win_pct_difference'\n",
    "                                                                                                                                        ]]\n",
    "matches_2players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recent form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basics first before moving to the prediction models: what features are we left with after data processing and feature engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70910 entries, 0 to 70909\n",
      "Data columns (total 50 columns):\n",
      " #   Column                                     Non-Null Count  Dtype         \n",
      "---  ------                                     --------------  -----         \n",
      " 0   tourney_id                                 70910 non-null  object        \n",
      " 1   tourney_name                               70910 non-null  object        \n",
      " 2   surface                                    70910 non-null  object        \n",
      " 3   draw_size                                  70910 non-null  int64         \n",
      " 4   tourney_level                              70910 non-null  object        \n",
      " 5   tourney_date                               70910 non-null  int64         \n",
      " 6   match_num                                  70910 non-null  int64         \n",
      " 7   score                                      70910 non-null  object        \n",
      " 8   best_of                                    70910 non-null  int64         \n",
      " 9   round                                      70910 non-null  object        \n",
      " 10  minutes                                    63229 non-null  float64       \n",
      " 11  player_1_name                              70910 non-null  object        \n",
      " 12  player_2_name                              70910 non-null  object        \n",
      " 13  player_1_id                                70910 non-null  int64         \n",
      " 14  player_2_id                                70910 non-null  int64         \n",
      " 15  player_1_seed                              38952 non-null  float64       \n",
      " 16  player_2_seed                              6638 non-null   float64       \n",
      " 17  player_1_entry                             2772 non-null   object        \n",
      " 18  player_2_entry                             20699 non-null  object        \n",
      " 19  player_1_hand                              70902 non-null  object        \n",
      " 20  player_2_hand                              70867 non-null  object        \n",
      " 21  player_1_ht                                69489 non-null  float64       \n",
      " 22  player_2_ht                                67438 non-null  float64       \n",
      " 23  player_1_ioc                               70910 non-null  object        \n",
      " 24  player_2_ioc                               70910 non-null  object        \n",
      " 25  player_1_age                               70908 non-null  float64       \n",
      " 26  player_2_age                               70901 non-null  float64       \n",
      " 27  player_1_rank                              70910 non-null  float64       \n",
      " 28  player_2_rank                              70910 non-null  float64       \n",
      " 29  player_1_rank_points                       70650 non-null  float64       \n",
      " 30  player_2_rank_points                       69210 non-null  float64       \n",
      " 31  winner                                     70910 non-null  object        \n",
      " 32  tourney_date_dt                            70910 non-null  datetime64[ns]\n",
      " 33  tourney_date_dt_preceding_monday           70910 non-null  datetime64[ns]\n",
      " 34  ranking_difference                         70910 non-null  float64       \n",
      " 35  player_1_cum_match_count                   70910 non-null  int64         \n",
      " 36  player_2_cum_match_count                   70910 non-null  int64         \n",
      " 37  player_1_surface_cum_match_count           70910 non-null  int64         \n",
      " 38  player_2_surface_cum_match_count           70910 non-null  int64         \n",
      " 39  player_1_surface_cum_win_percentage        70910 non-null  float64       \n",
      " 40  player_2_surface_cum_win_percentage        70910 non-null  float64       \n",
      " 41  player_1_tourney_level_cum_match_count     70910 non-null  int64         \n",
      " 42  player_2_tourney_level_cum_match_count     70910 non-null  int64         \n",
      " 43  player_1_tourney_level_cum_win_percentage  70910 non-null  float64       \n",
      " 44  player_2_tourney_level_cum_win_percentage  70910 non-null  float64       \n",
      " 45  surface_win_pct_difference                 70910 non-null  float64       \n",
      " 46  tourney_level_win_pct_difference           70910 non-null  float64       \n",
      " 47  player_1_h2h_win_pct                       70910 non-null  float64       \n",
      " 48  player_2_h2h_win_pct                       70910 non-null  float64       \n",
      " 49  h2h_win_pct_difference                     70910 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(21), int64(12), object(15)\n",
      "memory usage: 27.1+ MB\n"
     ]
    }
   ],
   "source": [
    "matches_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have engineered so far these features for assisting our prediction model:\n",
    "- ranking_difference\n",
    "- player_1_surface_cum_win_percentage     \n",
    "- player_2_surface_cum_win_percentage\n",
    "- surface_win_pct_difference\n",
    "- player_1_tourney_level_cum_win_percentage\n",
    "- player_2_tourney_level_cum_win_percentage\n",
    "- tourney_level_win_pct_difference\n",
    "- player_1_h2h_win_pct \n",
    "- player_2_h2h_win_pct\n",
    "- h2h_win_pct_difference\n",
    "\n",
    "The majority of the other features in our dataset are probably not needed,  # , 'player_1_tourney_level_cum_win_percentage'\n",
    "                                                        # , 'player_2_tourney_level_cum_win_percentage'and when applying encoding, we'll end up with a lot of additional useless features. \n",
    "So as a final step, we remove unused features from out dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_id                                       0\n",
       "tourney_name                                     0\n",
       "surface                                          0\n",
       "draw_size                                        0\n",
       "tourney_level                                    0\n",
       "tourney_date                                     0\n",
       "match_num                                        0\n",
       "score                                            0\n",
       "best_of                                          0\n",
       "round                                            0\n",
       "minutes                                       7681\n",
       "player_1_name                                    0\n",
       "player_2_name                                    0\n",
       "player_1_id                                      0\n",
       "player_2_id                                      0\n",
       "player_1_seed                                31958\n",
       "player_2_seed                                64272\n",
       "player_1_entry                               68138\n",
       "player_2_entry                               50211\n",
       "player_1_hand                                    8\n",
       "player_2_hand                                   43\n",
       "player_1_ht                                   1421\n",
       "player_2_ht                                   3472\n",
       "player_1_ioc                                     0\n",
       "player_2_ioc                                     0\n",
       "player_1_age                                     2\n",
       "player_2_age                                     9\n",
       "player_1_rank                                    0\n",
       "player_2_rank                                    0\n",
       "player_1_rank_points                           260\n",
       "player_2_rank_points                          1700\n",
       "winner                                           0\n",
       "tourney_date_dt                                  0\n",
       "tourney_date_dt_preceding_monday                 0\n",
       "ranking_difference                               0\n",
       "player_1_cum_match_count                         0\n",
       "player_2_cum_match_count                         0\n",
       "player_1_surface_cum_match_count                 0\n",
       "player_2_surface_cum_match_count                 0\n",
       "player_1_surface_cum_win_percentage              0\n",
       "player_2_surface_cum_win_percentage              0\n",
       "player_1_tourney_level_cum_match_count           0\n",
       "player_2_tourney_level_cum_match_count           0\n",
       "player_1_tourney_level_cum_win_percentage        0\n",
       "player_2_tourney_level_cum_win_percentage        0\n",
       "surface_win_pct_difference                       0\n",
       "tourney_level_win_pct_difference                 0\n",
       "player_1_h2h_win_pct                             0\n",
       "player_2_h2h_win_pct                             0\n",
       "h2h_win_pct_difference                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_features_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_date_dt\n",
       "2001    3395\n",
       "2002    3206\n",
       "2003    3108\n",
       "2004    3279\n",
       "2005    3253\n",
       "2006    3254\n",
       "2007    3274\n",
       "2008    3012\n",
       "2009    3070\n",
       "2010    3013\n",
       "2011    3001\n",
       "2012    3086\n",
       "2013    2940\n",
       "2014    2813\n",
       "2015    2937\n",
       "2016    2922\n",
       "2017    2896\n",
       "2018    2967\n",
       "2019    2701\n",
       "2020    1456\n",
       "2021    2713\n",
       "2022    2900\n",
       "2023    2352\n",
       "Name: tourney_id, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove data for the year 2000, so the majority of features with values = 0 is removed\n",
    "matches_features_df = matches_features_df[matches_features_df['tourney_date_dt'].dt.year > 2000]\n",
    "matches_features_df.groupby(matches_features_df['tourney_date_dt'].dt.year)['tourney_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 67548 entries, 3362 to 70909\n",
      "Data columns (total 5 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   winner                            67548 non-null  object \n",
      " 1   ranking_difference                67548 non-null  float64\n",
      " 2   surface_win_pct_difference        67548 non-null  float64\n",
      " 3   tourney_level_win_pct_difference  67548 non-null  float64\n",
      " 4   h2h_win_pct_difference            67548 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "matches_features_trimmed_df = matches_features_df.drop(columns=[\n",
    "                                                        'tourney_id'\n",
    "                                                        , 'tourney_name'\n",
    "                                                        , 'surface'\n",
    "                                                        , 'draw_size'\n",
    "                                                        , 'tourney_level'\n",
    "                                                        , 'tourney_date'\n",
    "                                                        , 'match_num'\n",
    "                                                        , 'score'\n",
    "                                                        , 'best_of'\n",
    "                                                        , 'round'\n",
    "                                                        , 'minutes'\n",
    "                                                        , 'player_1_name'\n",
    "                                                        , 'player_2_name'\n",
    "                                                        , 'player_1_id'\n",
    "                                                        , 'player_2_id'\n",
    "                                                        , 'player_1_seed'\n",
    "                                                        , 'player_2_seed'\n",
    "                                                        , 'player_1_entry'\n",
    "                                                        , 'player_2_entry'\n",
    "                                                        , 'player_1_hand'\n",
    "                                                        , 'player_2_hand'\n",
    "                                                        , 'player_1_ht'\n",
    "                                                        , 'player_2_ht'\n",
    "                                                        , 'player_1_ioc'\n",
    "                                                        , 'player_2_ioc'\n",
    "                                                        , 'player_1_age'\n",
    "                                                        , 'player_2_age'\n",
    "                                                        , 'player_1_rank'\n",
    "                                                        , 'player_2_rank'\n",
    "                                                        , 'player_1_rank_points'\n",
    "                                                        , 'player_2_rank_points'\n",
    "                                                        # , 'winner'\n",
    "                                                        , 'tourney_date_dt'\n",
    "                                                        , 'tourney_date_dt_preceding_monday'\n",
    "                                                        #, 'ranking_difference'\n",
    "                                                        , 'player_1_cum_match_count'\n",
    "                                                        , 'player_2_cum_match_count'\n",
    "                                                        , 'player_1_surface_cum_match_count'\n",
    "                                                        , 'player_2_surface_cum_match_count'\n",
    "                                                        , 'player_1_surface_cum_win_percentage'\n",
    "                                                        , 'player_2_surface_cum_win_percentage'\n",
    "                                                        # , 'tourney_level_win_pct_difference'\n",
    "                                                        , 'player_1_tourney_level_cum_match_count'\n",
    "                                                        , 'player_2_tourney_level_cum_match_count'\n",
    "                                                        , 'player_1_tourney_level_cum_win_percentage'\n",
    "                                                        , 'player_2_tourney_level_cum_win_percentage'\n",
    "                                                        #, 'tourney_level_win_pct_difference'\n",
    "                                                        , 'player_1_h2h_win_pct'\n",
    "                                                        , 'player_2_h2h_win_pct'\n",
    "                                                        # , 'h2h_win_pct_difference'\n",
    "                                                        ], axis=1)\n",
    "matches_features_trimmed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67548 entries, 0 to 67547\n",
      "Data columns (total 5 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   winner                            67548 non-null  object \n",
      " 1   ranking_difference                67548 non-null  float64\n",
      " 2   surface_win_pct_difference        67548 non-null  float64\n",
      " 3   tourney_level_win_pct_difference  67548 non-null  float64\n",
      " 4   h2h_win_pct_difference            67548 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# make a new copy of the dataframe, prior to starting the prediction\n",
    "matches_pred_df = matches_features_trimmed_df.copy().reset_index(drop=True)\n",
    "matches_pred_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking_difference</th>\n",
       "      <th>surface_win_pct_difference</th>\n",
       "      <th>tourney_level_win_pct_difference</th>\n",
       "      <th>h2h_win_pct_difference</th>\n",
       "      <th>winner_player_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.982</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.994</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.996</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.994</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ranking_difference  surface_win_pct_difference  \\\n",
       "0                 0.977                       0.297   \n",
       "1                 0.994                       0.333   \n",
       "2                 0.982                      -0.045   \n",
       "3                 0.861                       0.667   \n",
       "4                 0.986                       0.100   \n",
       "..                  ...                         ...   \n",
       "195               0.984                       0.145   \n",
       "196               0.994                      -0.333   \n",
       "197               0.996                      -0.077   \n",
       "198               0.994                      -0.066   \n",
       "199               0.971                      -0.400   \n",
       "\n",
       "     tourney_level_win_pct_difference  h2h_win_pct_difference  winner_player_2  \n",
       "0                               0.466                   0.000            False  \n",
       "1                               0.333                   0.000             True  \n",
       "2                               0.024                   0.000             True  \n",
       "3                               0.686                   0.000            False  \n",
       "4                               0.006                   0.000             True  \n",
       "..                                ...                     ...              ...  \n",
       "195                             0.600                   0.333            False  \n",
       "196                            -0.044                   0.000             True  \n",
       "197                             0.238                   0.000            False  \n",
       "198                            -0.081                  -1.000             True  \n",
       "199                             0.250                   0.000            False  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode categorical data\n",
    "train = pd.get_dummies(matches_pred_df, drop_first=True)\n",
    "train.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67548 entries, 0 to 67547\n",
      "Data columns (total 5 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   ranking_difference                67548 non-null  float64\n",
      " 1   surface_win_pct_difference        67548 non-null  float64\n",
      " 2   tourney_level_win_pct_difference  67548 non-null  float64\n",
      " 3   h2h_win_pct_difference            67548 non-null  float64\n",
      " 4   winner_player_2                   67548 non-null  bool   \n",
      "dtypes: bool(1), float64(4)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67548 entries, 0 to 67547\n",
      "Data columns (total 5 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   ranking_difference                67548 non-null  float64\n",
      " 1   surface_win_pct_difference        67548 non-null  float64\n",
      " 2   tourney_level_win_pct_difference  67548 non-null  float64\n",
      " 3   h2h_win_pct_difference            67548 non-null  float64\n",
      " 4   winner_player_2                   67548 non-null  int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "# convert data type of label from bool to int64\n",
    "train['winner_player_2'] = train['winner_player_2'].astype('int64')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Determine correlations between variables in the dataset\n",
    "corr = train.corr()\n",
    "\n",
    "# Plot the correlations\n",
    "ax = sns.heatmap(corr, annot=True, cmap='coolwarm', cbar_kws={'label': 'Correlation'})\n",
    "ax.set_title(\"Correlations of variables in the full dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- there are no really strong correlation (>0.7 or <-0.7) surface and tourney level have a strong correlation of 0.68 to 0.7\n",
    "- there is a medium strong correlation between surface_win_pct_difference and tourney_level_win_pct_difference\n",
    "\n",
    "Due to the low number of variables, and their insignificant correlation, its probably not beneficial to remove any variables in order to resolve the problem of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Now that the initial datasets have been used, we cleaup the pandas dataframes which are not required anymore to mitigate excessive memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport gc\\n\\ndel matches_2players\\ndel matches_4surfaces\\ndel matches_5levels\\ndel matches_4surfaces_calc\\ndel matches_df\\ndel matches_empty_rank\\ndel matches_features_df\\ndel matches_features_trimmed_df\\ndel matches_lessthan_0mins\\ndel matches_pred_df\\ndel matches_processed_df\\ndel matches_processed_ka_df\\ndel matches_score_text\\ndel matches_tournament_starts\\ndel matches_wins_by_ranking_df\\ndel matches_with_rank\\n\\n# Invoke garbage collector immediately\\ngc.collect()\\n\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import gc\n",
    "\n",
    "del matches_2players\n",
    "del matches_4surfaces\n",
    "del matches_5levels\n",
    "del matches_4surfaces_calc\n",
    "del matches_df\n",
    "del matches_empty_rank\n",
    "del matches_features_df\n",
    "del matches_features_trimmed_df\n",
    "del matches_lessthan_0mins\n",
    "del matches_pred_df\n",
    "del matches_processed_df\n",
    "del matches_processed_ka_df\n",
    "del matches_score_text\n",
    "del matches_tournament_starts\n",
    "del matches_wins_by_ranking_df\n",
    "del matches_with_rank\n",
    "\n",
    "# Invoke garbage collector immediately\n",
    "gc.collect()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we apply several different prediction models to determine which one gives us the most accurate results for predicting the outcome of a match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual vs predicted plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_vs_predicted_plot(y_true, y_pred):\n",
    "  min_value=np.array([y_true.min(), y_pred.min()]).min()\n",
    "  max_value= min=np.array([y_true.max(), y_pred.max()]).max()\n",
    "  fig = plt.figure()\n",
    "  ax = fig.gca()\n",
    "  ax.scatter(y_true,y_pred, color=\"blue\")\n",
    "  ax.plot([min_value,max_value], [min_value, max_value], lw=4, color=\"green\")\n",
    "  ax.set_xlabel('Actual')\n",
    "  ax.set_ylabel('Predicted')\n",
    "  plt.xlim=0\n",
    "  plt.ylim=0\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(model, X_test, y_test):\n",
    "  from sklearn.metrics import RocCurveDisplay\n",
    "  tree_ROC = RocCurveDisplay.from_estimator(model, X_test, y_test, color='green', linewidth=3)\n",
    "  plt.title('ROC Curve')\n",
    "  plt.xlabel('False Alarm (1 - Specificity)')\n",
    "  plt.ylabel('Recall (Sensitivity)')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Player_2_winner = 0', 'Player_2_winner = 1'],\n",
    "                yticklabels=['Player_2_winner = 0', 'Player_2_winner = 1'])\n",
    "    plt.xlabel('Predicted Outcome')\n",
    "    plt.ylabel('Actual Outcome')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot variable importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_importance(model, X_train):\n",
    "  importances = pd.Series(data=model.feature_importances_,\n",
    "                          index=X_train.columns)\n",
    "  importances.sort_values().plot(kind='barh', color=\"#00802F\")\n",
    "  plt.title('Features Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test data\n",
    "We will reuse 2  data sets for training each model and then testing (evaluating) the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"winner_player_2\", axis=1)\n",
    "y = train[\"winner_player_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking_difference</th>\n",
       "      <th>surface_win_pct_difference</th>\n",
       "      <th>tourney_level_win_pct_difference</th>\n",
       "      <th>h2h_win_pct_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.982</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67543</th>\n",
       "      <td>0.989</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67544</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.319</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67545</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67546</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67547</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67548 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ranking_difference  surface_win_pct_difference  \\\n",
       "0                   0.977                       0.297   \n",
       "1                   0.994                       0.333   \n",
       "2                   0.982                      -0.045   \n",
       "3                   0.861                       0.667   \n",
       "4                   0.986                       0.100   \n",
       "...                   ...                         ...   \n",
       "67543               0.989                      -0.002   \n",
       "67544               0.998                       0.249   \n",
       "67545               0.999                       0.009   \n",
       "67546               0.986                       0.296   \n",
       "67547               1.000                       0.092   \n",
       "\n",
       "       tourney_level_win_pct_difference  h2h_win_pct_difference  \n",
       "0                                 0.466                   0.000  \n",
       "1                                 0.333                   0.000  \n",
       "2                                 0.024                   0.000  \n",
       "3                                 0.686                   0.000  \n",
       "4                                 0.006                   0.000  \n",
       "...                                 ...                     ...  \n",
       "67543                            -0.119                   0.000  \n",
       "67544                             0.319                   1.000  \n",
       "67545                             0.095                   0.333  \n",
       "67546                             0.168                   0.000  \n",
       "67547                             0.138                   0.286  \n",
       "\n",
       "[67548 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "67543    1\n",
       "67544    0\n",
       "67545    1\n",
       "67546    0\n",
       "67547    0\n",
       "Name: winner_player_2, Length: 67548, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test data\n",
    "We use a method to split the train and test data 70:30. Note the parameter ```shuffle = False```, which ensures that the temporal order of the data is maintained during the split, reducing the risk of temporal leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.3\n",
    "                                                    , random_state = 8\n",
    "                                                    , shuffle=False\n",
    "                                                    )\n",
    "# Split into a 3rd validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test,\n",
    "                                                    test_size = 0.5\n",
    "                                                    , random_state = 8\n",
    "                                                    , shuffle=False\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation\n",
    "Cross validation and hyperparameter optimisation was done separately - see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probabilities:\n",
      "[[0.87804878 0.12195122]\n",
      " [0.87804878 0.12195122]\n",
      " [0.92971246 0.07028754]\n",
      " ...\n",
      " [0.57152663 0.42847337]\n",
      " [0.71965066 0.28034934]\n",
      " [0.57152663 0.42847337]]\n",
      "Accuracy: 0.652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Instantiate Model\n",
    "model1_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, max_features=4, min_samples_leaf = 10, min_samples_split = 2, random_state=1)\n",
    "\n",
    "# 2. Fit model\n",
    "model1_tree.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make prediction\n",
    "y_pred = model1_tree.predict(X_test)\n",
    "\n",
    "# 4. Get prediction probabilities\n",
    "print('Prediction probabilities:')\n",
    "print(model1_tree.predict_proba(X_test))\n",
    "\n",
    "# 5. Evaluate Model Performance - accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "\n",
    "# 6. Print classification report\n",
    "# y_pred =  (model1_tree.predict_proba(X_test)[:, 1] > 0.1).astype(int)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "###########\n",
    "# Run on 21.12\n",
    "# (criterion=\"entropy\", max_depth=5, max_features = 4, min_samples_leaf = 10, min_samples_split = 2, random_state=1)#\n",
    "# Accuracy score: 0.652\n",
    "###########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Decision Tree model, with 65.2% there is a slightly better accuracy than our benchmark of 65.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_variable_importance(model1_tree, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation and hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.687 total time=   0.2s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.668 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.691 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.658 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=2;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.640 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=3;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.640 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=7;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=2;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=3;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=5;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=10, min_samples_split=7;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=2;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=3;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=5;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=20, min_samples_split=7;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=2;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=3;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=5;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=4, min_samples_leaf=50, min_samples_split=7;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.658 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=2;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.640 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=3;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.640 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=5;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=1, min_samples_split=7;, score=0.683 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=2;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=3;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=5;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=10, min_samples_split=7;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=2;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=3;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=5;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=20, min_samples_split=7;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=2;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=3;, score=0.675 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.636 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=5;, score=0.675 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.676 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=8, min_samples_leaf=50, min_samples_split=7;, score=0.675 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.641 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.658 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.679 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.685 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=2;, score=0.683 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.640 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.679 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.685 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=3;, score=0.683 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.640 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.679 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=5;, score=0.683 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.639 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.679 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.685 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=1, min_samples_split=7;, score=0.683 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.636 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.676 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.681 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=2;, score=0.678 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=3;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=5;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.681 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=10, min_samples_split=7;, score=0.678 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=2;, score=0.674 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=3;, score=0.674 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.639 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=5;, score=0.674 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.639 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.653 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.673 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.673 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=20, min_samples_split=7;, score=0.674 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=2;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=3;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=5;, score=0.675 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.683 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=16, min_samples_leaf=50, min_samples_split=7;, score=0.675 total time=   0.3s\n",
      "Best hyperparameters: {'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Accuracy (trained cv data): 0.680\n",
      "Accuracy (tested on \"unseen\" data): 0.652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# 0. Setting up TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1. Define hyperparameters for GridSearchCV\n",
    "parameters = {\n",
    "            'max_depth': [5, 10],\n",
    "            'max_features': [4, 8, 16], \n",
    "            'min_samples_leaf': [1, 10, 20, 50], \n",
    "            'min_samples_split': [2, 3, 5, 7]\n",
    "            }\n",
    "\n",
    "# 2. Define a scoring function for accuracy\n",
    "acc_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# 3. Define GridSearch CV object\n",
    "model1_tree_CV = GridSearchCV(model1_tree, parameters, scoring=acc_score, cv=tscv, verbose=3) # Apply 5 TimeSeriesSplits to find best hyperparameters\n",
    "\n",
    "# 4. Fit GridSearch CV object to model\n",
    "model1_tree_CV_fitted= model1_tree_CV.fit(X_train, y_train)\n",
    "\n",
    "# 5. Interpret results\n",
    "print(\"Best hyperparameters:\", model1_tree_CV_fitted.best_params_)\n",
    "print(\"Accuracy (trained cv data): %.3f\" % model1_tree_CV_fitted.best_score_)\n",
    "\n",
    "# 6. Evaluation Generalization Performance\n",
    "y_pred_model1 = model1_tree_CV_fitted.predict(X_test)\n",
    "\n",
    "# acc = accuracy_score(y_test, y_pred_model1)\n",
    "print('Accuracy (tested on \"unseen\" data): %.3f' % acc)\n",
    "\n",
    "##########\n",
    "# Last run on 21.12\n",
    "# Tested:\n",
    "# parameters = {\n",
    "#             'max_depth': [5, 10],\n",
    "#              max_features\": [4, 8, 16], \n",
    "#              min_samples_leaf': [1, 10, 20, 50], \n",
    "#              min_samples_split\": [2, 3, 5, 7]\n",
    "#             }\n",
    "# Results:\n",
    "# Best hyperparameters: {'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
    "# Accuracy (trained cv data): 0.680\n",
    "# Accuracy (tested on \"unseen\" data): 0.652\n",
    "##########\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model 2: Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model creation and cross validation for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st attempt (Model 2.1.1 using GridSearchCV and TimeSeriesSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m model2_1_1_rf_CV \u001b[38;5;241m=\u001b[39m GridSearchCV(model2_1_1_rf, parameters, cv\u001b[38;5;241m=\u001b[39mtscv, scoring\u001b[38;5;241m=\u001b[39macc_score, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 4. Fit GridSearchCV to model data\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m model2_1_1_rf_CV_fitted \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2_1_1_rf_CV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# use this for ROC plot\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 5. Interpret results\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model2_1_1_rf_CV_fitted\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/tree/_classes.py:284\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[0;32m--> 284\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/multiclass.py:208\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_classification_targets\u001b[39m(y):\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     ]:\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/multiclass.py:331\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y):\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dev/cas-project/venv_proj/lib/python3.10/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test at 3.1.\n",
    "# Test duration 24m\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "# 0. Use TimeSeriesSplit instead of train_test_split for CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1. Instantiate Model\n",
    "model2_1_1_rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# 2. Define hyperparameters for GridSearchCV\n",
    "parameters = {\n",
    "            'n_estimators': [100, 200],\n",
    "            # 'max_features': [4, 8, 16],\n",
    "            'max_depth': [1,2,3],\n",
    "            'min_samples_split': [3, 5, 7], \n",
    "            # 'min_samples_leaf': [1, 10, 20, 50]\n",
    "            }\n",
    "\n",
    "# 3. Define GridSearchCV object\n",
    "acc_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "model2_1_1_rf_CV = GridSearchCV(model2_1_1_rf, parameters, cv=tscv, scoring=acc_score, verbose=3)\n",
    "\n",
    "\n",
    "# 4. Fit GridSearchCV to model data\n",
    "model2_1_1_rf_CV_fitted = model2_1_1_rf_CV.fit(X_train, y_train) # use this for ROC plot\n",
    "\n",
    "# 5. Interpret results\n",
    "print(\"Best hyperparameters:\", model2_1_1_rf_CV_fitted.best_params_)\n",
    "print(\"Accuracy (trained cv data): %.3f\" % model2_1_1_rf_CV_fitted.best_score_)\n",
    "\n",
    "# -. Get prediction probabilities\n",
    "# y_pred_model2_1_1.predict_proba(X_test)\n",
    "\n",
    "# 6. Evaluate Model Performance - accuracy\n",
    "y_pred_model2_1_1 = model2_1_1_rf_CV.predict(X_test)\n",
    "model2_1_1_acc = accuracy_score(y_test, y_pred_model2_1_1)\n",
    "print('Accuracy (test data): %.3f' % model2_1_1_acc)\n",
    "\n",
    "# -. Print classification report\n",
    "# y_pred =  (model2_1_1_rf.predict_proba(X_test)[:, 1] > 0.1).astype(int)\n",
    "# print(classification_report(y_test, y_pred_model2_1_1))\n",
    "\n",
    "###########\n",
    "# Tested\n",
    "#  parameters = {\n",
    "            # 'n_estimators': [500, 1000],\n",
    "            # 'max_depth': [5, 10],\n",
    "            # 'min_samples_split': [3, 5, 7]\n",
    "#           }\n",
    "# Results\n",
    "# Best hyperparameters: {'max_depth': 5, 'min_samples_split': 7, 'n_estimators': 1000}\n",
    "# Accuracy (trained cv data): 0.683\n",
    "# Accuracy: 0.651\n",
    "###########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Attempt (Model 2.1.2) - using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, n_estimators=700;, score=0.657 total time=  12.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, n_estimators=700;, score=0.671 total time=  19.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, n_estimators=700;, score=0.694 total time=  30.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, n_estimators=700;, score=0.694 total time=  37.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, n_estimators=700;, score=0.691 total time=  47.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, n_estimators=700;, score=0.665 total time=   5.8s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, n_estimators=700;, score=0.674 total time=  10.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, n_estimators=700;, score=0.691 total time=  16.8s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, n_estimators=700;, score=0.693 total time=  22.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, n_estimators=700;, score=0.693 total time=  26.7s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.651 total time=  19.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.657 total time=  38.9s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.681 total time= 1.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.677 total time= 1.4min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.679 total time= 1.8min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, n_estimators=700;, score=0.658 total time=   9.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, n_estimators=700;, score=0.671 total time=  20.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, n_estimators=700;, score=0.695 total time=  29.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, n_estimators=700;, score=0.693 total time=  38.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, n_estimators=700;, score=0.693 total time=  48.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, n_estimators=500;, score=0.659 total time=   6.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, n_estimators=500;, score=0.670 total time=  13.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, n_estimators=500;, score=0.694 total time=  19.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, n_estimators=500;, score=0.692 total time=  26.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, n_estimators=500;, score=0.692 total time=  33.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.658 total time=  14.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.671 total time=  26.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.696 total time=  39.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.694 total time=  54.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.691 total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.658 total time=  15.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.672 total time=  28.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.695 total time=  42.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.693 total time=  55.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.692 total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, n_estimators=500;, score=0.648 total time=  11.0s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, n_estimators=500;, score=0.654 total time=  21.3s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, n_estimators=500;, score=0.675 total time=  33.0s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, n_estimators=500;, score=0.675 total time=  45.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, n_estimators=500;, score=0.678 total time=  55.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, n_estimators=500;, score=0.665 total time=   4.4s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, n_estimators=500;, score=0.673 total time=   8.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, n_estimators=500;, score=0.691 total time=  11.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, n_estimators=500;, score=0.693 total time=  16.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, n_estimators=500;, score=0.692 total time=  19.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.657 total time=  15.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.670 total time=  29.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.695 total time=  41.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.693 total time=  54.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.691 total time= 1.2min\n",
      "Best hyperparameters: {'n_estimators': 700, 'min_samples_leaf': 1, 'max_depth': 5}\n",
      "Accuracy (trained cv data): 0.683\n",
      "Accuracy (test data): 0.651\n"
     ]
    }
   ],
   "source": [
    "# Test at 3.1 \n",
    "# Test duration 18m\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "# 0. Use TimeSeriesSplit instead of train_test_split for CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1. Instantiate Model\n",
    "model2_1_2_rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# 2. Define hyperparameters for RandomizedSearchCV\n",
    "parameters = {\n",
    "            'n_estimators': [500, 700, 1000],\n",
    "            # 'max_features': [4, 8, 16],\n",
    "            'max_depth': [5, 10, 20],\n",
    "            # 'min_samples_split': [2, 3, 5, 7], \n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "            }\n",
    "\n",
    "# 3. Define RandomizedSearchCV object\n",
    "acc_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "model2_1_2_rf_CV = RandomizedSearchCV(model2_1_2_rf, parameters, cv=tscv, scoring=acc_score, verbose=3)\n",
    "\n",
    "\n",
    "# 4. Fit RandomizedSearchCV to model data\n",
    "model2_1_2_rf_CV_fitted = model2_1_2_rf_CV.fit(X_train, y_train) # use this for ROC plot\n",
    "\n",
    "# 5. Interpret results\n",
    "print(\"Best hyperparameters:\", model2_1_2_rf_CV_fitted.best_params_)\n",
    "print(\"Accuracy (trained cv data): %.3f\" % model2_1_2_rf_CV_fitted.best_score_)\n",
    "\n",
    "# -. Get prediction probabilities\n",
    "# y_pred_model2_1_1.predict_proba(X_test)\n",
    "\n",
    "# 6. Evaluate Model Performance - accuracy\n",
    "y_pred_model2_1_2 = model2_1_2_rf_CV.predict(X_test)\n",
    "model2_1_2_acc = accuracy_score(y_test, y_pred_model2_1_2)\n",
    "print('Accuracy (test data): %.3f' % model2_1_2_acc)\n",
    "\n",
    "# -. Print classification report\n",
    "# y_pred =  (model2_1_1_rf.predict_proba(X_test)[:, 1] > 0.1).astype(int)\n",
    "# print(classification_report(y_test, y_pred_model2_1_1))\n",
    "\n",
    "###########\n",
    "# Tested\n",
    "#  parameters = {\n",
    "#               'n_estimators': [500, 700, 1000],\n",
    "                # 'max_depth': [5, 10, 20],\n",
    "#               'min_samples_leaf': [1, 2, 4]\n",
    "#                }\n",
    "# Results\n",
    "# Best hyperparameters: {'n_estimators': 700, 'min_samples_leaf': 1, 'max_depth': 5}\n",
    "# Accuracy (trained cv data): 0.683\n",
    "# Accuracy (test data): 0.651\n",
    "###########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimise the random state of the test data, as we assume the data are not distributed equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Run as one-off \\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\nrandom_state_value = 1\\nresults_random_state_comparison = []\\nfor random_state in range(1, 21):\\n\\n  # 1. Instantiate model\\n  model2_rf  = RandomForestClassifier(random_state=1)\\n\\n  # 2. Fit Model to Data\\n  reg = model2_rf.fit(X_train,y_train)\\n\\n  # 3. Make prediction\\n  y_pred = model2_rf.predict(X_test)\\n\\n  # 4. Evaluate Model Performance - accuracy\\n  acc = accuracy_score(y_test, y_pred)\\n  #print('Accuracy: %.3f' % acc)\\n\\n  results_random_state_comparison.append((random_state_value, acc))\\n  random_state_value = random_state_value+1\\n\\ndf_random_state_results = pd.DataFrame(results_random_state_comparison, columns=['Random State', 'Accuracy'])\\nprint(df_random_state_results)\\n\\n# Result:\\n# Top 2 random_states\\n# randam_state 8 -> Accuracy 0.658\\n# random_state 10, 17, 18, etc. -> Accuracy 0.656\\n\\n# Conclusion: Only random_state 8 will be used from now on as a parameter for the train_test_split() method. All previous models are adapted to \\n#             use random_state 8.\\n\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Run as one-off \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_state_value = 1\n",
    "results_random_state_comparison = []\n",
    "for random_state in range(1, 21):\n",
    "\n",
    "  # 1. Instantiate model\n",
    "  model2_rf  = RandomForestClassifier(random_state=1)\n",
    "\n",
    "  # 2. Fit Model to Data\n",
    "  reg = model2_rf.fit(X_train,y_train)\n",
    "\n",
    "  # 3. Make prediction\n",
    "  y_pred = model2_rf.predict(X_test)\n",
    "\n",
    "  # 4. Evaluate Model Performance - accuracy\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  #print('Accuracy: %.3f' % acc)\n",
    "\n",
    "  results_random_state_comparison.append((random_state_value, acc))\n",
    "  random_state_value = random_state_value+1\n",
    "\n",
    "df_random_state_results = pd.DataFrame(results_random_state_comparison, columns=['Random State', 'Accuracy'])\n",
    "print(df_random_state_results)\n",
    "\n",
    "# Result:\n",
    "# Top 2 random_states\n",
    "# randam_state 8 -> Accuracy 0.658\n",
    "# random_state 10, 17, 18, etc. -> Accuracy 0.656\n",
    "\n",
    "# Conclusion: Only random_state 8 will be used from now on as a parameter for the train_test_split() method. All previous models are adapted to \n",
    "#             use random_state 8.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_variable_importance(model2_1_2_rf_CV_fitted.best_estimator_, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Gradient Booster Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st attempt (Model 3.1.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END max_depth=5, min_samples_split=3, n_estimators=500;, score=0.637 total time=   9.8s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=3, n_estimators=500;, score=0.648 total time=  16.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=3, n_estimators=500;, score=0.681 total time=  25.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=3, n_estimators=500;, score=0.687 total time=  35.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=3, n_estimators=500;, score=0.684 total time=  45.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=3, n_estimators=1000;, score=0.622 total time=  17.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=3, n_estimators=1000;, score=0.632 total time=  33.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=3, n_estimators=1000;, score=0.670 total time=  57.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=3, n_estimators=1000;, score=0.670 total time= 1.3min\n",
      "[CV 5/5] END max_depth=5, min_samples_split=3, n_estimators=1000;, score=0.674 total time= 1.7min\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=500;, score=0.635 total time=   8.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=500;, score=0.648 total time=  18.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=500;, score=0.683 total time=  28.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=500;, score=0.684 total time=  42.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=500;, score=0.682 total time=  53.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=1000;, score=0.621 total time=  17.4s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=1000;, score=0.637 total time=  36.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=1000;, score=0.667 total time=  59.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=1000;, score=0.673 total time= 1.3min\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=1000;, score=0.678 total time= 1.4min\n",
      "[CV 1/5] END max_depth=5, min_samples_split=7, n_estimators=500;, score=0.641 total time=   6.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=7, n_estimators=500;, score=0.645 total time=  13.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=7, n_estimators=500;, score=0.678 total time=  20.8s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=7, n_estimators=500;, score=0.685 total time=  28.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=7, n_estimators=500;, score=0.681 total time=  35.8s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=7, n_estimators=1000;, score=0.624 total time=  13.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=7, n_estimators=1000;, score=0.635 total time=  27.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=7, n_estimators=1000;, score=0.669 total time=  41.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=7, n_estimators=1000;, score=0.673 total time=  56.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=7, n_estimators=1000;, score=0.676 total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_split=3, n_estimators=500;, score=0.612 total time=  14.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=3, n_estimators=500;, score=0.625 total time=  28.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=3, n_estimators=500;, score=0.652 total time=  43.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=3, n_estimators=500;, score=0.655 total time=  58.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=3, n_estimators=500;, score=0.665 total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_split=3, n_estimators=1000;, score=0.611 total time=  29.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=3, n_estimators=1000;, score=0.615 total time=  57.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=3, n_estimators=1000;, score=0.644 total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_split=3, n_estimators=1000;, score=0.647 total time= 1.9min\n",
      "[CV 5/5] END max_depth=10, min_samples_split=3, n_estimators=1000;, score=0.659 total time= 2.4min\n",
      "[CV 1/5] END max_depth=10, min_samples_split=5, n_estimators=500;, score=0.617 total time=  14.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=5, n_estimators=500;, score=0.626 total time=  28.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=5, n_estimators=500;, score=0.656 total time=  42.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=5, n_estimators=500;, score=0.655 total time=  57.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=5, n_estimators=500;, score=0.661 total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_split=5, n_estimators=1000;, score=0.619 total time=  28.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=5, n_estimators=1000;, score=0.622 total time=  55.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=5, n_estimators=1000;, score=0.649 total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_split=5, n_estimators=1000;, score=0.648 total time= 1.9min\n",
      "[CV 5/5] END max_depth=10, min_samples_split=5, n_estimators=1000;, score=0.652 total time= 2.4min\n",
      "[CV 1/5] END max_depth=10, min_samples_split=7, n_estimators=500;, score=0.615 total time=  14.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=7, n_estimators=500;, score=0.628 total time=  27.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=7, n_estimators=500;, score=0.652 total time=  42.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=7, n_estimators=500;, score=0.656 total time=  56.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=7, n_estimators=500;, score=0.663 total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_split=7, n_estimators=1000;, score=0.613 total time=  27.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=7, n_estimators=1000;, score=0.621 total time=  55.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=7, n_estimators=1000;, score=0.645 total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_split=7, n_estimators=1000;, score=0.651 total time= 1.9min\n",
      "[CV 5/5] END max_depth=10, min_samples_split=7, n_estimators=1000;, score=0.652 total time= 2.4min\n",
      "Best hyperparameters: {'max_depth': 5, 'min_samples_split': 3, 'n_estimators': 500}\n",
      "Accuracy (trained cv data): 0.667\n",
      "Accuracy (test data): 0.646\n"
     ]
    }
   ],
   "source": [
    "# Test at 3.1.\n",
    "# Test duration 50m \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "# 0. Use TimeSeriesSplit instead of train_test_split for CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1. Instantiate Model\n",
    "model3_1_1_gb = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "# 2. Define hyperparameters for GridSearchCV\n",
    "parameters = {\n",
    "            'n_estimators': [500, 1000],\n",
    "            # 'max_features': [4, 8, 16],\n",
    "            'max_depth': [5, 10],\n",
    "            'min_samples_split': [3, 5, 7], \n",
    "            # 'min_samples_leaf': [1, 10, 20, 50]\n",
    "            }\n",
    "\n",
    "# 3. Define GridSearchCV object\n",
    "acc_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "model3_1_1_gb_CV = GridSearchCV(model3_1_1_gb, parameters, cv=tscv, scoring=acc_score, verbose=3)\n",
    "\n",
    "\n",
    "# 4. Fit GridSearchCV to model data\n",
    "model3_1_1_gb_CV_fitted = model3_1_1_gb_CV.fit(X_train, y_train) # use this for ROC plot\n",
    "\n",
    "# 5. Interpret results\n",
    "print(\"Best hyperparameters:\", model3_1_1_gb_CV_fitted.best_params_)\n",
    "print(\"Accuracy (trained cv data): %.3f\" % model3_1_1_gb_CV_fitted.best_score_)\n",
    "\n",
    "# -. Get prediction probabilities\n",
    "# y_pred_model2_1_1.predict_proba(X_test)\n",
    "\n",
    "# 6. Evaluate Model Performance - accuracy\n",
    "y_pred_model3_1_1 = model3_1_1_gb_CV.predict(X_test)\n",
    "model3_1_1_acc = accuracy_score(y_test, y_pred_model3_1_1)\n",
    "print('Accuracy (test data): %.3f' % model3_1_1_acc)\n",
    "\n",
    "# -. Print classification report\n",
    "# y_pred =  (model2_1_1_rf.predict_proba(X_test)[:, 1] > 0.1).astype(int)\n",
    "# print(classification_report(y_test, y_pred_model2_1_1))\n",
    "\n",
    "###########\n",
    "# Tested\n",
    "#  parameters = {\n",
    "            # 'n_estimators': [500, 1000],\n",
    "            # 'max_depth': [5, 10],\n",
    "            # 'min_samples_split': [3, 5, 7]\n",
    "#           }\n",
    "# Results\n",
    "# Best hyperparameters: {'max_depth': 5, 'min_samples_split': 3, 'n_estimators': 500}\n",
    "# Accuracy (trained cv data): 0.667\n",
    "# Accuracy (test data): 0.646\n",
    "###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import GradientBoostingClassifier\\n\\nboostedtrees = GradientBoostingClassifier(max_depth= 2, max_features = 8, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 1000, \\n                                         # learning_rate= 0.5,\\n                                        random_state=1)\\n\\n# Create Train Data\\nX = train.drop(\"winner_player_2\", axis=1)\\ny = train[\"winner_player_2\"]\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)\\n\\n# fit model\\nboostedtrees.fit(X_train, y_train)\\n\\n#make prediction\\ny_pred = boostedtrees.predict(X_test)\\n\\n# get prediction probabilities\\nprint(boostedtrees.predict_proba(X_test))\\n\\naccuracy_score(y_test, y_pred)\\n\\n###########\\n# Run on 11.12\\n# Accuracy score: 0.6736 \\n# (max_depth= 2, max_features = 8, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 1000, random_state=1)#\\n###########\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLD VERSION - removed\n",
    "'''\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "boostedtrees = GradientBoostingClassifier(max_depth= 2, max_features = 8, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 1000, \n",
    "                                         # learning_rate= 0.5,\n",
    "                                        random_state=1)\n",
    "\n",
    "# Create Train Data\n",
    "X = train.drop(\"winner_player_2\", axis=1)\n",
    "y = train[\"winner_player_2\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "\n",
    "# fit model\n",
    "boostedtrees.fit(X_train, y_train)\n",
    "\n",
    "#make prediction\n",
    "y_pred = boostedtrees.predict(X_test)\n",
    "\n",
    "# get prediction probabilities\n",
    "print(boostedtrees.predict_proba(X_test))\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "###########\n",
    "# Run on 11.12\n",
    "# Accuracy score: 0.6736 \n",
    "# (max_depth= 2, max_features = 8, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 1000, random_state=1)#\n",
    "###########\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd attempt (Model 3.1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.613 total time=  37.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.619 total time= 1.1min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.643 total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.643 total time= 1.9min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, n_estimators=1000;, score=0.654 total time= 2.5min\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, n_estimators=700;, score=0.634 total time=   9.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, n_estimators=700;, score=0.643 total time=  19.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, n_estimators=700;, score=0.677 total time=  29.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, n_estimators=700;, score=0.679 total time=  39.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, n_estimators=700;, score=0.680 total time=  49.9s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.601 total time=  54.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.619 total time= 1.9min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.638 total time= 2.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.644 total time= 3.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, n_estimators=1000;, score=0.651 total time= 4.9min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, n_estimators=1000;, score=0.620 total time= 1.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, n_estimators=1000;, score=0.629 total time= 2.6min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, n_estimators=1000;, score=0.644 total time= 3.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, n_estimators=1000;, score=0.651 total time= 4.9min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, n_estimators=1000;, score=0.656 total time= 6.0min\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, n_estimators=500;, score=0.634 total time=   6.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, n_estimators=500;, score=0.645 total time=  13.7s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, n_estimators=500;, score=0.680 total time=  21.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, n_estimators=500;, score=0.685 total time=  28.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, n_estimators=500;, score=0.686 total time=  35.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.614 total time=  27.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.613 total time=  54.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.644 total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.642 total time= 1.9min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, n_estimators=1000;, score=0.649 total time= 2.4min\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, n_estimators=1000;, score=0.625 total time=  13.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, n_estimators=1000;, score=0.637 total time=  27.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, n_estimators=1000;, score=0.673 total time=  41.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, n_estimators=1000;, score=0.672 total time=  56.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, n_estimators=1000;, score=0.675 total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, n_estimators=700;, score=0.613 total time=  45.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, n_estimators=700;, score=0.627 total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, n_estimators=700;, score=0.647 total time= 2.2min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, n_estimators=700;, score=0.647 total time= 3.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, n_estimators=700;, score=0.649 total time= 3.7min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.609 total time=  28.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.618 total time=  56.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.646 total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.647 total time= 1.9min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, n_estimators=1000;, score=0.653 total time= 2.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, n_estimators=500;, score=0.609 total time=  27.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, n_estimators=500;, score=0.620 total time=  56.3s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, n_estimators=500;, score=0.643 total time= 1.9min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, n_estimators=500;, score=0.648 total time= 2.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, n_estimators=500;, score=0.652 total time= 3.2min\n",
      "Best hyperparameters: {'n_estimators': 500, 'min_samples_leaf': 2, 'max_depth': 5}\n",
      "Accuracy (trained cv data): 0.666\n",
      "Accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "# Test at 3.1.\n",
    "# Test duration 83m\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 0. Use TimeSeriesSplit instead of train_test_split for CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1. Instantiate Model\n",
    "model3_1_2_gb = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "# 2. Define hyperparameters for RandomizedSearchCV\n",
    "parameters = {\n",
    "            'n_estimators': [500, 700, 1000],\n",
    "            # 'max_features': [4, 8, 16],\n",
    "            'max_depth': [5, 10, 20],\n",
    "            # 'min_samples_split': [2, 3, 5, 7], \n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "            }\n",
    "\n",
    "# 3. Define RandomizedSearchCV object\n",
    "acc_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "model3_1_2_gb_CV = RandomizedSearchCV(model3_1_2_gb, parameters, cv=tscv, scoring=acc_score, verbose=3)\n",
    "\n",
    "\n",
    "# 4. Fit RandomizedSearchCV to model data\n",
    "model3_1_2_gb_CV_fitted = model3_1_2_gb_CV.fit(X_train, y_train) # use this for ROC plot\n",
    "\n",
    "# 5. Interpret results\n",
    "print(\"Best hyperparameters:\", model3_1_2_gb_CV_fitted.best_params_)\n",
    "print(\"Accuracy (trained cv data): %.3f\" % model3_1_2_gb_CV_fitted.best_score_)\n",
    "\n",
    "# -. Get prediction probabilities\n",
    "# y_pred_model2_1_1.predict_proba(X_test)\n",
    "\n",
    "# 6. Evaluate Model Performance - accuracy\n",
    "y_pred_model3_1_2 = model3_1_2_gb_CV.predict(X_test)\n",
    "model3_1_2_acc = accuracy_score(y_test, y_pred_model3_1_2)\n",
    "print('Accuracy: %.3f' % model3_1_2_acc)\n",
    "\n",
    "# -. Print classification report\n",
    "# y_pred =  (model2_1_1_rf.predict_proba(X_test)[:, 1] > 0.1).astype(int)\n",
    "# print(classification_report(y_test, y_pred_model2_1_1))\n",
    "\n",
    "###########\n",
    "# Tested\n",
    "#  parameters = {\n",
    "#               'n_estimators': [500, 700, 1000],\n",
    "                # 'max_depth': [5, 10, 20],\n",
    "#               'min_samples_leaf': [1, 2, 4]\n",
    "#                }\n",
    "# Results\n",
    "# Best hyperparameters: {'n_estimators': 500, 'min_samples_leaf': 2, 'max_depth': 5}\n",
    "# Accuracy (trained cv data): 0.666\n",
    "# Accuracy (test data): 0.646\n",
    "###########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3.1.1 ROC Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ROC(model3_1_1_gb_CV, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3.1.2 ROC Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ROC(model3_1_2_gb_CV, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3.1.1 Variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_variable_importance(model3_1_1_gb_CV_fitted.best_estimator_, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3.1.2 Variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_variable_importance(model3_1_2_gb_CV_fitted.best_estimator_, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4.1.1: plain XGBoost model without hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: run in terminal:\n",
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test data): 0.645\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Model libraries and functions\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# 2. Instantiate model\n",
    "model4_XGBoostReg  = XGBClassifier()\n",
    "\n",
    "# 3. Fit model to data\n",
    "model4_XGBoostReg_fitted = model4_XGBoostReg.fit(X_train,y_train)\n",
    "\n",
    "# 4. Evaluate Model Performance - accuracy\n",
    "y_pred_model4 = model4_XGBoostReg_fitted.predict(X_test)\n",
    "model4_acc = accuracy_score(y_test, y_pred_model4)\n",
    "print('Accuracy (test data): %.3f' % model4_acc)\n",
    "\n",
    "###########\n",
    "# Tested\n",
    "# parameters - none\n",
    "# Results\n",
    "# Accuracy (test data): 0.645\n",
    "###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4.1.2: XGBoost model with RandomizedSearchCV and hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.661, test=0.662) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.665, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.668, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.703, test=0.654) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.688, test=0.663) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.686, test=0.689) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.686, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.688, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.661, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.665, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.668, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.673, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.800, test=0.640) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.749, test=0.654) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.729, test=0.685) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.720, test=0.685) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.717, test=0.683) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.662, test=0.667) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.666, test=0.676) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.694, test=0.658) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.667) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.677, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.685, test=0.694) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.663, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.664, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.667, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.672, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.676, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.681, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.676, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.679, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.705, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.688, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.684, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.692, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.692, test=0.659) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.677, test=0.690) total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.682, test=0.694) total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.671, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.673, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.683, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.699, test=0.657) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.681, test=0.689) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.688, test=0.688) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.759, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.725, test=0.662) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.712, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.708, test=0.687) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.709, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.701, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.688, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.708, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.692, test=0.665) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.692) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.691, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.767, test=0.649) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.715, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.711, test=0.688) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.713, test=0.684) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.718, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.700, test=0.664) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.694, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.695, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.902, test=0.617) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.837, test=0.636) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.801, test=0.663) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.781, test=0.667) total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.771, test=0.673) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.920, test=0.622) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.855, test=0.636) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.815, test=0.655) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.795, test=0.671) total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.780, test=0.670) total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.673, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.669, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.671, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.689, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.684, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.696, test=0.657) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.667) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.680, test=0.688) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.769, test=0.651) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.730, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.717, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.711, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.712, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.686, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.678, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.675, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.679, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.683, test=0.690) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.841, test=0.621) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.786, test=0.640) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.761, test=0.663) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.746, test=0.674) total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.738, test=0.678) total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.817, test=0.631) total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.775, test=0.642) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.750, test=0.666) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.739, test=0.677) total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.735, test=0.677) total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.664, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.664, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.667, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.674, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.669, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.671, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.725, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.704, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.697, test=0.684) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.696, test=0.694) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.700, test=0.691) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.729, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.702, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.694, test=0.693) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.693, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.697, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.912, test=0.624) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.846, test=0.635) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.814, test=0.667) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.789, test=0.667) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.776, test=0.677) total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.683, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.680, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.682, test=0.696) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.686, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.904, test=0.620) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.839, test=0.635) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.801, test=0.657) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.780, test=0.669) total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.771, test=0.666) total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.706, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.689, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.685, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.687, test=0.690) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.690, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.711, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.692, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.661, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.665, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.668, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.673, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.742, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.713, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.703, test=0.689) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.702, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.707, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.752, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.720, test=0.663) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.707, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.704, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.690) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.877, test=0.625) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.821, test=0.639) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.791, test=0.664) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.773, test=0.671) total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.761, test=0.678) total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.664, test=0.660) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.667, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.668, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.678, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.915, test=0.620) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.849, test=0.635) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.817, test=0.663) total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.791, test=0.670) total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.780, test=0.672) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.792, test=0.641) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.749, test=0.651) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.725, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.718, test=0.687) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.714, test=0.682) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.705, test=0.653) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.691, test=0.665) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.685, test=0.687) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.695) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.689) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.708, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.691, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.688, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.688, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.693, test=0.688) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.704, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.689, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.683, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.690, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.775, test=0.651) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.731, test=0.663) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.720, test=0.690) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.710, test=0.691) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.715, test=0.687) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.685, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.676, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.675, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.680, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.671, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.670, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.671, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.678, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.801, test=0.639) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.753, test=0.651) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.731, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.720, test=0.689) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.719, test=0.685) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.663, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.664, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.667, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.672, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.677, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.676, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.672, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.673, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.677, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.682, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.691, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.676, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.680, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.683, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.779, test=0.640) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.741, test=0.657) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.720, test=0.683) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.715, test=0.684) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.712, test=0.683) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.717, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.698, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.689, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.692, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.697, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.670, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.670, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.694) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.801, test=0.641) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.750, test=0.655) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.679) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.720, test=0.688) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.718, test=0.682) total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.698, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.694, test=0.694) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.693, test=0.690) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.696, test=0.688) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.814, test=0.640) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.760, test=0.657) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.737, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.725, test=0.687) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.723, test=0.683) total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.667, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.667, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.675, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.661, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.665, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.667, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.673, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.701, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.687, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.684, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.688, test=0.691) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.678, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.673, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.673, test=0.688) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.677, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.764, test=0.649) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.734, test=0.659) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.719, test=0.686) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.708, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.712, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.731, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.706, test=0.663) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.701, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.698, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.700, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.701, test=0.655) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.690, test=0.666) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.690) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.688, test=0.688) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.664, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.665, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.677, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.679, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.672, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.673, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.683, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.670, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.668, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.670, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.677, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.679, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.661, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.665, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.668, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.674, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.676, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.670, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.671, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.672, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.680, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.764, test=0.649) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.728, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.715, test=0.684) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.710, test=0.689) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.713, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.751, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.727, test=0.658) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.712, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.709, test=0.688) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.708, test=0.690) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.665, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.666, test=0.677) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.669, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.748, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.720, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.704, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.704, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.707, test=0.689) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.737, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.712, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.702, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.700, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.700, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.704, test=0.653) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.669) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.682, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.684, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.689) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.690, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.677, test=0.688) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.682, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.685, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.811, test=0.634) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.763, test=0.650) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.745, test=0.673) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.742, test=0.681) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.733, test=0.678) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.661) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.673, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.678, test=0.691) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.689) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.695, test=0.661) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.680, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.682, test=0.695) total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.686, test=0.693) total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.726, test=0.651) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.710, test=0.664) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.698, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.699, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.698, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.663) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.675, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.675, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.679, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.681, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.662, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.667, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.668, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.675, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.814, test=0.641) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.756, test=0.652) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.734, test=0.681) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.724, test=0.688) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.721, test=0.681) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.713, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.694, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.689, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.756, test=0.640) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.723, test=0.654) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.711, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.707, test=0.690) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.705, test=0.685) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.793, test=0.637) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.748, test=0.651) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.726, test=0.677) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.718, test=0.688) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.715, test=0.680) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.754, test=0.647) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.724, test=0.655) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.708, test=0.685) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.707, test=0.692) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.705, test=0.688) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.707, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.682, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.659) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.694) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.693) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.723, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.700, test=0.666) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.694) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.692, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.695, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.672, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.670, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.671, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.676, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.681, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.800, test=0.637) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.751, test=0.653) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.727, test=0.681) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.724, test=0.686) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.719, test=0.682) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.786, test=0.642) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.747, test=0.653) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.724, test=0.682) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.717, test=0.688) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.717, test=0.687) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.805, test=0.633) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.754, test=0.650) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.732, test=0.676) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.722, test=0.685) total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.718, test=0.681) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.664, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.669, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.669, test=0.691) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.676, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.679, test=0.696) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.703, test=0.656) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.687, test=0.669) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.683, test=0.690) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.685, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.689, test=0.692) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.672, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.668, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.670, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.679, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.701, test=0.657) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.687, test=0.665) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.685) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.686, test=0.694) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.688, test=0.689) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.655) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.689, test=0.669) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.690) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.672, test=0.664) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.668, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.669, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.675, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.678, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.773, test=0.646) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.737, test=0.657) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.719, test=0.683) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.713, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.711, test=0.684) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.673, test=0.663) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.669, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.670, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.836, test=0.628) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.783, test=0.643) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.754, test=0.671) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.747, test=0.679) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.738, test=0.681) total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.730, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.702, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.693, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.693, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.696, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.789, test=0.642) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.745, test=0.656) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.725, test=0.685) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.719, test=0.687) total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.716, test=0.686) total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.829, test=0.627) total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.783, test=0.641) total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.757, test=0.667) total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.745, test=0.681) total time=   6.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.738, test=0.675) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.682, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.684, test=0.694) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.671, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.672, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.667, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.670, test=0.693) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.677, test=0.696) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.679, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.653) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.668) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.680, test=0.685) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.682, test=0.695) total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.687, test=0.690) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.697, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.683, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.681, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.682, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.691) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.727, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.707, test=0.664) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.700, test=0.684) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.697, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.701, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.709, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.692, test=0.666) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.689, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.692, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.752, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.718, test=0.668) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.706, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.701, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.705, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.884, test=0.628) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.827, test=0.644) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.800, test=0.672) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.779, test=0.677) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.770, test=0.675) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.704, test=0.654) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.687, test=0.666) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.691) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.686, test=0.693) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.770, test=0.649) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.735, test=0.664) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.722, test=0.683) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.710, test=0.690) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.713, test=0.687) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.674, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.669, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.671, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.676, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.680, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.672, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.671, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.672, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.671, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.682, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.766, test=0.641) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.654) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.713, test=0.677) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.707, test=0.686) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.709, test=0.685) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.764, test=0.649) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.730, test=0.659) total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.717, test=0.692) total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.711, test=0.687) total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.710, test=0.687) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.666, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.668, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.670, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.680, test=0.695) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.852, test=0.628) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.792, test=0.643) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.765, test=0.668) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.752, test=0.678) total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.745, test=0.677) total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.699, test=0.656) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.684, test=0.672) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.680, test=0.688) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.683, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.689) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.759, test=0.636) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.728, test=0.654) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.712, test=0.677) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.707, test=0.686) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.707, test=0.682) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.692, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.677, test=0.688) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.659, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.664, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.667, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.672, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.911, test=0.627) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.846, test=0.643) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.813, test=0.666) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.789, test=0.673) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.780, test=0.676) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.664, test=0.666) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.668, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.670, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.824, test=0.635) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.775, test=0.645) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.749, test=0.669) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.745, test=0.681) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.736, test=0.684) total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.703, test=0.654) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.668) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.683, test=0.690) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.701, test=0.658) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.686, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.681, test=0.691) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.684, test=0.692) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.807, test=0.635) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.757, test=0.650) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.732, test=0.676) total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.722, test=0.682) total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.719, test=0.681) total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.694, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.680, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.706, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.684, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.688, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.700, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.685, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.680, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.687, test=0.693) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.714, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.691, test=0.670) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.687, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.686, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.690, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.773, test=0.651) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.735, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.720, test=0.686) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.713, test=0.686) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.715, test=0.686) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.932, test=0.627) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.863, test=0.630) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.823, test=0.663) total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.805, test=0.671) total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.790, test=0.671) total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.708, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.692, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.694) total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.692, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.707, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.692, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.688, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.687, test=0.690) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.693, test=0.688) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.721, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.697, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.692, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.697, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.665, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.666, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.669, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.839, test=0.619) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.790, test=0.637) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.760, test=0.664) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.744, test=0.675) total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.739, test=0.675) total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.758, test=0.647) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.728, test=0.659) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.715, test=0.687) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.713, test=0.688) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.712, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.754, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.720, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.709, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.702, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.706, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.914, test=0.626) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.842, test=0.636) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.817, test=0.669) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.792, test=0.675) total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.778, test=0.673) total time=   4.7s\n",
      "Best hyperparameters: {'subsample': 1.0, 'reg_alpha': 0.01, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "Accuracy (trained cv data): 0.684\n",
      "Accuracy (test data): 0.653\n"
     ]
    }
   ],
   "source": [
    "# Test at 3.1.\n",
    "# Test duration 5m\n",
    "\n",
    "# 1. Import Model libraries and functions\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "# 0. Use TimeSeriesSplit instead of train_test_split for CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1. Instantiate Model\n",
    "model4_1_2_xgb = XGBClassifier(random_state=1)\n",
    "\n",
    "# 2. Define hyperparameters for RandomizedSearchCV\n",
    "parameters =  {'n_estimators': [50, 100, 400],\n",
    "              'max_depth': [3, 5,7],\n",
    "              'learning_rate': [0.1],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'reg_alpha': [0.01, 0.1, 1],\n",
    "              # 'reg_lambda': [0.01, 0.1, 1]\n",
    "              }\n",
    "\n",
    "# 3. Define RandomizedSearchCV object\n",
    "acc_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "model4_1_2_xgb_CV = RandomizedSearchCV(model4_1_2_xgb, \n",
    "                                       param_distributions = parameters, \n",
    "                                       cv=tscv, \n",
    "                                       n_iter = 150,\n",
    "                                       scoring=acc_score, \n",
    "                                       n_jobs=1,\n",
    "                                       verbose=3,\n",
    "                                       return_train_score=True,\n",
    "                                       random_state=8\n",
    "                                       )\n",
    "\n",
    "\n",
    "# 4. Fit RandomizedSearchCV to model data\n",
    "model4_1_2_xgb_CV_fitted = model4_1_2_xgb_CV.fit(X_train, y_train) # use this for ROC plot\n",
    "\n",
    "# 5. Interpret results\n",
    "print(\"Best hyperparameters:\", model4_1_2_xgb_CV_fitted.best_params_)\n",
    "print(\"Accuracy (trained cv data): %.3f\" % model4_1_2_xgb_CV_fitted.best_score_)\n",
    "\n",
    "# -. Get prediction probabilities\n",
    "# y_pred_model2_1_1.predict_proba(X_test)\n",
    "\n",
    "# 6. Evaluate Model Performance - accuracy\n",
    "y_pred_model4_1_2 = model4_1_2_xgb_CV.predict(X_test)\n",
    "model4_1_2_acc = accuracy_score(y_test, y_pred_model4_1_2)\n",
    "print('Accuracy (test data): %.3f' % model4_1_2_acc)\n",
    "\n",
    "# -. Print classification report\n",
    "# y_pred =  (model2_1_1_rf.predict_proba(X_test)[:, 1] > 0.1).astype(int)\n",
    "# print(classification_report(y_test, y_pred_model2_1_1))\n",
    "\n",
    "###########\n",
    "# Tested\n",
    "#  parameters = {'n_estimators': [50, 100, 400],\n",
    "#               'max_depth': [3, 5,7],\n",
    "#               'learning_rate': [0.1],\n",
    "#               'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#               'subsample': [0.6, 0.8, 1.0],\n",
    "#               'reg_alpha': [0.01, 0.1, 1],\n",
    "#                # 'reg_lambda': [0.01, 0.1, 1]\n",
    "#               }\n",
    "# Results\n",
    "# Best hyperparameters: {'subsample': 1.0, 'reg_alpha': 0.01, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
    "# Accuracy (trained cv data): 0.684\n",
    "# Accuracy (test data): 0.653\n",
    "###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4.1.3: XGBoost model with GridSearchCV and hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.661, test=0.661) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.665, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.667, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.673, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.663, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.664, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.667, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.672, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.677, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.661, test=0.665) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.665, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.668, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.673, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.677, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.661, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.665, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.668, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.673, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.663, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.664, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.667, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.672, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.676, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.661, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.665, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.668, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.673, test=0.697) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.660, test=0.663) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.664, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.667, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.673, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.677, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.661, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.664, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.667, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.672, test=0.697) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.659, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.664, test=0.672) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.667, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.672, test=0.697) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.665, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.668, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.670, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.675, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.679, test=0.695) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.672, test=0.664) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.668, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.669, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.675, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.678, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.665, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.666, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.669, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.664, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.669, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.669, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.676, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.679, test=0.696) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.669, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.667, test=0.672) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.669, test=0.691) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.678, test=0.693) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.664, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.667, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.669, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.695) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.679, test=0.696) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.667, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.667, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.668, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.678, test=0.696) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.668, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.669, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.670, test=0.688) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.678, test=0.695) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.667, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.667, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.675, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.699, test=0.655) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.667) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.680, test=0.686) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.682, test=0.696) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.699, test=0.657) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.684, test=0.667) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.681, test=0.687) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.683, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.686, test=0.691) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.697, test=0.658) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.680, test=0.667) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.677, test=0.688) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.685, test=0.694) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.693, test=0.655) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.685, test=0.668) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.685) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.683, test=0.697) total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.686, test=0.692) total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.699, test=0.656) total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.684, test=0.672) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.680, test=0.688) total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.683, test=0.694) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.689) total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.694, test=0.658) total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.667) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.677, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.685, test=0.694) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.653) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.680, test=0.685) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.682, test=0.695) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.687, test=0.690) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.696, test=0.657) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.667) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.680, test=0.688) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.690) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.692, test=0.659) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.677, test=0.690) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.682, test=0.694) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.679, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.672, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.673, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.683, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.679, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.683, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.672, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.671, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.671, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.673, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.678, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.683, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.678, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.682, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.671, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.676, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.672, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.673, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.677, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.682, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.678, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.673, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.673, test=0.688) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.677, test=0.696) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.672, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.671, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.682, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.698, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.684, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.681, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.683, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.687, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.696, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.684, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.681, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.682, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.686, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.691, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.680, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.676, test=0.685) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.681, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.697, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.683, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.681, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.682, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.695, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.680, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.682, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.686, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.692, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.677, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.683, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.680, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.682, test=0.696) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.686, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.694, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.670) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.680, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.694) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.690, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.677, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.682, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.685, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.759, test=0.636) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.728, test=0.654) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.712, test=0.677) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.707, test=0.686) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.707, test=0.682) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.762, test=0.643) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.726, test=0.653) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.712, test=0.677) total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.706, test=0.688) total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.708, test=0.681) total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.754, test=0.648) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.722, test=0.658) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.706, test=0.681) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.691) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.687) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.759, test=0.636) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.726, test=0.659) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.711, test=0.677) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.706, test=0.686) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.706, test=0.683) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.766, test=0.641) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.654) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.713, test=0.677) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.707, test=0.686) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.709, test=0.685) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.754, test=0.647) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.724, test=0.655) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.708, test=0.685) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.707, test=0.692) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.705, test=0.688) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.750, test=0.640) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.720, test=0.657) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.707, test=0.684) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.704, test=0.685) total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.704, test=0.683) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.756, test=0.640) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.723, test=0.654) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.711, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.707, test=0.690) total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.705, test=0.685) total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.745, test=0.648) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.717, test=0.658) total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.705, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.704, test=0.693) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.703, test=0.686) total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.708, test=0.660) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.691, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.690) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.697) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.692, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.708, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.691, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.688, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.688, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.693, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.709, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.692, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.689, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.692, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.708, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.692, test=0.665) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.692) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.695) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.691, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.708, test=0.656) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.692, test=0.668) total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.690) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.694) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.692, test=0.692) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.707, test=0.655) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.691, test=0.665) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.686, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.688, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.690, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.703, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.688, test=0.667) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.685, test=0.690) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.685, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.690, test=0.691) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.703, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.670) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.687, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.692, test=0.690) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.704, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.689, test=0.669) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.683, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.690, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.737, test=0.653) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.711, test=0.666) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.704, test=0.685) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.700, test=0.690) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.700, test=0.687) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.737, test=0.651) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.713, test=0.662) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.701, test=0.687) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.700, test=0.692) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.704, test=0.689) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.725, test=0.655) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.704, test=0.662) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.697, test=0.684) total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.696, test=0.694) total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.700, test=0.691) total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.735, test=0.651) total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.712, test=0.661) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.704, test=0.685) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.699, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.700, test=0.686) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.737, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.712, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.702, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.700, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.700, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.726, test=0.651) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.710, test=0.664) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.698, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.699, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.698, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.731, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.706, test=0.663) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.701, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.698, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.700, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.727, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.707, test=0.664) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.700, test=0.684) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.697, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.701, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.723, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.704, test=0.660) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.697, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.696, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.698, test=0.688) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.841, test=0.621) total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.786, test=0.640) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.761, test=0.663) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.746, test=0.674) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.738, test=0.678) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.850, test=0.622) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.790, test=0.642) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.763, test=0.665) total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.752, test=0.677) total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.745, test=0.678) total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.824, test=0.635) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.775, test=0.645) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.749, test=0.669) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.745, test=0.681) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.736, test=0.684) total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.839, test=0.619) total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.790, test=0.637) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.760, test=0.664) total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.744, test=0.675) total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.739, test=0.675) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.852, test=0.628) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.792, test=0.643) total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.765, test=0.668) total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.752, test=0.678) total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.745, test=0.677) total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.836, test=0.628) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.783, test=0.643) total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.754, test=0.671) total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.747, test=0.679) total time=   5.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.738, test=0.681) total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.817, test=0.631) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.775, test=0.642) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.750, test=0.666) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.739, test=0.677) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.735, test=0.677) total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.829, test=0.627) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.783, test=0.641) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.757, test=0.667) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.745, test=0.681) total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.738, test=0.675) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.811, test=0.634) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.763, test=0.650) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.745, test=0.673) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.742, test=0.681) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.733, test=0.678) total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.665, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.664, test=0.673) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.667, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.664, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.665, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.677, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.662, test=0.660) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.665, test=0.676) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.668, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.677, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.664, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.665, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.667, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.662, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.666, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.668, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.677, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.662, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.666, test=0.676) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.669, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.664, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.664, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.667, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.674, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.661, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.665, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.668, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.674, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.676, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.661, test=0.662) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.665, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.668, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.695) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.673, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.669, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.671, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.672, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.668, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.671, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.676, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.679, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.666, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.668, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.670, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.680, test=0.695) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.672, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.668, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.671, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.676, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.672, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.668, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.670, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.676, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.679, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.669, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.668, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.670, test=0.692) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.693) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.696) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.670, test=0.662) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.668, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.670, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.677, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.679, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.672, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.667, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.670, test=0.693) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.677, test=0.696) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.679, test=0.693) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.671, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.668, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.670, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.675, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.696) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.703, test=0.654) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.668) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.683, test=0.690) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.694) total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.690) total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.703, test=0.656) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.687, test=0.669) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.683, test=0.690) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.685, test=0.694) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.689, test=0.692) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.659) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.668) total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.689) total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.694) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.693) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.702, test=0.654) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.669) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.682, test=0.688) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.685, test=0.693) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.691) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.704, test=0.653) total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.669) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.682, test=0.689) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.684, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.689) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.702, test=0.655) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.685, test=0.665) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.690) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.684, test=0.693) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.686, test=0.693) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.697, test=0.654) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.668) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.682, test=0.689) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.696) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.688, test=0.690) total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.699, test=0.657) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.668) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.681, test=0.689) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.694) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.688, test=0.688) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.698, test=0.654) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.686, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.681, test=0.688) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.692) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.689, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.675, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.679, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.684, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.686, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.679, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.684, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.681, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.676, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.679, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.682, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.684, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.683, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.681, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.685, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.676, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.675, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.680, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.683, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.676, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.674, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.663) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.675, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.675, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.679, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.681, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.706, test=0.653) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.689, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.685, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.687, test=0.690) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.690, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.707, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.689, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.684, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.686, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.689, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.700, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.685, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.680, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.687, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.707, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.691, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.684, test=0.692) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.690, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.707, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.670) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.682, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.699, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.684, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.679, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.684, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.687, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.704, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.688, test=0.663) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.685, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.686, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.689, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.706, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.684, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.688, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.699, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.684, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.681, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.683, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.791, test=0.638) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.744, test=0.652) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.725, test=0.679) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.717, test=0.682) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.716, test=0.682) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.800, test=0.640) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.749, test=0.654) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.729, test=0.685) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.720, test=0.685) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.717, test=0.683) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.789, test=0.642) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.745, test=0.656) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.725, test=0.685) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.719, test=0.687) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.716, test=0.686) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.792, test=0.641) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.749, test=0.651) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.725, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.718, test=0.687) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.714, test=0.682) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.801, test=0.641) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.750, test=0.655) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.679) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.720, test=0.688) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.718, test=0.682) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.786, test=0.642) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.747, test=0.653) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.724, test=0.682) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.717, test=0.688) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.717, test=0.687) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.779, test=0.640) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.741, test=0.657) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.720, test=0.683) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.715, test=0.684) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.712, test=0.683) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.785, test=0.635) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.747, test=0.648) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.725, test=0.680) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.717, test=0.685) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.716, test=0.681) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.780, test=0.645) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.745, test=0.658) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.722, test=0.685) total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.718, test=0.688) total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.714, test=0.685) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.722, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.700, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.694, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.695, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.698, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.720, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.700, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.694, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.695, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.696, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.713, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.696, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.691, test=0.694) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.691, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.696, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.722, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.702, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.694, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.695, test=0.689) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.698, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.698, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.694, test=0.694) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.693, test=0.690) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.696, test=0.688) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.717, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.698, test=0.669) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.689, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.692, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.697, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.718, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.700, test=0.664) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.694, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.695, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.721, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.697, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.692, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.697, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.717, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.693, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.689, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.690, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.696, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.764, test=0.649) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.728, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.715, test=0.684) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.710, test=0.689) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.713, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.769, test=0.651) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.730, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.717, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.711, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.712, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.752, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.720, test=0.663) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.707, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.704, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.690) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.758, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.728, test=0.659) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.715, test=0.687) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.713, test=0.688) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.712, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.767, test=0.649) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.715, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.711, test=0.688) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.713, test=0.684) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.748, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.720, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.704, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.704, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.707, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.751, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.727, test=0.658) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.712, test=0.687) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.709, test=0.688) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.708, test=0.690) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.759, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.725, test=0.662) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.712, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.708, test=0.687) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.709, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.742, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.713, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.703, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.702, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.707, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.904, test=0.620) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.839, test=0.635) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.801, test=0.657) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.780, test=0.669) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.771, test=0.666) total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.916, test=0.621) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.848, test=0.634) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.813, test=0.670) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.792, test=0.673) total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.776, test=0.673) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.889, test=0.631) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.830, test=0.644) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.801, test=0.672) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.778, test=0.680) total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.769, test=0.679) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.902, test=0.617) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.837, test=0.636) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.801, test=0.663) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.781, test=0.667) total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.771, test=0.673) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.912, test=0.624) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.846, test=0.635) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.814, test=0.667) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.789, test=0.667) total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.776, test=0.677) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.884, test=0.628) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.827, test=0.644) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.800, test=0.672) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.779, test=0.677) total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.770, test=0.675) total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.877, test=0.625) total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.821, test=0.639) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.791, test=0.664) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.773, test=0.671) total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.761, test=0.678) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.891, test=0.628) total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.833, test=0.634) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.801, test=0.663) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.781, test=0.675) total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.769, test=0.672) total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.876, test=0.633) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.821, test=0.642) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.787, test=0.676) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.773, test=0.676) total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.764, test=0.677) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.664, test=0.660) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.667, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.668, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.678, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.664, test=0.666) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.668, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.670, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.662, test=0.667) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.666, test=0.676) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.662, test=0.661) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.667, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.668, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.675, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.666, test=0.667) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.667, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.662, test=0.664) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.666, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.663, test=0.660) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.667, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.667, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.674, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.665, test=0.663) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.666, test=0.677) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.669, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.675, test=0.695) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.678, test=0.694) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.662, test=0.664) total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.667, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.669, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.674, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.670, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.671, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.672, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.680, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.672, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.670, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.671, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.676, test=0.695) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.681, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.669, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.670, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.670, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.675, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.680, test=0.696) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.671, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.670, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.671, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.678, test=0.696) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.674, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.669, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.671, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.670, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.670, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.680, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.669, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.670, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.671, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.674, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.669, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.671, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.676, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.680, test=0.694) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.673, test=0.663) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.669, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.670, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.676, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.680, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.705, test=0.653) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.691, test=0.665) total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.685, test=0.687) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.695) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.689) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.707, test=0.656) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.690, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.685, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.686, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.688, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.705, test=0.655) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.689, test=0.669) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.682, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.690) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.703, test=0.654) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.688, test=0.663) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.686, test=0.689) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.686, test=0.693) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.688, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.708, test=0.655) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.690, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.684, test=0.690) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.687, test=0.692) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.689, test=0.690) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.704, test=0.654) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.687, test=0.666) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.691) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.685, test=0.693) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.686, test=0.693) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.701, test=0.657) total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.687, test=0.665) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.685) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.686, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.688, test=0.689) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.701, test=0.655) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.690, test=0.666) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.690) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.686, test=0.694) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.688, test=0.688) total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.701, test=0.658) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.686, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.681, test=0.691) total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.684, test=0.692) total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.690) total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.691, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.677, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.676, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.680, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.683, test=0.693) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.687, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.677, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.674, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.679, test=0.692) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.683, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.673, test=0.662) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.673, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.673, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.678, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.681, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.689, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.677, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.680, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.684, test=0.692) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.686, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.678, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.675, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.679, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.683, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.675, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.674, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.673, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.678, test=0.691) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.689) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.689, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.677, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.676, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.679, test=0.693) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.684, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.677, test=0.675) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.675, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.679, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.682, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.674, test=0.663) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.672, test=0.674) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.674, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.677, test=0.694) total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.682, test=0.691) total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.713, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.694, test=0.668) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.686, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.688, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.689, test=0.689) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.714, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.691, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.687, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.686, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.690, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.701, test=0.661) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.686, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.683, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.688, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.709, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.692, test=0.668) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.686, test=0.689) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.687, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.691, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.712, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.691, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.685, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.686, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.691, test=0.691) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.701, test=0.658) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.687, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.682, test=0.688) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.684, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.688, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.710, test=0.657) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.685, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.686, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.690, test=0.688) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.711, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.692, test=0.671) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.691) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.685, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.689, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.696, test=0.659) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.678, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.681, test=0.694) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.686, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.805, test=0.633) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.754, test=0.650) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.732, test=0.676) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.722, test=0.685) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.718, test=0.681) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.814, test=0.640) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.760, test=0.657) total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.737, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.725, test=0.687) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.723, test=0.683) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.800, test=0.637) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.751, test=0.653) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.727, test=0.681) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.724, test=0.686) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.719, test=0.682) total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.807, test=0.635) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.757, test=0.650) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.732, test=0.676) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.722, test=0.682) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.719, test=0.681) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.814, test=0.641) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.756, test=0.652) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.734, test=0.681) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.724, test=0.688) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.721, test=0.681) total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.801, test=0.641) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.752, test=0.651) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.730, test=0.682) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.724, test=0.690) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.717, test=0.684) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.793, test=0.637) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.748, test=0.651) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.726, test=0.677) total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.718, test=0.688) total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.715, test=0.680) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.801, test=0.639) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.753, test=0.651) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.731, test=0.680) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.720, test=0.689) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.719, test=0.685) total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.785, test=0.641) total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.746, test=0.654) total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.729, test=0.681) total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.720, test=0.689) total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.717, test=0.682) total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.730, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.702, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.693, test=0.691) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.693, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.6;, score=(train=0.696, test=0.692) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.729, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.702, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.694, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.693, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=0.8;, score=(train=0.697, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.715, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.689, test=0.673) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.687, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.689, test=0.692) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.01, subsample=1.0;, score=(train=0.690, test=0.687) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.727, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.704, test=0.667) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.691, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.693, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.6;, score=(train=0.696, test=0.691) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.728, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.701, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.694, test=0.693) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.692, test=0.693) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=0.8;, score=(train=0.698, test=0.690) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.707, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.692, test=0.672) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.688, test=0.689) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.687, test=0.690) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=0.1, subsample=1.0;, score=(train=0.693, test=0.688) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.723, test=0.655) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.700, test=0.666) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.693, test=0.694) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.692, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.6;, score=(train=0.695, test=0.693) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.723, test=0.656) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.701, test=0.668) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.690, test=0.690) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.691, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=0.8;, score=(train=0.695, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.705, test=0.660) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.688, test=0.670) total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.684, test=0.692) total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.687, test=0.691) total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=50, reg_alpha=1, subsample=1.0;, score=(train=0.692, test=0.689) total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.770, test=0.649) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.735, test=0.664) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.722, test=0.683) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.710, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.6;, score=(train=0.713, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.773, test=0.651) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.735, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.720, test=0.686) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.713, test=0.686) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=0.8;, score=(train=0.715, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.754, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.720, test=0.666) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.709, test=0.689) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.702, test=0.692) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.01, subsample=1.0;, score=(train=0.706, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.773, test=0.646) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.737, test=0.657) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.719, test=0.683) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.713, test=0.690) total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.6;, score=(train=0.711, test=0.684) total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.775, test=0.651) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.731, test=0.663) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.720, test=0.690) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.710, test=0.691) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=0.8;, score=(train=0.715, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.752, test=0.653) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.718, test=0.668) total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.706, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.701, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=0.1, subsample=1.0;, score=(train=0.705, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.764, test=0.649) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.730, test=0.659) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.717, test=0.692) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.711, test=0.687) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.6;, score=(train=0.710, test=0.687) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.764, test=0.649) total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.734, test=0.659) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.719, test=0.686) total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.708, test=0.690) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=0.8;, score=(train=0.712, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.745, test=0.652) total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.714, test=0.663) total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.702, test=0.690) total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.704, test=0.693) total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, reg_alpha=1, subsample=1.0;, score=(train=0.702, test=0.686) total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.918, test=0.617) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.854, test=0.633) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.817, test=0.661) total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.793, test=0.667) total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.6;, score=(train=0.782, test=0.670) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.932, test=0.627) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.863, test=0.630) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.823, test=0.663) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.805, test=0.671) total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=0.8;, score=(train=0.790, test=0.671) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.911, test=0.627) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.846, test=0.643) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.813, test=0.666) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.789, test=0.673) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.01, subsample=1.0;, score=(train=0.780, test=0.676) total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.920, test=0.622) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.855, test=0.636) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.815, test=0.655) total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.795, test=0.671) total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.6;, score=(train=0.780, test=0.670) total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.930, test=0.623) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.865, test=0.637) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.829, test=0.667) total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.803, test=0.668) total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=0.8;, score=(train=0.788, test=0.671) total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.914, test=0.626) total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.842, test=0.636) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.817, test=0.669) total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.792, test=0.675) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=0.1, subsample=1.0;, score=(train=0.778, test=0.673) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.900, test=0.621) total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.838, test=0.632) total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.808, test=0.661) total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.786, test=0.668) total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.6;, score=(train=0.774, test=0.673) total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.915, test=0.620) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.849, test=0.635) total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.817, test=0.663) total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.791, test=0.670) total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=0.8;, score=(train=0.780, test=0.672) total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.897, test=0.627) total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.836, test=0.637) total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.807, test=0.665) total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.785, test=0.677) total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=400, reg_alpha=1, subsample=1.0;, score=(train=0.773, test=0.675) total time=   1.4s\n",
      "Best hyperparameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'reg_alpha': 0.1, 'subsample': 0.8}\n",
      "Accuracy (trained cv data): 0.684\n",
      "Accuracy (test data): 0.653\n"
     ]
    }
   ],
   "source": [
    "# Test at 3.1.\n",
    "# Test duration 16m\n",
    "\n",
    "# 1. Import Model libraries and functions\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "\n",
    "# 0. Use TimeSeriesSplit instead of train_test_split for CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1. Instantiate Model\n",
    "model4_1_3_xgb = XGBClassifier(random_state=1)\n",
    "\n",
    "# 2. Define hyperparameters for GridSearchCV\n",
    "parameters =  {'n_estimators': [50, 100, 400],\n",
    "              'max_depth': [3, 5,7],\n",
    "              'learning_rate': [0.1],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'reg_alpha': [0.01, 0.1, 1]\n",
    "              }\n",
    "\n",
    "# 3. Define GridSearchCV object\n",
    "acc_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "model4_1_3_xgb_CV = GridSearchCV(model4_1_3_xgb, \n",
    "                                       param_grid = parameters, \n",
    "                                       cv=tscv, \n",
    "                                       scoring=acc_score, \n",
    "                                       n_jobs=1,\n",
    "                                       verbose=3,\n",
    "                                       return_train_score=True\n",
    "                                       )\n",
    "\n",
    "\n",
    "# 4. Fit GridSearchCV to model data\n",
    "model4_1_3_xgb_CV_fitted = model4_1_3_xgb_CV.fit(X_train, y_train) # use this for ROC plot\n",
    "\n",
    "# 5. Interpret results\n",
    "print(\"Best hyperparameters:\", model4_1_3_xgb_CV_fitted.best_params_)\n",
    "print(\"Accuracy (trained cv data): %.3f\" % model4_1_3_xgb_CV_fitted.best_score_)\n",
    "\n",
    "# -. Get prediction probabilities\n",
    "# y_pred_model2_1_1.predict_proba(X_test)\n",
    "\n",
    "# 6. Evaluate Model Performance - accuracy\n",
    "y_pred_model4_1_3 = model4_1_3_xgb_CV.predict(X_test)\n",
    "model4_1_3_acc = accuracy_score(y_test, y_pred_model4_1_3)\n",
    "print('Accuracy (test data): %.3f' % model4_1_3_acc)\n",
    "\n",
    "# -. Print classification report\n",
    "# y_pred =  (model2_1_1_rf.predict_proba(X_test)[:, 1] > 0.1).astype(int)\n",
    "# print(classification_report(y_test, y_pred_model2_1_1))\n",
    "\n",
    "###########\n",
    "# Tested\n",
    "#  parameters = {'n_estimators': [50, 100, 400],\n",
    "#               'max_depth': [3, 5,7],\n",
    "#               'learning_rate': [0.1],\n",
    "#               'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#               'subsample': [0.6, 0.8, 1.0],\n",
    "#               'reg_alpha': [0.01, 0.1, 1]\n",
    "#               }\n",
    "# Results\n",
    "# Best hyperparameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'reg_alpha': 0.1, 'subsample': 0.8}\n",
    "# Accuracy (trained cv data): 0.684\n",
    "# Accuracy (test data): 0.653\n",
    "###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Conclusion  <a name=\"final-concl\"></a>\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cas-proj",
   "language": "python",
   "name": "cas-proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
